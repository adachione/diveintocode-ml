{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 深層学習スクラッチ ニューラルネットワーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import copy\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "uint8\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(X_train[0].dtype) # uint8\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "# X_train[index]: (784,)\n",
    "# image: (28, 28)\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -102.35  -87.35  -87.35  -87.35   20.65   30.65\n",
      "    69.65  -79.35   60.65  149.65  141.65   21.65 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -75.35\n",
      "   -69.35  -11.35   48.65   64.65  147.65  147.65  147.65  147.65  147.65\n",
      "   119.65   66.65  147.65  136.65   89.65  -41.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -56.35  132.65\n",
      "   147.65  147.65  147.65  147.65  147.65  147.65  147.65  147.65  145.65\n",
      "   -12.35  -23.35  -23.35  -49.35  -66.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35  113.65\n",
      "   147.65  147.65  147.65  147.65  147.65   92.65   76.65  141.65  135.65\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -25.35\n",
      "    50.65    1.65  147.65  147.65   99.65  -94.35 -105.35  -62.35   48.65\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "   -91.35 -104.35   48.65  147.65  -15.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35   33.65  147.65   84.65 -103.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35  -94.35   84.65  147.65  -35.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35  -70.35  135.65  119.65   54.65    2.65 -104.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35  -24.35  134.65  147.65  147.65   13.65\n",
      "   -80.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35  -60.35   80.65  147.65  147.65\n",
      "    44.65  -78.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -89.35  -12.35  146.65\n",
      "   147.65   81.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  143.65\n",
      "   147.65  143.65  -41.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35  -59.35   24.65   77.65  147.65\n",
      "   147.65  101.65 -103.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35  -66.35   42.65  123.65  147.65  147.65  147.65\n",
      "   144.65   76.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35  -81.35    8.65  115.65  147.65  147.65  147.65  147.65   95.65\n",
      "   -27.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -82.35\n",
      "   -39.35  107.65  147.65  147.65  147.65  147.65   92.65  -24.35 -103.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35   65.65  113.65\n",
      "   147.65  147.65  147.65  147.65   89.65  -25.35  -96.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35  -50.35   66.65  120.65  147.65  147.65\n",
      "   147.65  147.65  138.65   27.65  -94.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35   30.65  147.65  147.65  147.65  106.65\n",
      "    29.65   26.65  -89.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "image = image.astype(np.float) # float型に変換\n",
    "image -= 105.35 # 意図的に負の小数値を作り出してみる\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()\n",
    "print(image) # 値を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbf78a9fdd8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image, 'gray', vmin = 0, vmax = 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, y, batch_size=20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0] / self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        p0 = item * self.batch_size\n",
    "        p1 = item * self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter * self.batch_size\n",
    "        p1 = self._counter * self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n",
      "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), array([0, 9, 7, 8, 1, 8, 9, 6, 6, 9, 8, 0, 7, 9, 0, 9, 1, 1, 1, 6],\n",
      "      dtype=uint8))\n"
     ]
    }
   ],
   "source": [
    "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "print(len(get_mini_batch)) # 2400\n",
    "print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    # このfor文内でミニバッチが使える\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20 # バッチサイズ\n",
    "n_features = 784 # 特徴量の数\n",
    "n_nodes1 = 400 # 1層目のノード数\n",
    "n_nodes2 = 200 # 2層目のノード数\n",
    "n_output = 10 # 出力のクラス数（3層目のノード数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSimpleNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, epoch=20, n_batch=20, bias=False, func=\"sigmoid\", lr=0.001, n_nodes1=400, n_nodes2=200, n_output=10, verbose=True):\n",
    "        self.verbose = verbose\n",
    "        self.epoch = epoch\n",
    "        self.n_batch = n_batch\n",
    "        self.bias = bias\n",
    "        self.func = func\n",
    "        self.lr = lr\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.epoch)\n",
    "        self.val_loss = np.zeros(self.epoch)\n",
    "        \n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.n_output = n_output\n",
    "        \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, self.n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, self.n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        self.n_features = X.shape[1]\n",
    "\n",
    "        enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        y_train_one_hot = enc.fit_transform(y[:, np.newaxis])\n",
    "        \n",
    "        if y_val is not None:\n",
    "            y_val_one_hot = enc.fit_transform(y[:, np.newaxis])\n",
    "        \n",
    "        self.epoch_cnt = 0\n",
    "        self.batch_cnt = 0\n",
    "        \n",
    "        self.W_list, self.b_list = self._init_network()\n",
    "        self.default_W_list, self.default_b_list = copy.deepcopy(self.W_list), copy.deepcopy(self.b_list)\n",
    "                \n",
    "        for i in range(self.epoch):\n",
    "            get_mini_batch = GetMiniBatch(X, y_train_one_hot, batch_size=20)\n",
    "\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                # フォワードプロバゲーション**************************\n",
    "                self.A_list, self.Z_list = self._forward(mini_X_train, self.W_list, self.b_list)\n",
    "\n",
    "                # バックプロバゲーション**************************            \n",
    "                self._backward(mini_X_train, mini_y_train, self.W_list, self.b_list, self.A_list, self.Z_list)\n",
    "            \n",
    "            # クロスエントロピー誤差**************************\n",
    "            self.loss[i] = self._cross_entropy_error(mini_y_train, self.Z_list[-1])\n",
    "        \n",
    "        # 問題7 val_loss計算\n",
    "        if X_val is not None and y_val is not None:\n",
    "            self.val_W_list, self.val_b_list = self._init_network()\n",
    "            self.default_val_W_list, self.default_val_b_list = copy.deepcopy(self.val_W_list), copy.deepcopy(self.val_b_list)\n",
    "            \n",
    "            for i in range(self.epoch):\n",
    "                get_mini_batch = GetMiniBatch(X_val, y_val_one_hot, batch_size=20)\n",
    "\n",
    "                for mini_X_val, mini_y_val in get_mini_batch:\n",
    "                    # フォワードプロバゲーション**************************\n",
    "                    self.val_A_list, self.val_Z_list = self._forward(mini_X_val, self.val_W_list, self.val_b_list)\n",
    "\n",
    "                    # バックプロバゲーション**************************            \n",
    "                    self._backward(mini_X_val, mini_y_val, self.val_W_list, self.val_b_list, self.val_A_list, self.val_Z_list)\n",
    "\n",
    "                self.val_loss[i] = self._cross_entropy_error(mini_y_val, self.val_Z_list[-1])\n",
    "\n",
    "        if self.verbose:\n",
    "            # verboseをTrueにした際は学習過程などを出力する\n",
    "            pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, self.n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        _, Z = self._forward(X, self.W_list, self.b_list)        \n",
    "        pred = np.argmax(Z[-1], axis=1)\n",
    "        return pred\n",
    "    \n",
    "    def accuracy(self, val, pred):\n",
    "        return accuracy_score(val, pred)\n",
    "\n",
    "    # 問題1\n",
    "    # 重み初期化\n",
    "    def _init_network(self):\n",
    "        \"\"\"重み初期値作成関数\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        sigma = 0.01  # ガウス分布の標準偏差\n",
    "        \n",
    "        # 重みは前ノード数の１/ルートが適切\n",
    "        W1 = sigma * np.random.randn(self.n_features, self.n_nodes1)\n",
    "        W2 = sigma * np.random.randn(self.n_nodes1, self.n_nodes2)\n",
    "        W3 = sigma * np.random.randn(self.n_nodes2, self.n_output)\n",
    "        \n",
    "        # バイアス項はランダム値か0かでパラメータ選択\n",
    "        if self.bias==True:\n",
    "            b1 = sigma * np.random.randn(self.n_nodes1)\n",
    "            b2 = sigma * np.random.randn(self.n_nodes2)\n",
    "            b3 = sigma * np.random.randn(self.n_output)\n",
    "        \n",
    "        else:\n",
    "            b1 = np.zeros(self.n_nodes1)\n",
    "            b2 = np.zeros(self.n_nodes2)\n",
    "            b3 = np.zeros(self.n_output)\n",
    "\n",
    "        W_list = [W1, W2, W3]\n",
    "        b_list = [b1, b2, b3]\n",
    "\n",
    "        return W_list, b_list\n",
    "\n",
    "    # 問題2\n",
    "    # 活性化関数（フォワードプロバゲーション）\n",
    "    def _forward(self, X, W, b):\n",
    "        \"\"\"\n",
    "        X :\n",
    "        \"\"\"\n",
    "        # sigmoid\n",
    "        if self.func == \"sigmoid\":            \n",
    "            A1 = np.dot(X, W[0]) + b[0]     #(20, 400)\n",
    "            Z1 = self._sigmoid(A1)\n",
    "            A2 = np.dot(Z1, W[1]) + b[1]   #(20, 200)\n",
    "            Z2 = self._sigmoid(A2)\n",
    "            A3 = np.dot(Z2, W[2]) + b[2]   #(20, 10)\n",
    "            Z3 = self._softmax(A3)\n",
    "        \n",
    "        # tanh\n",
    "        else:\n",
    "            A1 = np.dot(X, W[0]) + b[0]     #(20, 400)\n",
    "            Z1 = self._hyperbolic_tangent(A1)\n",
    "            A2 = np.dot(Z1, W[1]) + b[1]   #(20, 200)\n",
    "            Z2 = self._hyperbolic_tangent(A2)\n",
    "            A3 = np.dot(Z2, W[2]) + b[2]   #(20, 10)\n",
    "            Z3 = self._softmax(A3)\n",
    "\n",
    "        A_list = [A1, A2, A3]\n",
    "        Z_list = [Z1, Z2, Z3]    # Z[-1]:Z3が予測値\n",
    "        \n",
    "        return A_list, Z_list\n",
    "\n",
    "    # 問題4\n",
    "    # 確率的勾配降下法(バックプロパゲーション)\n",
    "    # ここのコード：書き足しで進めて行き、長くなってしまった。分岐自体はシンプルなので、中身は薄い。何かアドバイスがほしい。\n",
    "    def _backward(self, X, y, W, b, A, Z):\n",
    "        if self.func == \"sigmoid\":\n",
    "            # 3層目\n",
    "            gra_a_3 = Z[-1] - y\n",
    "            gra_b_3 = np.sum(gra_a_3, axis=0)\n",
    "            gra_W_3 = np.dot(Z[1].T, gra_a_3)\n",
    "            gra_z_3 = np.dot(gra_a_3, W[-1].T)\n",
    "\n",
    "            # 2層目\n",
    "            gra_a_2 = gra_z_3*np.multiply((1-self._sigmoid(A[1])), self._sigmoid(A[1]))\n",
    "            gra_b_2 = np.sum(gra_a_2, axis=0)\n",
    "            gra_W_2 = np.dot(Z[0].T, gra_a_2)\n",
    "            gra_z_2 = np.dot(gra_a_2, W[1].T)\n",
    "\n",
    "            # 1層目\n",
    "            gra_a_1 = gra_z_2*np.multiply((1-self._sigmoid(A[0])), self._sigmoid(A[0]))\n",
    "            gra_b_1 = np.sum(gra_a_1, axis=0)\n",
    "            gra_W_1 = np.dot(X.T, gra_a_1)\n",
    "\n",
    "            gra_b_list = [gra_b_1, gra_b_2, gra_b_3]\n",
    "            gra_W_list = [gra_W_1, gra_W_2, gra_W_3]\n",
    "\n",
    "            for i in range(3):\n",
    "                W[i] -= self.lr*gra_W_list[i]\n",
    "                b[i] -= self.lr*gra_b_list[i]    \n",
    "\n",
    "        if self.func == \"tanh\":\n",
    "            # 3層目\n",
    "            gra_a_3 = Z[-1] - y\n",
    "            gra_b_3 = np.sum(gra_a_3, axis=0)\n",
    "            gra_W_3 = np.dot(Z[1].T, gra_a_3)\n",
    "            gra_z_3 = np.dot(gra_a_3, W[-1].T)\n",
    "\n",
    "            # 2層目\n",
    "            gra_a_2 = gra_z_3*((1-self._hyperbolic_tangent(A[1])**2))\n",
    "            gra_b_2 = np.sum(gra_a_2, axis=0)\n",
    "            gra_W_2 = np.dot(Z[0].T, gra_a_2)\n",
    "            gra_z_2 = np.dot(gra_a_2, W[1].T)\n",
    "\n",
    "            # 1層目\n",
    "            gra_a_1 = gra_z_2*((1-self._hyperbolic_tangent(A[0])**2))\n",
    "            gra_b_1 = np.sum(gra_a_1, axis=0)\n",
    "            gra_W_1 = np.dot(X.T, gra_a_1)\n",
    "\n",
    "            gra_b_list = [gra_b_1, gra_b_2, gra_b_3]\n",
    "            gra_W_list = [gra_W_1, gra_W_2, gra_W_3]\n",
    "\n",
    "            for i in range(3):\n",
    "                W[i] -= self.lr*gra_W_list[i]\n",
    "                b[i] -= self.lr*gra_b_list[i]    \n",
    "\n",
    "    \n",
    "    # 問題2------------------------------------\n",
    "    # シグモイド関数\n",
    "    def _sigmoid(self, X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "\n",
    "    #ハイパボリックタンジェント関数\n",
    "    def _hyperbolic_tangent(self, X):\n",
    "        return np.tanh(X)\n",
    "\n",
    "    # ソフトマックス関数\n",
    "    def _softmax(self, X):\n",
    "        c = np.max(X)\n",
    "        \n",
    "        return np.exp(X-c) / np.sum(np.exp(X - c), axis=1, keepdims=True)\n",
    "\n",
    "    # 問題３------------------------------------\n",
    "    # クロスエントロピー誤差関数\n",
    "    def _cross_entropy_error(self, y, Z):\n",
    "        if y.ndim == 1:\n",
    "            Z = t.reshape(1, Z.size)\n",
    "            y = y.reshape(1, y.size)        \n",
    "        \n",
    "        batch_size = y.shape[0]\n",
    "        \n",
    "        error = -np.sum(y*np.log(Z + 1e-7)) / batch_size\n",
    "        \n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# backward検算\n",
    "\n",
    "n_features = 784\n",
    "n_nodes1 = 400\n",
    "n_nodes2 = 200\n",
    "n_output = 10\n",
    "sigma = 0.01  # ガウス分布の標準偏差\n",
    "\n",
    "tmpW1 = sigma * np.random.randn(n_features, n_nodes1)\n",
    "tmpW2 = np.random.randn(n_nodes1, n_nodes2) / np.sqrt(n_nodes1)\n",
    "tmpW3 = np.random.randn(n_nodes2, n_output) / np.sqrt(n_nodes2)\n",
    "tmpb1 = sigma * np.random.randn(n_nodes1)\n",
    "tmpb2 = np.random.randn(n_nodes2) / np.sqrt(n_nodes1)\n",
    "tmpb3 = np.random.randn(n_output) / np.sqrt(n_nodes2)\n",
    "\n",
    "tmp_W_list = [tmpW1, tmpW2, tmpW3]\n",
    "tmp_b_list = [tmpb1, tmpb2, tmpb3]\n",
    "\n",
    "tmpA1 = np.dot(mini_X_train, tmp_W_list[0]) + tmp_b_list[0]     #(20, 400)\n",
    "tmpZ1 = scr_NN._sigmoid(tmpA1)\n",
    "tmpA2 = np.dot(tmpZ1, tmp_W_list[1]) + tmp_b_list[1]   #(20, 200)\n",
    "tmpZ2 = scr_NN._sigmoid(tmpA2)\n",
    "tmpA3 = np.dot(tmpZ2, tmp_W_list[2]) + tmp_b_list[2]   #(20, 10)\n",
    "tmpZ3 = scr_NN._softmax(tmpA3)\n",
    "\n",
    "A_list = [tmpA1, tmpA2, tmpA3]\n",
    "Z_list = [tmpZ1, tmpZ2, tmpZ3] \n",
    "\n",
    "gra_a_3 = Z_list[-1] - mini_y_train_hot    # (20, 10)\n",
    "gra_b_3 = np.sum(gra_a_3, axis=0)     #(10,)\n",
    "gra_W_3 = np.dot(Z_list[1].T, gra_a_3)   #(200, 10)\n",
    "gra_z_3 = np.dot(gra_a_3, tmp_W_list[-1].T)    #(20, 200)\n",
    "\n",
    "\n",
    "gra_a_2 = gra_z_3*((1-scr_NN._sigmoid(A_list[1])*scr_NN._sigmoid(A_list[1])))  #(20, 200)\n",
    "gra_b_2 = np.sum(gra_a_2, axis=0)  #(200,)\n",
    "gra_W_2 = np.dot(Z_list[0].T, gra_a_2)  #(400, 200)\n",
    "gra_z_2 = np.dot(gra_a_2, tmp_W_list[1].T)  #(20, 400)\n",
    "\n",
    "gra_a_1 = gra_z_2*((1-scr_NN._sigmoid(A_list[0])*scr_NN._sigmoid(A_list[0])))\n",
    "gra_b_1 = np.sum(gra_a_1, axis=0)\n",
    "gra_W_1 = np.dot(mini_X_train.T, gra_a_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】重みの初期値を決めるコードの作成\n",
    "ニューラルネットワークの各層の重みの初期値を決めるコードを作成してください。\n",
    "\n",
    "\n",
    "重みの初期値は様々な方法が提案されていますが、今回はガウス分布による単純な初期化を行います。バイアスに関しても同様です。\n",
    "\n",
    "\n",
    "以下のコードを参考にしてください。標準偏差の値sigmaはハイパーパラメータです。発展的な重みの初期化方法については次のSprintで扱います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】フォワードプロパゲーションの実装\n",
    "三層のニューラルネットワークの フォワードプロパゲーション を作成してください。以下の説明ではノード数は1層目は400、2層目は200としますが、変更しても構いません。\n",
    "\n",
    "\n",
    "各層の数式を以下に示します。今回はそれぞれの記号が表す配列が、実装上どのようなndarrayのshapeになるかを併記してあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】交差エントロピー誤差の実装\n",
    "目的関数（損失関数）を作成します。\n",
    "\n",
    "\n",
    "多クラス分類の目的関数である交差エントロピー誤差 $L$ は次の数式です。\n",
    "\n",
    "\n",
    "L\n",
    "=\n",
    "−\n",
    "1\n",
    "n\n",
    "b\n",
    "n\n",
    "b\n",
    "∑\n",
    "j\n",
    "  \n",
    "n\n",
    "c\n",
    "∑\n",
    "k\n",
    " \n",
    "y\n",
    "j\n",
    "k\n",
    "l\n",
    "o\n",
    "g\n",
    "(\n",
    "z\n",
    "3\n",
    "_\n",
    "j\n",
    "k\n",
    ")\n",
    "\n",
    "$y_{ij}$ : $j$ 番目のサンプルの $k$ 番目のクラスの正解ラベル（one-hot表現で0か1のスカラー）\n",
    "\n",
    "\n",
    "$z_{3_ij}$ : $j$ 番目のサンプルの $k$ 番目のクラスの確率（スカラー）\n",
    "\n",
    "\n",
    "$n_{b}$ : バッチサイズ、batch_size\n",
    "\n",
    "\n",
    "$n_{c}$ : クラスの数、n_output（今回のMNISTでは10）\n",
    "\n",
    "\n",
    "サンプル1つあたりの誤差が求まります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】バックプロパゲーションの実装\n",
    "三層のニューラルネットワークのバックプロパゲーションを作成してください。確率的勾配降下法を行う部分です。\n",
    "\n",
    "\n",
    "数式を以下に示します。\n",
    "\n",
    "\n",
    "まず、i層目の重みとバイアスの更新式です。 $W_i$ と $B_i$ に対し、更新後の $W_i^{\\prime}$ と $B_i^{\\prime}$ は次の数式で求められます。\n",
    "\n",
    "$$\n",
    "W\n",
    "′\n",
    "i\n",
    "=\n",
    "W\n",
    "i\n",
    "−\n",
    "α\n",
    "\\frac{∂L}{∂Wi}\n",
    "$$\n",
    "\n",
    "$$\n",
    "B′i\n",
    "=\n",
    "B\n",
    "i\n",
    "−\n",
    "α\\frac{∂L}{∂Bi}\n",
    "$$\n",
    "\n",
    "$\\alpha$ : 学習率（層ごとに変えることも可能だが、基本的には全て同じとする）\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_i}$ : $W_i$ に関する損失 $L$ の勾配\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial B_i}$ : $B_i$ に関する損失 $L$ の勾配\n",
    "\n",
    "\n",
    "＊この勾配はミニバッチのサンプル数分の合計または平均を考えます。ここでは合計を計算します。\n",
    "\n",
    "\n",
    "この更新方法はSprint3線形回帰やsprint4ロジスティック回帰における最急降下法と同様です。より効果的な更新方法が知られており、それは次のSprintで扱います。\n",
    "\n",
    "\n",
    "勾配 $\\frac{\\partial L}{\\partial W_i}$ や $\\frac{\\partial L}{\\partial B_i}$ を求めるために、バックプロパゲーションを行います。以下の数式です。ハイパボリックタンジェント関数を使用した例を載せました。シグモイド関数の場合の数式はその後ろにあります。\n",
    "\n",
    "\n",
    "「3層目」\n",
    "\n",
    "$$\n",
    "\\frac{∂L}{∂A3}\n",
    "=\n",
    "Z3−Y\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{∂L}{∂B3}\n",
    "=\n",
    "\\sum_{j}^{n_b} \\quad\\frac{∂L}{∂A3_j}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{∂L}{∂W3}\n",
    "=\n",
    "Z_2^T\n",
    "⋅\n",
    "\\frac{∂L}{∂A3}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{∂L}{∂Z2}\n",
    "=\n",
    "\\frac{∂L}{∂A3}\n",
    "⋅\n",
    "W_3^T\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_3}$ : $A_3$ に関する損失 $L$ の勾配 (batch_size, n_output)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_{3_j}}$ : j番目のサンプルの$A_3$ に関する損失 $L$ の勾配 (n_nodes2,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial B_3}$ : $B_3$ に関する損失 $L$ の勾配 (n_output,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_3}$ : $W_3$ に関する損失 $L$ の勾配 (n_nodes2, n_output)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial Z_2}$ : $Z_2$ に関する損失 $L$ の勾配 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$Z_{3}$ : ソフトマックス関数の出力 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$Y$ : 正解ラベル (batch_size, n_output)\n",
    "\n",
    "\n",
    "$Z_{2}$ : 2層目の活性化関数の出力 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$W_3$ : 3層目の重み (n_nodes2, n_output)\n",
    "\n",
    "\n",
    "「2層目」\n",
    "$$\\frac{∂L}{∂A2}=\\frac{∂L}{∂Z2}⊙{1−tanh^2(A2)}$$\n",
    "\n",
    "$$\\frac{∂L}{∂B2}=\\sum_{j}^{nb}\\quad\\frac{∂L}{∂A2_j}$$\n",
    "\n",
    "$$\\frac{∂L}{∂W2}=Z_1^T⋅\\frac{∂L}{∂A2}$$\n",
    "\n",
    "$$\\frac{∂L}{∂Z1}=\\frac{∂L}{∂A2}⋅W_2^T$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_2}$ : $A_2$ に関する損失 $L$ の勾配 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_{2_j}}$ : j番目のサンプルの$A_2$ に関する損失 $L$ の勾配 (n_nodes2,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial B_2}$ : $B_2$ に関する損失 $L$ の勾配 (n_output,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_2}$ : $W_2$ に関する損失 $L$ の勾配 (n_nodes1, n_nodes2)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial Z_2}$ : $Z_2$ に関する損失 $L$ の勾配 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$A_2$ : 2層目の出力 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$Z_{1}$ : 1層目の活性化関数の出力 (batch_size, n_nodes1)\n",
    "\n",
    "\n",
    "$W_2$ : 2層目の重み (n_nodes1, n_nodes2)\n",
    "\n",
    "\n",
    "「1層目」\n",
    "\n",
    "$$\\frac{∂L}{∂A1}=\\frac{∂L}{∂Z1}⊙{1−tanh^2(A1)}$$\n",
    "\n",
    "$$\\frac{∂L}{∂B1}=\\sum_{j}^{nb} \\quad\\frac{∂L}{∂A1_j}$$\n",
    "\n",
    "$$\\frac{∂L}{∂W1}=X^T⋅\\frac{∂L}{∂A1}$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_1}$ : $A_1$ に関する損失 $L$ の勾配 (batch_size, n_nodes1)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_{1_j}}$ : j番目のサンプルの$A_1$ に関する損失 $L$ の勾配 (n_nodes1,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial B_1}$ : $B_1$ に関する損失 $L$ の勾配 (n_output,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_1}$ : $W_1$ に関する損失 $L$ の勾配 (n_features, n_nodes1)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial Z_1}$ : $Z_1$ に関する損失 $L$ の勾配 (batch_size, n_nodes1)\n",
    "\n",
    "\n",
    "$A_1$ : 1層目の出力 (batch_size, n_nodes1)\n",
    "\n",
    "\n",
    "$X$ : 特徴量ベクトル (batch_size, n_features)\n",
    "\n",
    "\n",
    "$W_1$ : 1層目の重み (n_features, n_nodes1)\n",
    "\n",
    "\n",
    "《補足》\n",
    "\n",
    "\n",
    "活性化関数にシグモイド関数を使用した場合は、次のようになります。\n",
    "$$\n",
    "\\frac{∂L}{∂A2}=\\frac{∂L}{∂Z2}⊙{1−sigmoid(A2)}sigmoid(A2)\n",
    "$$\n",
    "$$\n",
    "\\frac{∂L}{∂A1}=\\frac{∂L}{∂Z1}⊙{1−sigmoid(A1)}sigmoid(A1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】学習と推定\n",
    "MNISTのデータを学習・推定し、Accuracyを計算してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9806\n"
     ]
    }
   ],
   "source": [
    "# 最も正解率の高かったlr:0.01でエポック数を20にして再度実行\n",
    "scr_NN = ScratchSimpleNeuralNetrowkClassifier(epoch=20, lr=0.01, bias=False, func=\"tanh\")\n",
    "\n",
    "scr_NN.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "pred = scr_NN.predict(X_test)\n",
    "print(\"Accuracy:{}\".format(scr_NN.accuracy(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 988, 1138, 1026, 1017,  974,  881,  956, 1031,  976, 1013])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問題なく分類できているようである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題7】学習曲線のプロット\n",
    "学習曲線をプロットしてください。\n",
    "\n",
    "\n",
    "ニューラルネットワークは過学習が発生しやすいため、学習曲線の確認が重要です。訓練データと検証データに対するエポックごとの損失（交差エントロピー誤差）を記録できるようにする必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.30691547, 2.30712293, 2.30875142, 2.30813648, 2.30216684,\n",
       "       2.29206885, 2.28071211, 2.27068474, 2.26257395, 2.25596154,\n",
       "       2.25040875, 2.24561493, 2.24136341, 2.23749815, 2.23391496,\n",
       "       2.23054688, 2.22733944, 2.2242214 , 2.22108629, 2.2178143 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scr_NN.loss\n",
    "\n",
    "scr_NN.val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(scr_NN.loss, marker=\".\")\n",
    "plt.plot(scr_NN.val_loss, marker=\".\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### val_lossの描画が上手く行きませんでした。コードを何度見ても特に問題がないようにしか見えませんでした。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題8】（アドバンス課題）誤分類の確認\n",
    "誤分類した画像はどのようなものだったかを確認してください。推定値を用意し、以下のコードを実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adachi-yuya/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADQAAABBCAYAAACel4eZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAA41JREFUaIHtmT1s5EQUx39vDyqaq6DABt1VNCDRbEZEIDrEUW42Hw1cRZ2USJyQaEOkSNBABzTeoBQU0FGgxbtuaK+gQNrVbhBwBcVRrTyPIllrvThrxztOrMh/aTTW+Hne+8/M+xhZVJXbhNZNG+AaDaG6oyFUdzSE6o6G0Bwi8nSpxSLyec43X4nIhxnjDy++X5zv7VKGqeraDXgOeAq8lSM3BryM8YfALy5scXXktoC/gP5lAiLyGvCPqk4c6cyEK0IfAN/o6sLwAfDDivevi8gTEflNRB6JyDOlLHFw3F4CYuBejlwfePOSd/eBe5wv8KvAY+CjUvY4IPQx8HOOzF3gb+BOwTl3gV9vyofeB77OkXkH+ElV44JzKiBljFmLkIi8AbwIfJcj+h7w44p53hWRFy6eXwEeAd+XMmrN4/Yl8G2OjAB/AM+vkPkM+BP4F/gd+BR4toxNoisD0/oQkTbwhaq2K1V0gesqfT65Jj3V79B1oylO644rlRcicqPnU1Vzc9Ot26GGUN1RCSHf9wnDkDAMUVXiuGgJ5wBXLHW0SAvDUGezmc5mM43jWGezWfLOGKPGmELzLDfn14ciSo0xaq3VOI41juPkOau31urh4WG9CQVBkOzK4g5l9cu754JQuWvuJfB9H9/3ERFarXP3nD8v99PpFIDt7W2XJrglZIyh3W6jqlhrAYiiiOPjY0TkvLy/6OeEoihyaYJbQkBqFwA2NzeJoojT01Pnxmfqr1zDdcNlUOh2uynHX3wejUYaBEGpcM0VgoJTQsYYHY1GqbA9Ho9TY/O+TD5yfgUvUm0bY/A8b74AifN3Oh329/dptVpYazk7OwNgOByyu7tbSH+RaruSSmFVGwwGqcQax7EOBgPtdrv1O3JFmud52ul0Uol13h8cHNQrsRbBZDJhMpkkxywIgiTMG2PWV1DFDvV6vVyn9zxPPc/Tfr+fioSrviliY5OHVjXf9zUMw1TYLhKaF0P61tZWfXwoq5br9XoMh8P/1XIiklpQay2tVisJ96VRdWLNuw8tjvV6vbWjnFMfiqKInZ0djo6OsNZirU1WP6vPGlsbVeehxUR62Q6Nx2MNgsBJHnJe+izD8zw2NjY4OTlJ/MRay97eXrKg0+m00NVCC5Q+lRNyiSKEbl0eagjVHbeO0FUrhSfAqApDCuDlIkLNL8m6oyFUdzSE6o6GUN3REKo7/gOIax/4AllWQgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "語分類結果を並べて表示する。画像の上の表示は「推定結果/正解」である。\n",
    "\n",
    "Parameters:\n",
    "----------\n",
    "y_pred : 推定値のndarray (n_samples,)\n",
    "y_val : 検証データの正解ラベル(n_samples,)\n",
    "X_val : 検証データの特徴量（n_samples, n_features)\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "num = 36 # いくつ表示するか\n",
    "true_false = pred==y_val\n",
    "false_list = np.where(true_false==False)[0].astype(np.int)\n",
    "if false_list.shape[0] < num:\n",
    "    num = false_list.shape[0]\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "fig.subplots_adjust(left=0, right=0.8,  bottom=0, top=0.8, hspace=1, wspace=0.5)\n",
    "for i in range(num):\n",
    "    ax = fig.add_subplot(6, 6, i + 1, xticks=[], yticks=[])\n",
    "    ax.set_title(\"{} / {}\".format(pred[false_list[i]],y_val[false_list[i]]))\n",
    "    ax.imshow(X_val.reshape(-1,28,28)[false_list[i]], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 711,
   "position": {
    "height": "732.986px",
    "left": "1718.99px",
    "right": "20px",
    "top": "112.99px",
    "width": "406.997px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
