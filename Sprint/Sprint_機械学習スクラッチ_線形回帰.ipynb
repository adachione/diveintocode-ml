{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 機械学習スクラッチ 線形回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題1~3と5は下記class内に実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】仮定関数\n",
    "以下の数式で表される線形回帰の仮定関数を実装してください。メソッドの雛形を用意してあります。\n",
    "\n",
    "$$\n",
    "hθ(x)=θ_0x_0+θ_1x_1+...+θj_xj+...+θ_nx_n.(x_0=1)\n",
    "$$\n",
    "\n",
    "$x$ : 特徴量ベクトル\n",
    "\n",
    "\n",
    "$\\theta$ : パラメータベクトル\n",
    "\n",
    "\n",
    "$n$ : 特徴量の数\n",
    "\n",
    "\n",
    "$x_j$ : j番目の特徴量\n",
    "\n",
    "\n",
    "$\\theta_j$ : j番目のパラメータ（重み）\n",
    "\n",
    "\n",
    "特徴量の数$n$は任意の値に対応できる実装にしてください。\n",
    "\n",
    "\n",
    "なお、ベクトル形式で表すと以下のようになります。\n",
    "\n",
    "\n",
    "$$\n",
    "hθ(x)=θT⋅x\n",
    "$$\n",
    "雛形\n",
    "\n",
    "\n",
    "クラスの外から呼び出すことがないメソッドのため、Pythonの慣例としてアンダースコアを先頭にひとつつけています。\n",
    "\n",
    "## 【問題2】最急降下法\n",
    "最急降下法により学習させる実装を行なってください。以下の式で表されるパラメータの更新式のメソッド_gradient_descentを追加し、fit\n",
    "メソッドから呼び出すようにしてください。\n",
    "\n",
    "$$\n",
    "θj:=θj−\n",
    "α\n",
    "1\n",
    "m\n",
    "m\n",
    "∑\n",
    "i\n",
    "=\n",
    "1\n",
    " \n",
    "[\n",
    "(\n",
    "h\n",
    "θ\n",
    "(\n",
    "x\n",
    "(\n",
    "i\n",
    ")\n",
    ")\n",
    "−\n",
    "y\n",
    "(\n",
    "i\n",
    ")\n",
    ")\n",
    "x\n",
    "(\n",
    "i\n",
    ")\n",
    "j\n",
    "]\n",
    "$$\n",
    "\n",
    "$\\alpha$ : 学習率\n",
    "\n",
    "\n",
    "$i$ : サンプルのインデックス\n",
    "\n",
    "\n",
    "$j$ : 特徴量のインデックス\n",
    "\n",
    "\n",
    "雛形\n",
    "\n",
    "\n",
    "ScratchLinearRegressionクラスへ以下のメソッドを追加してください。コメントアウト部分の説明も記述してください。\n",
    "\n",
    "## 【問題3】推定\n",
    "推定する仕組みを実装してください。ScratchLinearRegressionクラスの雛形に含まれるpredictメソッドに書き加えてください。\n",
    "\n",
    "\n",
    "仮定関数 $h_\\theta(x)$ の出力が推定結果です。\n",
    "\n",
    "\n",
    "## 【問題5】目的関数\n",
    "以下の数式で表される線形回帰の 目的関数（損失関数） を実装してください。そして、これをself.loss, self.val_lossに記録するようにしてください。\n",
    "\n",
    "\n",
    "目的関数（損失関数） \n",
    "J\n",
    "(\n",
    "θ\n",
    ")\n",
    " は次の式です。\n",
    "\n",
    "\n",
    "J\n",
    "(\n",
    "θ\n",
    ")\n",
    "=\n",
    "1\n",
    "2\n",
    "m\n",
    "m\n",
    "∑\n",
    "i\n",
    "=\n",
    "1\n",
    " \n",
    "(\n",
    "h\n",
    "θ\n",
    "(\n",
    "x\n",
    "(\n",
    "i\n",
    ")\n",
    ")\n",
    "−\n",
    "y\n",
    "(\n",
    "i\n",
    ")\n",
    ")\n",
    "2\n",
    ".\n",
    "\n",
    "m\n",
    " : 入力されるデータの数\n",
    "\n",
    "\n",
    "h\n",
    "θ\n",
    "(\n",
    ")\n",
    " : 仮定関数\n",
    "\n",
    "\n",
    "x\n",
    "(\n",
    "i\n",
    ")\n",
    " : i番目のサンプルの特徴量ベクトル\n",
    "\n",
    "\n",
    "y\n",
    "(\n",
    "i\n",
    ")\n",
    " : i番目のサンプルの正解値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      訓練データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証データに対する損失の記録\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_iter, lr, no_bias, verbose):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.no_bias = no_bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        \n",
    "        # 訓練データ・学習データのインスタンス変数化\n",
    "        self.X, self.y, self.X_val, self.y_val, self.theta = self._setting(X, y, X_val, y_val)\n",
    "        \n",
    "        for i in range(self.iter):\n",
    "            self.linear_hypo = self._linear_hypothesis(self.X)    #仮定関数\n",
    "            self.grad = self._gradient_descent(self.X, self.y)    #thetaの更新\n",
    "            self.pred = self.predict(self.X)     #目的関数\n",
    "            #print(\"[pred]\", self.pred)\n",
    "            \n",
    "            self.loss[i] = self.loss_func(self.y)    #損失関数\n",
    "            \n",
    "            if X_val is not None and y_val is not None:\n",
    "                self.val_pred = self.predict(self.X_val)\n",
    "                self.val_loss[i] = self.val_loss_func(self.y_val)\n",
    "                    \n",
    "            if self.verbose:\n",
    "                # verboseをTrueにした際は学習過程を出力\n",
    "                print(\"iter{}:[loss]:{}\".format(i, self.loss[i]))\n",
    "                print(\"iter{}:[val_loss]:{}\".format(i, self.val_loss[i]))    \n",
    "\n",
    "\n",
    "    def _setting(self, X, y, X_val, y_val):\n",
    "        \"\"\"\n",
    "        インスタンス変数の整形関数\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        #thetaはこの関数内で作成\n",
    "        \n",
    "        X_copy = np.copy(X)\n",
    "        y_copy = np.copy(y)\n",
    "        \n",
    "        if X_val is not None and y_val is not None:\n",
    "            X_val_copy = np.copy(X_val)\n",
    "            y_val_copy = np.copy(y_val)\n",
    "                \n",
    "        #バイアス項ありの場合\n",
    "        if self.no_bias == False:\n",
    "            X_ones = np.ones(X.shape[0]).reshape(-1, 1)\n",
    "            X_val_ones = np.ones(X_val.shape[0]).reshape(-1, 1)   #X0列目に1を追加\n",
    "            X_copy = np.hstack((X_ones, X_copy))\n",
    "            X_val_copy = np.hstack((X_val_ones, X_val_copy))    #X0列目に1を追加\n",
    "            np.random.seed(0)\n",
    "            theta = np.random.randn(X.shape[1] + 1)   \n",
    "            return X_copy, y_copy, X_val_copy, y_val_copy, theta\n",
    "\n",
    "        else:\n",
    "            theta = np.random.randn(X.shape[1])\n",
    "            return X_copy, y_copy, X_val_copy, y_val_copy, theta\n",
    "\n",
    "    def _linear_hypothesis(self, X):\n",
    "        \"\"\"\n",
    "        線形の仮定関数を計算する\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "          訓練データ\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "          次の形のndarray, shape (n_samples, 1)\n",
    "          線形の仮定関数による推定結果\n",
    "\n",
    "        \"\"\"\n",
    "        self.hypo = np.dot(X, self.theta.T).reshape(-1, 1)\n",
    "\n",
    "        return self.hypo\n",
    "\n",
    "    def _gradient_descent(self, X, y, alpha=0.0001, error=0):\n",
    "        \"\"\"\n",
    "        最急降下法\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "          訓練データ\n",
    "\n",
    "        alpha：学習率\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        grad = np.average(np.dot(X.T,(self.linear_hypo-y)), axis=1)\n",
    "        self.theta -= alpha*grad        \n",
    "        return self.theta\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            線形回帰による推定結果\n",
    "        \"\"\"\n",
    "        pred = self._linear_hypothesis(X)\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def loss_func(self, y):\n",
    "        \"\"\"\n",
    "        損失関数の計算\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : 次の形のndarray, shape (n_samples,)\n",
    "        訓練データ用\n",
    "        Returns\n",
    "        ----------\n",
    "        \"\"\"\n",
    "        loss = np.average(self.pred - self.y) ** 2 / 2\n",
    "        return loss\n",
    "    \n",
    "    def val_loss_func(self, y):\n",
    "        \"\"\"\n",
    "        損失関数の計算\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : 次の形のndarray, shape (n_samples,)\n",
    "        テストデータ用\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        \"\"\"\n",
    "        val_loss = np.average(self.val_pred - self.y_val) ** 2 / 2\n",
    "        return val_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題1  単独で作成した関数\n",
    "\n",
    "def _linear_hypothesis(X):\n",
    "    \"\"\"\n",
    "    線形の仮定関数を計算する\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "      次の形のndarray, shape (n_samples, 1)\n",
    "      線形の仮定関数による推定結果\n",
    "\n",
    "    \"\"\"\n",
    "    line_hypo = np.dot(X, theta.T)\n",
    "    \n",
    "    return line_hypo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題２　単独で作成した関数\n",
    "\n",
    "def _gradient_descent_1(X, y, alpha=0.1, error=0):\n",
    "    \"\"\"\n",
    "    最急降下法\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    \n",
    "    alpha：学習率\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    \"\"\"\n",
    "    # データフレーム型だった場合にnd_array型に変換\n",
    "    if type(X) is pd.core.frame.DataFrame:\n",
    "        X = X.values\n",
    "        \n",
    "    np.random.seed(0)\n",
    "    theta = np.random.random(size=X.shape[1])\n",
    "\n",
    "    y = np.ones(5)\n",
    "    \n",
    "    # gradientを求める\n",
    "    gradient = 0\n",
    "    for x in range(X.shape[1]):\n",
    "        gradient += alpha * (_linear_hypothesis(X)[x] - y[x]) * X[x, :]\n",
    "    \n",
    "    gradient = gradient / X.shape[1]\n",
    "    \n",
    "    # thetaの更新\n",
    "    error = theta - gradient\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題3 単独で作成した関数\n",
    "def predict(X):\n",
    "    \"\"\"\n",
    "    線形回帰を使い推定する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "        サンプル\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        次の形のndarray, shape (n_samples, 1)\n",
    "        線形回帰による推定結果\n",
    "    \"\"\"\n",
    "\n",
    "    theta = np.random.random(size=X.shape[1])\n",
    "    theta = np.dot(X, _gradient_descent(X).T)    \n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】平均二乗誤差\n",
    "線形回帰の指標値として用いられる平均二乗誤差（mean square error, MSE）の関数を作成してください。\n",
    "\n",
    "\n",
    "平均二乗誤差関数は回帰問題全般で使える関数のため、ScratchLinearRegressionクラスのメソッドではなく、別の関数として作成してください。雛形を用意してあります。\n",
    "\n",
    "\n",
    "平均二乗誤差は以下の数式で表されます。\n",
    "\n",
    "\n",
    "L\n",
    "(\n",
    "θ\n",
    ")\n",
    "=\n",
    "1\n",
    "m\n",
    "m\n",
    "∑\n",
    "i\n",
    "=\n",
    "1\n",
    " \n",
    "(\n",
    "h\n",
    "θ\n",
    "(\n",
    "x\n",
    "(\n",
    "i\n",
    ")\n",
    ")\n",
    "−\n",
    "y\n",
    "(\n",
    "i\n",
    ")\n",
    ")\n",
    "2\n",
    ".\n",
    "\n",
    "$m$ : 入力されるデータの数\n",
    "\n",
    "\n",
    "$h_\\theta()$ : 仮定関数\n",
    "\n",
    "\n",
    "$x^{(i)}$ : i番目のサンプルの特徴量ベクトル\n",
    "\n",
    "\n",
    "$y^{(i)}$ : i番目のサンプルの正解値\n",
    "\n",
    "\n",
    "なお、最急降下法のための目的関数（損失関数）としては、これを2で割ったものを使用します。（問題5, 9）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題4\n",
    "def MSE(y_pred, y):\n",
    "    \"\"\"\n",
    "    平均二乗誤差の計算\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : 次の形のndarray, shape (n_samples,)\n",
    "      推定した値\n",
    "    y : 次の形のndarray, shape (n_samples,)\n",
    "      正解値\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mse : numpy.float\n",
    "      平均二乗誤差\n",
    "    \"\"\"\n",
    "    mse = np.average((y_pred - y) ** 2)\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】学習と推定\n",
    "機械学習スクラッチ入門のSprintで用意したHouse Pricesコンペティションのデータに対してスクラッチ実装の学習と推定を行なってください。\n",
    "\n",
    "\n",
    "scikit-learnによる実装と比べ、正しく動いているかを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "Id                                                                    \n",
       "1           60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "2           20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "3           60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "4           70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "5           60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "   LandContour Utilities LotConfig    ...     PoolArea PoolQC Fence  \\\n",
       "Id                                    ...                             \n",
       "1          Lvl    AllPub    Inside    ...            0    NaN   NaN   \n",
       "2          Lvl    AllPub       FR2    ...            0    NaN   NaN   \n",
       "3          Lvl    AllPub    Inside    ...            0    NaN   NaN   \n",
       "4          Lvl    AllPub    Corner    ...            0    NaN   NaN   \n",
       "5          Lvl    AllPub       FR2    ...            0    NaN   NaN   \n",
       "\n",
       "   MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "Id                                                                         \n",
       "1          NaN       0      2    2008        WD         Normal     208500  \n",
       "2          NaN       0      5    2007        WD         Normal     181500  \n",
       "3          NaN       0      9    2008        WD         Normal     223500  \n",
       "4          NaN       0      2    2006        WD        Abnorml     140000  \n",
       "5          NaN       0     12    2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Week4/train.csv\")\n",
    "df = df.set_index(\"Id\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1095, 2)\n",
      "(365, 2)\n",
      "(1095, 1)\n",
      "(365, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X変数には2つ、y変数にはSalePriceを抽出\n",
    "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n",
    "y = df.loc[:, [\"SalePrice\"]]\n",
    "\n",
    "# スクラッチ関数で分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 標準化せずに実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter0:[loss]:7.951702962679633e+21\n",
      "iter0:[val_loss]:7.862347266731651e+21\n",
      "iter1:[loss]:3.7939742347296113e+33\n",
      "iter1:[val_loss]:3.752860124210466e+33\n",
      "iter2:[loss]:1.808219924388178e+45\n",
      "iter2:[val_loss]:1.788643394190084e+45\n",
      "iter3:[loss]:8.617789351554086e+56\n",
      "iter3:[val_loss]:8.524491904315359e+56\n",
      "iter4:[loss]:4.107146400753324e+68\n",
      "iter4:[val_loss]:4.0626818612587986e+68\n",
      "iter5:[loss]:1.9574220900070029e+80\n",
      "iter5:[val_loss]:1.936230765924807e+80\n",
      "iter6:[loss]:9.328864527247144e+91\n",
      "iter6:[val_loss]:9.227868941040374e+91\n",
      "iter7:[loss]:4.446037153200478e+103\n",
      "iter7:[val_loss]:4.397903735969654e+103\n",
      "iter8:[loss]:2.1189338005603896e+115\n",
      "iter8:[val_loss]:2.0959939282218454e+115\n",
      "iter9:[loss]:1.0098612081829374e+127\n",
      "iter9:[val_loss]:9.989283101427827e+126\n",
      "iter10:[loss]:4.81289061283081e+138\n",
      "iter10:[val_loss]:4.7607855889699827e+138\n",
      "iter11:[loss]:2.2937722395292518e+150\n",
      "iter11:[val_loss]:2.268939541908129e+150\n",
      "iter12:[loss]:1.093187340017362e+162\n",
      "iter12:[val_loss]:1.0813523416726864e+162\n",
      "iter13:[loss]:5.210014053616307e+173\n",
      "iter13:[val_loss]:5.153609716095067e+173\n",
      "iter14:[loss]:2.4830370280768448e+185\n",
      "iter14:[val_loss]:2.4561553235040567e+185\n",
      "iter15:[loss]:1.1833889159130363e+197\n",
      "iter15:[val_loss]:1.1705773827491816e+197\n",
      "iter16:[loss]:5.63990512614495e+208\n",
      "iter16:[val_loss]:5.5788467280198925e+208\n",
      "iter17:[loss]:2.687918519785563e+220\n",
      "iter17:[val_loss]:2.658818739658417e+220\n",
      "iter18:[loss]:1.2810332456682039e+232\n",
      "iter18:[val_loss]:1.2671646013956523e+232\n",
      "iter19:[loss]:6.105267568297171e+243\n",
      "iter19:[val_loss]:6.039171091582164e+243\n",
      "iter20:[loss]:2.9097052872393242e+255\n",
      "iter20:[val_loss]:2.878204412688925e+255\n",
      "iter21:[loss]:1.3867344492077434e+267\n",
      "iter21:[val_loss]:1.371721468989167e+267\n",
      "iter22:[loss]:6.60902821001519e+278\n",
      "iter22:[val_loss]:6.537477950455649e+278\n",
      "iter23:[loss]:3.149792226314926e+290\n",
      "iter23:[val_loss]:3.1156921371354088e+290\n",
      "iter24:[loss]:1.5011573190018394e+302\n",
      "iter24:[val_loss]:1.4849055808640715e+302\n",
      "iter25:[loss]:inf\n",
      "iter25:[val_loss]:inf\n",
      "iter26:[loss]:inf\n",
      "iter26:[val_loss]:inf\n",
      "iter27:[loss]:inf\n",
      "iter27:[val_loss]:inf\n",
      "iter28:[loss]:inf\n",
      "iter28:[val_loss]:inf\n",
      "iter29:[loss]:inf\n",
      "iter29:[val_loss]:inf\n",
      "iter30:[loss]:inf\n",
      "iter30:[val_loss]:inf\n",
      "iter31:[loss]:inf\n",
      "iter31:[val_loss]:inf\n",
      "iter32:[loss]:inf\n",
      "iter32:[val_loss]:inf\n",
      "iter33:[loss]:inf\n",
      "iter33:[val_loss]:inf\n",
      "iter34:[loss]:inf\n",
      "iter34:[val_loss]:inf\n",
      "iter35:[loss]:inf\n",
      "iter35:[val_loss]:inf\n",
      "iter36:[loss]:inf\n",
      "iter36:[val_loss]:inf\n",
      "iter37:[loss]:inf\n",
      "iter37:[val_loss]:inf\n",
      "iter38:[loss]:inf\n",
      "iter38:[val_loss]:inf\n",
      "iter39:[loss]:inf\n",
      "iter39:[val_loss]:inf\n",
      "iter40:[loss]:inf\n",
      "iter40:[val_loss]:inf\n",
      "iter41:[loss]:inf\n",
      "iter41:[val_loss]:inf\n",
      "iter42:[loss]:inf\n",
      "iter42:[val_loss]:inf\n",
      "iter43:[loss]:inf\n",
      "iter43:[val_loss]:inf\n",
      "iter44:[loss]:inf\n",
      "iter44:[val_loss]:inf\n",
      "iter45:[loss]:inf\n",
      "iter45:[val_loss]:inf\n",
      "iter46:[loss]:inf\n",
      "iter46:[val_loss]:inf\n",
      "iter47:[loss]:inf\n",
      "iter47:[val_loss]:inf\n",
      "iter48:[loss]:inf\n",
      "iter48:[val_loss]:inf\n",
      "iter49:[loss]:inf\n",
      "iter49:[val_loss]:inf\n",
      "iter50:[loss]:inf\n",
      "iter50:[val_loss]:inf\n",
      "iter51:[loss]:inf\n",
      "iter51:[val_loss]:inf\n",
      "iter52:[loss]:nan\n",
      "iter52:[val_loss]:nan\n",
      "iter53:[loss]:nan\n",
      "iter53:[val_loss]:nan\n",
      "iter54:[loss]:nan\n",
      "iter54:[val_loss]:nan\n",
      "iter55:[loss]:nan\n",
      "iter55:[val_loss]:nan\n",
      "iter56:[loss]:nan\n",
      "iter56:[val_loss]:nan\n",
      "iter57:[loss]:nan\n",
      "iter57:[val_loss]:nan\n",
      "iter58:[loss]:nan\n",
      "iter58:[val_loss]:nan\n",
      "iter59:[loss]:nan\n",
      "iter59:[val_loss]:nan\n",
      "iter60:[loss]:nan\n",
      "iter60:[val_loss]:nan\n",
      "iter61:[loss]:nan\n",
      "iter61:[val_loss]:nan\n",
      "iter62:[loss]:nan\n",
      "iter62:[val_loss]:nan\n",
      "iter63:[loss]:nan\n",
      "iter63:[val_loss]:nan\n",
      "iter64:[loss]:nan\n",
      "iter64:[val_loss]:nan\n",
      "iter65:[loss]:nan\n",
      "iter65:[val_loss]:nan\n",
      "iter66:[loss]:nan\n",
      "iter66:[val_loss]:nan\n",
      "iter67:[loss]:nan\n",
      "iter67:[val_loss]:nan\n",
      "iter68:[loss]:nan\n",
      "iter68:[val_loss]:nan\n",
      "iter69:[loss]:nan\n",
      "iter69:[val_loss]:nan\n",
      "iter70:[loss]:nan\n",
      "iter70:[val_loss]:nan\n",
      "iter71:[loss]:nan\n",
      "iter71:[val_loss]:nan\n",
      "iter72:[loss]:nan\n",
      "iter72:[val_loss]:nan\n",
      "iter73:[loss]:nan\n",
      "iter73:[val_loss]:nan\n",
      "iter74:[loss]:nan\n",
      "iter74:[val_loss]:nan\n",
      "iter75:[loss]:nan\n",
      "iter75:[val_loss]:nan\n",
      "iter76:[loss]:nan\n",
      "iter76:[val_loss]:nan\n",
      "iter77:[loss]:nan\n",
      "iter77:[val_loss]:nan\n",
      "iter78:[loss]:nan\n",
      "iter78:[val_loss]:nan\n",
      "iter79:[loss]:nan\n",
      "iter79:[val_loss]:nan\n",
      "iter80:[loss]:nan\n",
      "iter80:[val_loss]:nan\n",
      "iter81:[loss]:nan\n",
      "iter81:[val_loss]:nan\n",
      "iter82:[loss]:nan\n",
      "iter82:[val_loss]:nan\n",
      "iter83:[loss]:nan\n",
      "iter83:[val_loss]:nan\n",
      "iter84:[loss]:nan\n",
      "iter84:[val_loss]:nan\n",
      "iter85:[loss]:nan\n",
      "iter85:[val_loss]:nan\n",
      "iter86:[loss]:nan\n",
      "iter86:[val_loss]:nan\n",
      "iter87:[loss]:nan\n",
      "iter87:[val_loss]:nan\n",
      "iter88:[loss]:nan\n",
      "iter88:[val_loss]:nan\n",
      "iter89:[loss]:nan\n",
      "iter89:[val_loss]:nan\n",
      "iter90:[loss]:nan\n",
      "iter90:[val_loss]:nan\n",
      "iter91:[loss]:nan\n",
      "iter91:[val_loss]:nan\n",
      "iter92:[loss]:nan\n",
      "iter92:[val_loss]:nan\n",
      "iter93:[loss]:nan\n",
      "iter93:[val_loss]:nan\n",
      "iter94:[loss]:nan\n",
      "iter94:[val_loss]:nan\n",
      "iter95:[loss]:nan\n",
      "iter95:[val_loss]:nan\n",
      "iter96:[loss]:nan\n",
      "iter96:[val_loss]:nan\n",
      "iter97:[loss]:nan\n",
      "iter97:[val_loss]:nan\n",
      "iter98:[loss]:nan\n",
      "iter98:[val_loss]:nan\n",
      "iter99:[loss]:nan\n",
      "iter99:[val_loss]:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adachi-yuya/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/ipykernel_launcher.py:179: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/adachi-yuya/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/ipykernel_launcher.py:194: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/adachi-yuya/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/ipykernel_launcher.py:147: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    }
   ],
   "source": [
    "scr_lr = ScratchLinearRegression(num_iter=100, \n",
    "                                 lr=0.01, \n",
    "                                 no_bias = False,\n",
    "                                 verbose=True)\n",
    "\n",
    "scr_lr.fit(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  98.588892  , 1041.18622755]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([-2021422.10210011])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "# 係数\n",
    "display(lr.coef_)\n",
    "# 切片\n",
    "display(lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失なく上昇している、かつ、学習回数を増やすとinfになり計算不可。\n",
    "## 授業内の学習共有で発表されていた、標準化するしないが関係しているかも。\n",
    "## sklearnとスクラッチ関数それぞれ標準化して試してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)   #後でスケーリングするために使用する平均と標準を計算します。\n",
    "X_train_scaler = scaler.transform(X_train)   # 標準化　センタリングとスケーリングによって標準化を実行する\n",
    "X_test_scaler = scaler.transform(X_test)     # 標準化　センタリングとスケーリングによって標準化を実行する\n",
    "\n",
    "#scaler.fit(y_train)\n",
    "#y_train_scaler = scaler.transform(y_train)\n",
    "#y_test_scaler = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50915.49019418, 31435.11963558]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([180733.14977169])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sklearn\n",
    "# 標準化して実行\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaler, y_train)\n",
    "lr_pred = lr.predict(X_test_scaler)\n",
    "\n",
    "# 係数\n",
    "display(lr.coef_)\n",
    "# 切片\n",
    "display(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter0:[loss]:12951050859.179832\n",
      "iter0:[val_loss]:13091680931.198393\n",
      "iter1:[loss]:10270057058.583729\n",
      "iter1:[val_loss]:10410699496.378399\n",
      "iter2:[loss]:8144055114.400573\n",
      "iter2:[val_loss]:8281603327.242138\n",
      "iter3:[loss]:6458156301.182291\n",
      "iter3:[val_loss]:6590482803.25765\n",
      "iter4:[loss]:5121254979.813619\n",
      "iter4:[val_loss]:5246971628.2906885\n",
      "iter5:[loss]:4061105266.7561455\n",
      "iter5:[val_loss]:4179377479.0188155\n",
      "iter6:[loss]:3220416880.7612724\n",
      "iter6:[val_loss]:3330820074.075228\n",
      "iter7:[loss]:2553759187.379101\n",
      "iter7:[val_loss]:2656168213.800138\n",
      "iter8:[loss]:2025106136.4395483\n",
      "iter8:[val_loss]:2119610472.4758675\n",
      "iter9:[loss]:1605889421.411732\n",
      "iter9:[val_loss]:1692728432.5295422\n",
      "iter10:[loss]:1273454653.7576444\n",
      "iter10:[val_loss]:1352968479.8025944\n",
      "iter11:[loss]:1009837124.2469386\n",
      "iter11:[val_loss]:1082429695.0350432\n",
      "iter12:[loss]:800790993.6158609\n",
      "iter12:[val_loss]:866902440.660606\n",
      "iter13:[loss]:635019450.2251891\n",
      "iter13:[val_loss]:695105775.0312133\n",
      "iter14:[loss]:503564232.5889351\n",
      "iter14:[val_loss]:558082558.8789155\n",
      "iter15:[loss]:399321526.6917582\n",
      "iter15:[val_loss]:448719630.61535513\n",
      "iter16:[loss]:316658077.28167903\n",
      "iter16:[val_loss]:361367177.5133705\n",
      "iter17:[loss]:251106767.86811805\n",
      "iter17:[val_loss]:291536783.3780176\n",
      "iter18:[loss]:199125218.62843084\n",
      "iter18:[val_loss]:235661879.0491364\n",
      "iter19:[loss]:157904356.90146416\n",
      "iter19:[val_loss]:190907689.2287149\n",
      "iter20:[loss]:125216615.4553814\n",
      "iter20:[val_loss]:155020439.50255013\n",
      "iter21:[loss]:99295555.19411665\n",
      "iter21:[val_loss]:126207705.21525039\n",
      "iter22:[loss]:78740407.13727152\n",
      "iter22:[val_loss]:103043463.41203739\n",
      "iter23:[loss]:62440375.14088673\n",
      "iter23:[val_loss]:84392741.06857312\n",
      "iter24:[loss]:49514608.693065666\n",
      "iter24:[val_loss]:69351809.21303496\n",
      "iter25:[loss]:39264601.926166244\n",
      "iter25:[val_loss]:57200710.34122803\n",
      "iter26:[loss]:31136446.49758107\n",
      "iter26:[val_loss]:47365570.97048186\n",
      "iter27:[loss]:24690898.49222842\n",
      "iter27:[val_loss]:39388678.145036325\n",
      "iter28:[loss]:19579641.768076774\n",
      "iter28:[val_loss]:32904716.64437003\n",
      "iter29:[loss]:15526465.020577697\n",
      "iter29:[val_loss]:27621895.1185109\n",
      "iter30:[loss]:12312335.37828414\n",
      "iter30:[val_loss]:23306952.273698457\n",
      "iter31:[loss]:9763561.909709333\n",
      "iter31:[val_loss]:19773242.747755412\n",
      "iter32:[loss]:7742409.399670831\n",
      "iter32:[val_loss]:16871267.70046818\n",
      "iter33:[loss]:6139655.165447268\n",
      "iter33:[val_loss]:14481146.324613623\n",
      "iter34:[loss]:4868686.684561858\n",
      "iter34:[val_loss]:12506628.535501357\n",
      "iter35:[loss]:3860821.0711623807\n",
      "iter35:[val_loss]:10870331.633871889\n",
      "iter36:[loss]:3061593.466426353\n",
      "iter36:[val_loss]:9509949.209988547\n",
      "iter37:[loss]:2427813.768339816\n",
      "iter37:[val_loss]:8375232.495906432\n",
      "iter38:[loss]:1925232.6471092228\n",
      "iter38:[val_loss]:7425585.577822636\n",
      "iter39:[loss]:1526690.718139282\n",
      "iter39:[val_loss]:6628148.571382049\n",
      "iter40:[loss]:1210650.85424995\n",
      "iter40:[val_loss]:5956268.8007004885\n",
      "iter41:[loss]:960034.323574364\n",
      "iter41:[val_loss]:5388280.603175771\n",
      "iter42:[loss]:761297.8582598129\n",
      "iter42:[val_loss]:4906530.714456931\n",
      "iter43:[loss]:603701.7789459197\n",
      "iter43:[val_loss]:4496599.1496474305\n",
      "iter44:[loss]:478729.6246117816\n",
      "iter44:[val_loss]:4146675.7846318684\n",
      "iter45:[loss]:379627.92470329505\n",
      "iter45:[val_loss]:3847061.0079065743\n",
      "iter46:[loss]:301041.2429174379\n",
      "iter46:[val_loss]:3589765.296750172\n",
      "iter47:[loss]:238722.77048141608\n",
      "iter47:[val_loss]:3368187.7196239983\n",
      "iter48:[loss]:189304.82944474864\n",
      "iter48:[val_loss]:3176857.455098023\n",
      "iter49:[loss]:150116.8840276038\n",
      "iter49:[val_loss]:3011225.665087451\n",
      "iter50:[loss]:119041.22539426529\n",
      "iter50:[val_loss]:2867497.6402754663\n",
      "iter51:[loss]:94398.53108570687\n",
      "iter51:[val_loss]:2742497.185947818\n",
      "iter52:[loss]:74857.11476528642\n",
      "iter52:[val_loss]:2633556.8462742735\n",
      "iter53:[loss]:59360.96215200513\n",
      "iter53:[val_loss]:2538428.860998407\n",
      "iter54:[loss]:47072.66421716206\n",
      "iter54:[val_loss]:2455212.779282503\n",
      "iter55:[loss]:37328.16376573342\n",
      "iter55:[val_loss]:2382296.475663377\n",
      "iter56:[loss]:29600.869916631586\n",
      "iter56:[val_loss]:2318307.965999315\n",
      "iter57:[loss]:23473.201235408204\n",
      "iter57:[val_loss]:2262075.941294091\n",
      "iter58:[loss]:18614.01971596692\n",
      "iter58:[val_loss]:2212597.351650345\n",
      "iter59:[loss]:14760.736148069049\n",
      "iter59:[val_loss]:2169010.702984103\n",
      "iter60:[loss]:11705.119848239505\n",
      "iter60:[val_loss]:2130573.992722948\n",
      "iter61:[loss]:9282.045914736627\n",
      "iter61:[val_loss]:2096646.4211659464\n",
      "iter62:[loss]:7360.571910439265\n",
      "iter62:[val_loss]:2066673.183350109\n",
      "iter63:[loss]:5836.86175940371\n",
      "iter63:[val_loss]:2040172.780765621\n",
      "iter64:[loss]:4628.574465804586\n",
      "iter64:[val_loss]:2016726.3999335303\n",
      "iter65:[loss]:3670.414422781776\n",
      "iter65:[val_loss]:1995968.9911541264\n",
      "iter66:[loss]:2910.6028507248834\n",
      "iter66:[val_loss]:1977581.749973838\n",
      "iter67:[loss]:2308.0796822472375\n",
      "iter67:[val_loss]:1961285.7595512765\n",
      "iter68:[loss]:1830.284684244975\n",
      "iter68:[val_loss]:1946836.596863028\n",
      "iter69:[loss]:1451.3979093312735\n",
      "iter69:[val_loss]:1934019.741762101\n",
      "iter70:[loss]:1150.944390970187\n",
      "iter70:[val_loss]:1922646.6570189102\n",
      "iter71:[loss]:912.6876803310605\n",
      "iter71:[val_loss]:1912551.431024064\n",
      "iter72:[loss]:723.7524317972843\n",
      "iter72:[val_loss]:1903587.8939138066\n",
      "iter73:[loss]:573.9286218288838\n",
      "iter73:[val_loss]:1895627.1333752011\n",
      "iter74:[loss]:455.1198013059155\n",
      "iter74:[val_loss]:1888555.34900161\n",
      "iter75:[loss]:360.9055650171893\n",
      "iter75:[val_loss]:1882271.9943599615\n",
      "iter76:[loss]:286.1945942292742\n",
      "iter76:[val_loss]:1876688.1643502146\n",
      "iter77:[loss]:226.9495228263599\n",
      "iter77:[val_loss]:1871725.1923434725\n",
      "iter78:[loss]:179.96875884344013\n",
      "iter78:[val_loss]:1867313.4272665048\n",
      "iter79:[loss]:142.7134710671966\n",
      "iter79:[val_loss]:1863391.165487581\n",
      "iter80:[loss]:113.17039109990414\n",
      "iter80:[val_loss]:1859903.7162391173\n",
      "iter81:[loss]:89.7430167310412\n",
      "iter81:[val_loss]:1856802.5825333192\n",
      "iter82:[loss]:71.16533727326926\n",
      "iter82:[val_loss]:1854044.7422116576\n",
      "iter83:[loss]:56.43341859556367\n",
      "iter83:[val_loss]:1851592.0160118316\n",
      "iter84:[loss]:44.75115072039177\n",
      "iter84:[val_loss]:1849410.5114168492\n",
      "iter85:[loss]:35.487226197459414\n",
      "iter85:[val_loss]:1847470.1326344516\n",
      "iter86:[loss]:28.141024374186152\n",
      "iter86:[val_loss]:1845744.148391684\n",
      "iter87:[loss]:22.31555795380171\n",
      "iter87:[val_loss]:1844208.8103612834\n",
      "iter88:[loss]:17.69601988064972\n",
      "iter88:[val_loss]:1842843.0159998338\n",
      "iter89:[loss]:14.032771229172047\n",
      "iter89:[val_loss]:1841628.0103975711\n",
      "iter90:[loss]:11.127850765275145\n",
      "iter90:[val_loss]:1840547.1224416734\n",
      "iter91:[loss]:8.824277160297353\n",
      "iter91:[val_loss]:1839585.531197585\n",
      "iter92:[loss]:6.997565751434756\n",
      "iter92:[val_loss]:1838730.0589306725\n",
      "iter93:[loss]:5.5490014146166375\n",
      "iter93:[val_loss]:1837968.987637\n",
      "iter94:[loss]:4.400304019049615\n",
      "iter94:[val_loss]:1837291.8963397595\n",
      "iter95:[loss]:3.4893981841545347\n",
      "iter95:[val_loss]:1836689.5167418958\n",
      "iter96:[loss]:2.7670587384171315\n",
      "iter96:[val_loss]:1836153.605117892\n",
      "iter97:[loss]:2.1942506007511016\n",
      "iter97:[val_loss]:1835676.828580575\n",
      "iter98:[loss]:1.7400193324764666\n",
      "iter98:[val_loss]:1835252.6640810007\n",
      "iter99:[loss]:1.3798183654463374\n",
      "iter99:[val_loss]:1834875.3086924301\n",
      "iter100:[loss]:1.094182510568243\n",
      "iter100:[val_loss]:1834539.5998999502\n",
      "iter101:[loss]:0.867676062587555\n",
      "iter101:[val_loss]:1834240.9447646313\n",
      "iter102:[loss]:0.6880586577802849\n",
      "iter102:[val_loss]:1833975.2569635718\n",
      "iter103:[loss]:0.5456238070575088\n",
      "iter103:[val_loss]:1833738.9008206646\n",
      "iter104:[loss]:0.4326743591574854\n",
      "iter104:[val_loss]:1833528.6415448338\n",
      "iter105:[loss]:0.3431065482460627\n",
      "iter105:[val_loss]:1833341.6009821885\n",
      "iter106:[loss]:0.2720801474699669\n",
      "iter106:[val_loss]:1833175.2182659318\n",
      "iter107:[loss]:0.21575690416336998\n",
      "iter107:[val_loss]:1833027.2148193985\n",
      "iter108:[loss]:0.17109312136572585\n",
      "iter108:[val_loss]:1832895.5632271948\n",
      "iter109:[loss]:0.13567517709252203\n",
      "iter109:[val_loss]:1832778.4595454535\n",
      "iter110:[loss]:0.10758909260387925\n",
      "iter110:[val_loss]:1832674.2986689943\n",
      "iter111:[loss]:0.08531710144196794\n",
      "iter111:[val_loss]:1832581.652417422\n",
      "iter112:[loss]:0.06765562959909738\n",
      "iter112:[val_loss]:1832499.2500383572\n",
      "iter113:[loss]:0.05365025462524535\n",
      "iter113:[val_loss]:1832425.9608610012\n",
      "iter114:[loss]:0.04254412882975955\n",
      "iter114:[val_loss]:1832360.7788619185\n",
      "iter115:[loss]:0.03373707935832257\n",
      "iter115:[val_loss]:1832302.8089319242\n",
      "iter116:[loss]:0.026753174995890316\n",
      "iter116:[val_loss]:1832251.2546565114\n",
      "iter117:[loss]:0.021215006925766215\n",
      "iter117:[val_loss]:1832205.4074423756\n",
      "iter118:[loss]:0.016823293644472985\n",
      "iter118:[val_loss]:1832164.6368419745\n",
      "iter119:[loss]:0.013340707834151654\n",
      "iter119:[val_loss]:1832128.3819435951\n",
      "iter120:[loss]:0.010579051239268706\n",
      "iter120:[val_loss]:1832096.1437097443\n",
      "iter121:[loss]:0.00838908448566003\n",
      "iter121:[val_loss]:1832067.4781595601\n",
      "iter122:[loss]:0.0066524622048601345\n",
      "iter122:[val_loss]:1832041.9903017774\n",
      "iter123:[loss]:0.005275337667472808\n",
      "iter123:[val_loss]:1832019.3287357334\n",
      "iter124:[loss]:0.004183291336554695\n",
      "iter124:[val_loss]:1831999.180847303\n",
      "iter125:[loss]:0.0033173092437507852\n",
      "iter125:[val_loss]:1831981.268533524\n",
      "iter126:[loss]:0.0026305938858917147\n",
      "iter126:[val_loss]:1831965.3443981921\n",
      "iter127:[loss]:0.0020860353029162814\n",
      "iter127:[val_loss]:1831951.1883665563\n",
      "iter128:[loss]:0.001654205657029756\n",
      "iter128:[val_loss]:1831938.6046726385\n",
      "iter129:[loss]:0.0013117689570799921\n",
      "iter129:[val_loss]:1831927.419178402\n",
      "iter130:[loss]:0.0010402199925599528\n",
      "iter130:[val_loss]:1831917.4769885181\n",
      "iter131:[loss]:0.0008248843118129582\n",
      "iter131:[val_loss]:1831908.6403275742\n",
      "iter132:[loss]:0.0006541252170211216\n",
      "iter132:[val_loss]:1831900.7866512125\n",
      "iter133:[loss]:0.0005187149191063204\n",
      "iter133:[val_loss]:1831893.8069654205\n",
      "iter134:[loss]:0.00041133587363973584\n",
      "iter134:[val_loss]:1831887.6043312072\n",
      "iter135:[loss]:0.00032618533710788994\n",
      "iter135:[val_loss]:1831882.0925336676\n",
      "iter136:[loss]:0.00025866179223786253\n",
      "iter136:[val_loss]:1831877.1948982186\n",
      "iter137:[loss]:0.0002051162793246229\n",
      "iter137:[val_loss]:1831872.8432368813\n",
      "iter138:[loss]:0.0001626552098316792\n",
      "iter138:[val_loss]:1831868.9769111238\n",
      "iter139:[loss]:0.00012898399562624884\n",
      "iter139:[val_loss]:1831865.541997721\n",
      "iter140:[loss]:0.00010228305079772468\n",
      "iter140:[val_loss]:1831862.4905468202\n",
      "iter141:[loss]:8.110946191819228e-05\n",
      "iter141:[val_loss]:1831859.7799218288\n",
      "iter142:[loss]:6.431901249855118e-05\n",
      "iter142:[val_loss]:1831857.3722119941\n",
      "iter143:[loss]:5.1004349876458326e-05\n",
      "iter143:[val_loss]:1831855.2337098485\n",
      "iter144:[loss]:4.0445952284304746e-05\n",
      "iter144:[val_loss]:1831853.3344464216\n",
      "iter145:[loss]:3.2073245890458815e-05\n",
      "iter145:[val_loss]:1831851.6477776\n",
      "iter146:[loss]:2.5433771179451822e-05\n",
      "iter146:[val_loss]:1831850.1500162713\n",
      "iter147:[loss]:2.0168732550003348e-05\n",
      "iter147:[val_loss]:1831848.8201051517\n",
      "iter148:[loss]:1.5993608278293807e-05\n",
      "iter148:[val_loss]:1831847.6393254695\n",
      "iter149:[loss]:1.2682775421932092e-05\n",
      "iter149:[val_loss]:1831846.5910380683\n",
      "iter150:[loss]:1.005731727137704e-05\n",
      "iter150:[val_loss]:1831845.660453094\n",
      "iter151:[loss]:7.975354481874071e-06\n",
      "iter151:[val_loss]:1831844.834424983\n",
      "iter152:[loss]:6.3243783486799334e-06\n",
      "iter152:[val_loss]:1831844.1012704028\n",
      "iter153:[loss]:5.015170361446292e-06\n",
      "iter153:[val_loss]:1831843.4506059247\n",
      "iter154:[loss]:3.9769811742724286e-06\n",
      "iter154:[val_loss]:1831842.873203988\n",
      "iter155:[loss]:3.1537072789051033e-06\n",
      "iter155:[val_loss]:1831842.3608646481\n",
      "iter156:[loss]:2.5008591120288033e-06\n",
      "iter156:[val_loss]:1831841.9063015224\n",
      "iter157:[loss]:1.983156906263605e-06\n",
      "iter157:[val_loss]:1831841.5030403994\n",
      "iter158:[loss]:1.572624069504935e-06\n",
      "iter158:[val_loss]:1831841.1453289306\n",
      "iter159:[loss]:1.2470755374321223e-06\n",
      "iter159:[val_loss]:1831840.828056649\n",
      "iter160:[loss]:9.889187472244018e-07\n",
      "iter160:[val_loss]:1831840.5466834956\n",
      "iter161:[loss]:7.842029263635264e-07\n",
      "iter161:[val_loss]:1831840.2971763557\n",
      "iter162:[loss]:6.218652708191167e-07\n",
      "iter162:[val_loss]:1831840.0759527872\n",
      "iter163:[loss]:4.931331015802742e-07\n",
      "iter163:[val_loss]:1831839.8798308715\n",
      "iter164:[loss]:3.9104974376108607e-07\n",
      "iter164:[val_loss]:1831839.7059845407\n",
      "iter165:[loss]:3.1009863413807884e-07\n",
      "iter165:[val_loss]:1831839.5519040364\n",
      "iter166:[loss]:2.459051972908614e-07\n",
      "iter166:[val_loss]:1831839.4153606566\n",
      "iter167:[loss]:1.9500041864652293e-07\n",
      "iter167:[val_loss]:1831839.2943753605\n",
      "iter168:[loss]:1.5463343393948857e-07\n",
      "iter168:[val_loss]:1831839.1871910996\n",
      "iter169:[loss]:1.226228109667354e-07\n",
      "iter169:[val_loss]:1831839.092247844\n",
      "iter170:[loss]:9.723869222288421e-08\n",
      "iter170:[val_loss]:1831839.0081606936\n",
      "iter171:[loss]:7.710933756163689e-08\n",
      "iter171:[val_loss]:1831838.9337003776\n",
      "iter172:[loss]:6.114695116045317e-08\n",
      "iter172:[val_loss]:1831838.8677757466\n",
      "iter173:[loss]:4.848893499607839e-08\n",
      "iter173:[val_loss]:1831838.8094184333\n",
      "iter174:[loss]:3.8451255792435185e-08\n",
      "iter174:[val_loss]:1831838.7577691057\n",
      "iter175:[loss]:3.04914713519244e-08\n",
      "iter175:[val_loss]:1831838.7120651584\n",
      "iter176:[loss]:2.4179441449614657e-08\n",
      "iter176:[val_loss]:1831838.6716300347\n",
      "iter177:[loss]:1.9174063121419603e-08\n",
      "iter177:[val_loss]:1831838.6358634839\n",
      "iter178:[loss]:1.520484514912444e-08\n",
      "iter178:[val_loss]:1831838.6042330228\n",
      "iter179:[loss]:1.2057293598178657e-08\n",
      "iter179:[val_loss]:1831838.5762663924\n",
      "iter180:[loss]:9.561315818382412e-09\n",
      "iter180:[val_loss]:1831838.5515447345\n",
      "iter181:[loss]:7.582029451780956e-09\n",
      "iter181:[val_loss]:1831838.5296966096\n",
      "iter182:[loss]:6.01247562548463e-09\n",
      "iter182:[val_loss]:1831838.5103927017\n",
      "iter183:[loss]:4.767833313406164e-09\n",
      "iter183:[val_loss]:1831838.4933409805\n",
      "iter184:[loss]:3.78084616260265e-09\n",
      "iter184:[val_loss]:1831838.4782826896\n",
      "iter185:[loss]:2.998174089399515e-09\n",
      "iter185:[val_loss]:1831838.464988357\n",
      "iter186:[loss]:2.377522604951073e-09\n",
      "iter186:[val_loss]:1831838.4532546855\n",
      "iter187:[loss]:1.885351445258655e-09\n",
      "iter187:[val_loss]:1831838.4429015187\n",
      "iter188:[loss]:1.495064703107572e-09\n",
      "iter188:[val_loss]:1831838.4337692652\n",
      "iter189:[loss]:1.185572261815572e-09\n",
      "iter189:[val_loss]:1831838.4257165834\n",
      "iter190:[loss]:9.401477335885772e-10\n",
      "iter190:[val_loss]:1831838.4186182008\n",
      "iter191:[loss]:7.455282114064431e-10\n",
      "iter191:[val_loss]:1831838.4123632123\n",
      "iter192:[loss]:5.911963575026594e-10\n",
      "iter192:[val_loss]:1831838.4068534153\n",
      "iter193:[loss]:4.688132301571317e-10\n",
      "iter193:[val_loss]:1831838.4020019588\n",
      "iter194:[loss]:3.717643328221964e-10\n",
      "iter194:[val_loss]:1831838.3977318439\n",
      "iter195:[loss]:2.948054102635146e-10\n",
      "iter195:[val_loss]:1831838.393975007\n",
      "iter196:[loss]:2.3377782203681857e-10\n",
      "iter196:[val_loss]:1831838.3906712318\n",
      "iter197:[loss]:1.853837077527083e-10\n",
      "iter197:[val_loss]:1831838.387767232\n",
      "iter198:[loss]:1.4700751072932012e-10\n",
      "iter198:[val_loss]:1831838.3852158526\n",
      "iter199:[loss]:1.1657560434580027e-10\n",
      "iter199:[val_loss]:1831838.382975443\n",
      "iter200:[loss]:9.244335476509479e-11\n",
      "iter200:[val_loss]:1831838.3810091615\n",
      "iter201:[loss]:7.330678393524628e-11\n",
      "iter201:[val_loss]:1831838.3792844645\n",
      "iter202:[loss]:5.8131437575627905e-11\n",
      "iter202:[val_loss]:1831838.3777725294\n",
      "iter203:[loss]:4.6097702002137344e-11\n",
      "iter203:[val_loss]:1831838.3764480134\n",
      "iter204:[loss]:3.6554998675289956e-11\n",
      "iter204:[val_loss]:1831838.3752884273\n",
      "iter205:[loss]:2.8987776699606004e-11\n",
      "iter205:[val_loss]:1831838.3742739744\n",
      "iter206:[loss]:2.2987116952076932e-11\n",
      "iter206:[val_loss]:1831838.373387183\n",
      "iter207:[loss]:1.822849896275772e-11\n",
      "iter207:[val_loss]:1831838.3726125334\n",
      "iter208:[loss]:1.4455044829385554e-11\n",
      "iter208:[val_loss]:1831838.3719364991\n",
      "iter209:[loss]:1.1462664684395052e-11\n",
      "iter209:[val_loss]:1831838.3713470092\n",
      "iter210:[loss]:9.089838100176393e-12\n",
      "iter210:[val_loss]:1831838.370833554\n",
      "iter211:[loss]:7.2081508109472424e-12\n",
      "iter211:[val_loss]:1831838.3703867232\n",
      "iter212:[loss]:5.7160262665539844e-12\n",
      "iter212:[val_loss]:1831838.3699983498\n",
      "iter213:[loss]:4.532764110850013e-12\n",
      "iter213:[val_loss]:1831838.369661162\n",
      "iter214:[loss]:3.5944559924696427e-12\n",
      "iter214:[val_loss]:1831838.3693688053\n",
      "iter215:[loss]:2.8503526774703597e-12\n",
      "iter215:[val_loss]:1831838.3691156516\n",
      "iter216:[loss]:2.260308917375685e-12\n",
      "iter216:[val_loss]:1831838.368896808\n",
      "iter217:[loss]:1.792378020414869e-12\n",
      "iter217:[val_loss]:1831838.368707888\n",
      "iter218:[loss]:1.42131331752582e-12\n",
      "iter218:[val_loss]:1831838.3685451143\n",
      "iter219:[loss]:1.1271029055053306e-12\n",
      "iter219:[val_loss]:1831838.368405197\n",
      "iter220:[loss]:8.93777664082824e-13\n",
      "iter220:[val_loss]:1831838.368285113\n",
      "iter221:[loss]:7.087682486201239e-13\n",
      "iter221:[val_loss]:1831838.3681823474\n",
      "iter222:[loss]:5.620312633450416e-13\n",
      "iter222:[val_loss]:1831838.3680945681\n",
      "iter223:[loss]:4.4568436805242923e-13\n",
      "iter223:[val_loss]:1831838.3680198696\n",
      "iter224:[loss]:3.5342721344123137e-13\n",
      "iter224:[val_loss]:1831838.3679564972\n",
      "iter225:[loss]:2.802691578433666e-13\n",
      "iter225:[val_loss]:1831838.3679029318\n",
      "iter226:[loss]:2.2224786253025423e-13\n",
      "iter226:[val_loss]:1831838.3678578227\n",
      "iter227:[loss]:1.7624708088627384e-13\n",
      "iter227:[val_loss]:1831838.367820063\n",
      "iter228:[loss]:1.397587665338113e-13\n",
      "iter228:[val_loss]:1831838.367788573\n",
      "iter229:[loss]:1.1082999291578044e-13\n",
      "iter229:[val_loss]:1831838.3677625312\n",
      "iter230:[loss]:8.789092268285254e-14\n",
      "iter230:[val_loss]:1831838.367741155\n",
      "iter231:[loss]:6.970217566243989e-14\n",
      "iter231:[val_loss]:1831838.3677237763\n",
      "iter232:[loss]:5.527042568850873e-14\n",
      "iter232:[val_loss]:1831838.3677097529\n",
      "iter233:[loss]:4.3828155289020977e-14\n",
      "iter233:[val_loss]:1831838.3676986408\n",
      "iter234:[loss]:3.475445037876393e-14\n",
      "iter234:[val_loss]:1831838.3676899958\n",
      "iter235:[loss]:2.755986063366322e-14\n",
      "iter235:[val_loss]:1831838.3676834407\n",
      "iter236:[loss]:2.1856512800659545e-14\n",
      "iter236:[val_loss]:1831838.367678655\n",
      "iter237:[loss]:1.7329931447595633e-14\n",
      "iter237:[val_loss]:1831838.3676753026\n",
      "iter238:[loss]:1.3744622310951552e-14\n",
      "iter238:[val_loss]:1831838.3676732227\n",
      "iter239:[loss]:1.0898429314543692e-14\n",
      "iter239:[val_loss]:1831838.3676721165\n",
      "iter240:[loss]:8.644305443341457e-15\n",
      "iter240:[val_loss]:1831838.3676718944\n",
      "iter241:[loss]:6.853664683733685e-15\n",
      "iter241:[val_loss]:1831838.367672297\n",
      "iter242:[loss]:5.436367367719487e-15\n",
      "iter242:[val_loss]:1831838.3676733032\n",
      "iter243:[loss]:4.312011552725935e-15\n",
      "iter243:[val_loss]:1831838.3676747316\n",
      "iter244:[loss]:3.4202129004380054e-15\n",
      "iter244:[val_loss]:1831838.3676764986\n",
      "iter245:[loss]:2.7125895156461546e-15\n",
      "iter245:[val_loss]:1831838.3676785165\n",
      "iter246:[loss]:2.151316085806166e-15\n",
      "iter246:[val_loss]:1831838.367680717\n",
      "iter247:[loss]:1.7057324212528927e-15\n",
      "iter247:[val_loss]:1831838.3676830411\n",
      "iter248:[loss]:1.3522107747245556e-15\n",
      "iter248:[val_loss]:1831838.367685442\n",
      "iter249:[loss]:1.0717918440782938e-15\n",
      "iter249:[val_loss]:1831838.3676878884\n",
      "iter250:[loss]:8.502173315238653e-16\n",
      "iter250:[val_loss]:1831838.3676903879\n",
      "iter251:[loss]:6.742981725089959e-16\n",
      "iter251:[val_loss]:1831838.367692862\n",
      "iter252:[loss]:5.348901466608467e-16\n",
      "iter252:[val_loss]:1831838.367695307\n",
      "iter253:[loss]:4.2419746770077785e-16\n",
      "iter253:[val_loss]:1831838.367697696\n",
      "iter254:[loss]:3.361520730183311e-16\n",
      "iter254:[val_loss]:1831838.3676999938\n",
      "iter255:[loss]:2.6619113537553673e-16\n",
      "iter255:[val_loss]:1831838.3677022113\n",
      "iter256:[loss]:2.110095783494631e-16\n",
      "iter256:[val_loss]:1831838.3677043673\n",
      "iter257:[loss]:1.6745394133821365e-16\n",
      "iter257:[val_loss]:1831838.3677064653\n",
      "iter258:[loss]:1.3270042969624269e-16\n",
      "iter258:[val_loss]:1831838.367708439\n",
      "iter259:[loss]:1.0538462763299599e-16\n",
      "iter259:[val_loss]:1831838.3677103526\n",
      "iter260:[loss]:8.339695006554838e-17\n",
      "iter260:[val_loss]:1831838.3677121217\n",
      "iter261:[loss]:6.602875154887116e-17\n",
      "iter261:[val_loss]:1831838.3677138113\n",
      "iter262:[loss]:5.2417675921331645e-17\n",
      "iter262:[val_loss]:1831838.367715439\n",
      "iter263:[loss]:4.1452029242437464e-17\n",
      "iter263:[val_loss]:1831838.3677169352\n",
      "iter264:[loss]:3.2921855007579584e-17\n",
      "iter264:[val_loss]:1831838.3677183853\n",
      "iter265:[loss]:2.6008836650657532e-17\n",
      "iter265:[val_loss]:1831838.3677197087\n",
      "iter266:[loss]:2.0650279046795643e-17\n",
      "iter266:[val_loss]:1831838.3677209858\n",
      "iter267:[loss]:1.6405939486153844e-17\n",
      "iter267:[val_loss]:1831838.367722186\n",
      "iter268:[loss]:1.2947324468036601e-17\n",
      "iter268:[val_loss]:1831838.367723274\n",
      "iter269:[loss]:1.0278719734377382e-17\n",
      "iter269:[val_loss]:1831838.367724319\n",
      "iter270:[loss]:8.158157565051256e-18\n",
      "iter270:[val_loss]:1831838.3677252934\n",
      "iter271:[loss]:6.49205327983628e-18\n",
      "iter271:[val_loss]:1831838.3677262142\n",
      "iter272:[loss]:5.1124736635418236e-18\n",
      "iter272:[val_loss]:1831838.3677270347\n",
      "iter273:[loss]:4.050942960766828e-18\n",
      "iter273:[val_loss]:1831838.3677278198\n",
      "iter274:[loss]:3.1931580537433283e-18\n",
      "iter274:[val_loss]:1831838.3677285353\n",
      "iter275:[loss]:2.496576208742574e-18\n",
      "iter275:[val_loss]:1831838.3677291903\n",
      "iter276:[loss]:2.00660619360297e-18\n",
      "iter276:[val_loss]:1831838.36772985\n",
      "iter277:[loss]:1.567093309998535e-18\n",
      "iter277:[val_loss]:1831838.3677304105\n",
      "iter278:[loss]:1.2268836621511256e-18\n",
      "iter278:[val_loss]:1831838.3677309393\n",
      "iter279:[loss]:9.66891049825504e-19\n",
      "iter279:[val_loss]:1831838.3677314403\n",
      "iter280:[loss]:7.772055665410479e-19\n",
      "iter280:[val_loss]:1831838.367731927\n",
      "iter281:[loss]:6.083286392730421e-19\n",
      "iter281:[val_loss]:1831838.3677323477\n",
      "iter282:[loss]:4.846006870447763e-19\n",
      "iter282:[val_loss]:1831838.3677327547\n",
      "iter283:[loss]:3.763070629065845e-19\n",
      "iter283:[val_loss]:1831838.3677331102\n",
      "iter284:[loss]:3.0472571769487636e-19\n",
      "iter284:[val_loss]:1831838.367733471\n",
      "iter285:[loss]:2.4091031161030142e-19\n",
      "iter285:[val_loss]:1831838.3677337843\n",
      "iter286:[loss]:1.8361652480168285e-19\n",
      "iter286:[val_loss]:1831838.367734059\n",
      "iter287:[loss]:1.4977493115136402e-19\n",
      "iter287:[val_loss]:1831838.3677343444\n",
      "iter288:[loss]:1.205229933230164e-19\n",
      "iter288:[val_loss]:1831838.3677346017\n",
      "iter289:[loss]:9.278994675984886e-20\n",
      "iter289:[val_loss]:1831838.3677348185\n",
      "iter290:[loss]:6.962677584515889e-20\n",
      "iter290:[val_loss]:1831838.3677350124\n",
      "iter291:[loss]:5.874245845789648e-20\n",
      "iter291:[val_loss]:1831838.3677352283\n",
      "iter292:[loss]:4.971693483712751e-20\n",
      "iter292:[val_loss]:1831838.3677354285\n",
      "iter293:[loss]:4.074277750118227e-20\n",
      "iter293:[val_loss]:1831838.3677356036\n",
      "iter294:[loss]:3.320681962551962e-20\n",
      "iter294:[val_loss]:1831838.3677357568\n",
      "iter295:[loss]:2.5881509294607158e-20\n",
      "iter295:[val_loss]:1831838.367735889\n",
      "iter296:[loss]:1.988967653402423e-20\n",
      "iter296:[val_loss]:1831838.3677360117\n",
      "iter297:[loss]:1.4197784672819565e-20\n",
      "iter297:[val_loss]:1831838.367736115\n",
      "iter298:[loss]:9.936858379876996e-21\n",
      "iter298:[val_loss]:1831838.3677362015\n",
      "iter299:[loss]:6.089151214171263e-21\n",
      "iter299:[val_loss]:1831838.367736278\n",
      "iter300:[loss]:6.1715554169454505e-21\n",
      "iter300:[val_loss]:1831838.3677363996\n",
      "iter301:[loss]:6.06570888284232e-21\n",
      "iter301:[val_loss]:1831838.3677365088\n",
      "iter302:[loss]:6.302166728262524e-21\n",
      "iter302:[val_loss]:1831838.3677366092\n",
      "iter303:[loss]:6.1715554169454505e-21\n",
      "iter303:[val_loss]:1831838.3677366986\n",
      "iter304:[loss]:6.124399483336794e-21\n",
      "iter304:[val_loss]:1831838.3677367843\n",
      "iter305:[loss]:6.054004671612271e-21\n",
      "iter305:[val_loss]:1831838.3677368548\n",
      "iter306:[loss]:6.290236457906834e-21\n",
      "iter306:[val_loss]:1831838.3677369284\n",
      "iter307:[loss]:6.124399483336794e-21\n",
      "iter307:[val_loss]:1831838.3677369906\n",
      "iter308:[loss]:6.159749479108863e-21\n",
      "iter308:[val_loss]:1831838.367737048\n",
      "iter309:[loss]:6.18337265773832e-21\n",
      "iter309:[val_loss]:1831838.3677371033\n",
      "iter310:[loss]:6.1715554169454505e-21\n",
      "iter310:[val_loss]:1831838.3677371512\n",
      "iter311:[loss]:6.07742439702865e-21\n",
      "iter311:[val_loss]:1831838.367737192\n",
      "iter312:[loss]:6.230754650472616e-21\n",
      "iter312:[val_loss]:1831838.367737232\n",
      "iter313:[loss]:6.06570888284232e-21\n",
      "iter313:[val_loss]:1831838.3677372686\n",
      "iter314:[loss]:6.147954844228559e-21\n",
      "iter314:[val_loss]:1831838.367737303\n",
      "iter315:[loss]:6.100889334270158e-21\n",
      "iter315:[val_loss]:1831838.3677373286\n",
      "iter316:[loss]:6.18337265773832e-21\n",
      "iter316:[val_loss]:1831838.3677373591\n",
      "iter317:[loss]:6.18337265773832e-21\n",
      "iter317:[val_loss]:1831838.3677373836\n",
      "iter318:[loss]:5.9260043431963484e-21\n",
      "iter318:[val_loss]:1831838.3677374062\n",
      "iter319:[loss]:6.18337265773832e-21\n",
      "iter319:[val_loss]:1831838.3677374276\n",
      "iter320:[loss]:6.159749479108863e-21\n",
      "iter320:[val_loss]:1831838.3677374457\n",
      "iter321:[loss]:6.124399483336794e-21\n",
      "iter321:[val_loss]:1831838.3677374648\n",
      "iter322:[loss]:6.19520120148747e-21\n",
      "iter322:[val_loss]:1831838.3677374823\n",
      "iter323:[loss]:6.230754650472616e-21\n",
      "iter323:[val_loss]:1831838.3677374972\n",
      "iter324:[loss]:5.891332524801201e-21\n",
      "iter324:[val_loss]:1831838.3677375063\n",
      "iter325:[loss]:6.1361715123045355e-21\n",
      "iter325:[val_loss]:1831838.3677375198\n",
      "iter326:[loss]:6.054004671612271e-21\n",
      "iter326:[val_loss]:1831838.3677375277\n",
      "iter327:[loss]:6.1361715123045355e-21\n",
      "iter327:[val_loss]:1831838.367737541\n",
      "iter328:[loss]:6.207041048192904e-21\n",
      "iter328:[val_loss]:1831838.3677375503\n",
      "iter329:[loss]:6.1361715123045355e-21\n",
      "iter329:[val_loss]:1831838.3677375575\n",
      "iter330:[loss]:6.06570888284232e-21\n",
      "iter330:[val_loss]:1831838.3677375654\n",
      "iter331:[loss]:6.1126387573253344e-21\n",
      "iter331:[val_loss]:1831838.3677375724\n",
      "iter332:[loss]:6.1126387573253344e-21\n",
      "iter332:[val_loss]:1831838.3677375773\n",
      "iter333:[loss]:6.350000839248101e-21\n",
      "iter333:[val_loss]:1831838.3677375875\n",
      "iter334:[loss]:6.207041048192904e-21\n",
      "iter334:[val_loss]:1831838.3677375899\n",
      "iter335:[loss]:6.007300856254896e-21\n",
      "iter335:[val_loss]:1831838.3677375924\n",
      "iter336:[loss]:5.995653159806257e-21\n",
      "iter336:[val_loss]:1831838.3677375938\n",
      "iter337:[loss]:6.124399483336794e-21\n",
      "iter337:[val_loss]:1831838.3677375985\n",
      "iter338:[loss]:5.960777888198033e-21\n",
      "iter338:[val_loss]:1831838.3677376034\n",
      "iter339:[loss]:6.159749479108863e-21\n",
      "iter339:[val_loss]:1831838.367737608\n",
      "iter340:[loss]:6.302166728262524e-21\n",
      "iter340:[val_loss]:1831838.3677376155\n",
      "iter341:[loss]:6.230754650472616e-21\n",
      "iter341:[val_loss]:1831838.3677376173\n",
      "iter342:[loss]:6.2426284060468956e-21\n",
      "iter342:[val_loss]:1831838.3677376169\n",
      "iter343:[loss]:6.1715554169454505e-21\n",
      "iter343:[val_loss]:1831838.3677376185\n",
      "iter344:[loss]:5.995653159806257e-21\n",
      "iter344:[val_loss]:1831838.3677376204\n",
      "iter345:[loss]:6.18337265773832e-21\n",
      "iter345:[val_loss]:1831838.367737623\n",
      "iter346:[loss]:6.302166728262524e-21\n",
      "iter346:[val_loss]:1831838.3677376276\n",
      "iter347:[loss]:6.1715554169454505e-21\n",
      "iter347:[val_loss]:1831838.3677376255\n",
      "iter348:[loss]:6.1361715123045355e-21\n",
      "iter348:[val_loss]:1831838.3677376264\n",
      "iter349:[loss]:6.159749479108863e-21\n",
      "iter349:[val_loss]:1831838.3677376304\n",
      "iter350:[loss]:6.159749479108863e-21\n",
      "iter350:[val_loss]:1831838.367737629\n",
      "iter351:[loss]:6.1126387573253344e-21\n",
      "iter351:[val_loss]:1831838.3677376325\n",
      "iter352:[loss]:6.326061177842748e-21\n",
      "iter352:[val_loss]:1831838.3677376325\n",
      "iter353:[loss]:6.18337265773832e-21\n",
      "iter353:[val_loss]:1831838.3677376346\n",
      "iter354:[loss]:6.147954844228559e-21\n",
      "iter354:[val_loss]:1831838.3677376339\n",
      "iter355:[loss]:6.1715554169454505e-21\n",
      "iter355:[val_loss]:1831838.3677376364\n",
      "iter356:[loss]:6.03063015802102e-21\n",
      "iter356:[val_loss]:1831838.3677376334\n",
      "iter357:[loss]:6.100889334270158e-21\n",
      "iter357:[val_loss]:1831838.3677376364\n",
      "iter358:[loss]:6.207041048192904e-21\n",
      "iter358:[val_loss]:1831838.36773764\n",
      "iter359:[loss]:6.06570888284232e-21\n",
      "iter359:[val_loss]:1831838.3677376364\n",
      "iter360:[loss]:6.159749479108863e-21\n",
      "iter360:[val_loss]:1831838.3677376385\n",
      "iter361:[loss]:6.1715554169454505e-21\n",
      "iter361:[val_loss]:1831838.3677376376\n",
      "iter362:[loss]:6.089151214171263e-21\n",
      "iter362:[val_loss]:1831838.3677376385\n",
      "iter363:[loss]:6.007300856254896e-21\n",
      "iter363:[val_loss]:1831838.367737637\n",
      "iter364:[loss]:6.007300856254896e-21\n",
      "iter364:[val_loss]:1831838.367737637\n",
      "iter365:[loss]:6.007300856254896e-21\n",
      "iter365:[val_loss]:1831838.367737637\n",
      "iter366:[loss]:6.007300856254896e-21\n",
      "iter366:[val_loss]:1831838.367737637\n",
      "iter367:[loss]:6.007300856254896e-21\n",
      "iter367:[val_loss]:1831838.367737637\n",
      "iter368:[loss]:6.007300856254896e-21\n",
      "iter368:[val_loss]:1831838.367737637\n",
      "iter369:[loss]:6.007300856254896e-21\n",
      "iter369:[val_loss]:1831838.367737637\n",
      "iter370:[loss]:6.007300856254896e-21\n",
      "iter370:[val_loss]:1831838.367737637\n",
      "iter371:[loss]:6.007300856254896e-21\n",
      "iter371:[val_loss]:1831838.367737637\n",
      "iter372:[loss]:6.007300856254896e-21\n",
      "iter372:[val_loss]:1831838.367737637\n",
      "iter373:[loss]:6.007300856254896e-21\n",
      "iter373:[val_loss]:1831838.367737637\n",
      "iter374:[loss]:6.007300856254896e-21\n",
      "iter374:[val_loss]:1831838.367737637\n",
      "iter375:[loss]:6.007300856254896e-21\n",
      "iter375:[val_loss]:1831838.367737637\n",
      "iter376:[loss]:6.007300856254896e-21\n",
      "iter376:[val_loss]:1831838.367737637\n",
      "iter377:[loss]:6.007300856254896e-21\n",
      "iter377:[val_loss]:1831838.367737637\n",
      "iter378:[loss]:6.007300856254896e-21\n",
      "iter378:[val_loss]:1831838.367737637\n",
      "iter379:[loss]:6.007300856254896e-21\n",
      "iter379:[val_loss]:1831838.367737637\n",
      "iter380:[loss]:6.007300856254896e-21\n",
      "iter380:[val_loss]:1831838.367737637\n",
      "iter381:[loss]:6.007300856254896e-21\n",
      "iter381:[val_loss]:1831838.367737637\n",
      "iter382:[loss]:6.007300856254896e-21\n",
      "iter382:[val_loss]:1831838.367737637\n",
      "iter383:[loss]:6.007300856254896e-21\n",
      "iter383:[val_loss]:1831838.367737637\n",
      "iter384:[loss]:6.007300856254896e-21\n",
      "iter384:[val_loss]:1831838.367737637\n",
      "iter385:[loss]:6.007300856254896e-21\n",
      "iter385:[val_loss]:1831838.367737637\n",
      "iter386:[loss]:6.007300856254896e-21\n",
      "iter386:[val_loss]:1831838.367737637\n",
      "iter387:[loss]:6.007300856254896e-21\n",
      "iter387:[val_loss]:1831838.367737637\n",
      "iter388:[loss]:6.007300856254896e-21\n",
      "iter388:[val_loss]:1831838.367737637\n",
      "iter389:[loss]:6.007300856254896e-21\n",
      "iter389:[val_loss]:1831838.367737637\n",
      "iter390:[loss]:6.007300856254896e-21\n",
      "iter390:[val_loss]:1831838.367737637\n",
      "iter391:[loss]:6.007300856254896e-21\n",
      "iter391:[val_loss]:1831838.367737637\n",
      "iter392:[loss]:6.007300856254896e-21\n",
      "iter392:[val_loss]:1831838.367737637\n",
      "iter393:[loss]:6.007300856254896e-21\n",
      "iter393:[val_loss]:1831838.367737637\n",
      "iter394:[loss]:6.007300856254896e-21\n",
      "iter394:[val_loss]:1831838.367737637\n",
      "iter395:[loss]:6.007300856254896e-21\n",
      "iter395:[val_loss]:1831838.367737637\n",
      "iter396:[loss]:6.007300856254896e-21\n",
      "iter396:[val_loss]:1831838.367737637\n",
      "iter397:[loss]:6.007300856254896e-21\n",
      "iter397:[val_loss]:1831838.367737637\n",
      "iter398:[loss]:6.007300856254896e-21\n",
      "iter398:[val_loss]:1831838.367737637\n",
      "iter399:[loss]:6.007300856254896e-21\n",
      "iter399:[val_loss]:1831838.367737637\n",
      "iter400:[loss]:6.007300856254896e-21\n",
      "iter400:[val_loss]:1831838.367737637\n",
      "iter401:[loss]:6.007300856254896e-21\n",
      "iter401:[val_loss]:1831838.367737637\n",
      "iter402:[loss]:6.007300856254896e-21\n",
      "iter402:[val_loss]:1831838.367737637\n",
      "iter403:[loss]:6.007300856254896e-21\n",
      "iter403:[val_loss]:1831838.367737637\n",
      "iter404:[loss]:6.007300856254896e-21\n",
      "iter404:[val_loss]:1831838.367737637\n",
      "iter405:[loss]:6.007300856254896e-21\n",
      "iter405:[val_loss]:1831838.367737637\n",
      "iter406:[loss]:6.007300856254896e-21\n",
      "iter406:[val_loss]:1831838.367737637\n",
      "iter407:[loss]:6.007300856254896e-21\n",
      "iter407:[val_loss]:1831838.367737637\n",
      "iter408:[loss]:6.007300856254896e-21\n",
      "iter408:[val_loss]:1831838.367737637\n",
      "iter409:[loss]:6.007300856254896e-21\n",
      "iter409:[val_loss]:1831838.367737637\n",
      "iter410:[loss]:6.007300856254896e-21\n",
      "iter410:[val_loss]:1831838.367737637\n",
      "iter411:[loss]:6.007300856254896e-21\n",
      "iter411:[val_loss]:1831838.367737637\n",
      "iter412:[loss]:6.007300856254896e-21\n",
      "iter412:[val_loss]:1831838.367737637\n",
      "iter413:[loss]:6.007300856254896e-21\n",
      "iter413:[val_loss]:1831838.367737637\n",
      "iter414:[loss]:6.007300856254896e-21\n",
      "iter414:[val_loss]:1831838.367737637\n",
      "iter415:[loss]:6.007300856254896e-21\n",
      "iter415:[val_loss]:1831838.367737637\n",
      "iter416:[loss]:6.007300856254896e-21\n",
      "iter416:[val_loss]:1831838.367737637\n",
      "iter417:[loss]:6.007300856254896e-21\n",
      "iter417:[val_loss]:1831838.367737637\n",
      "iter418:[loss]:6.007300856254896e-21\n",
      "iter418:[val_loss]:1831838.367737637\n",
      "iter419:[loss]:6.007300856254896e-21\n",
      "iter419:[val_loss]:1831838.367737637\n",
      "iter420:[loss]:6.007300856254896e-21\n",
      "iter420:[val_loss]:1831838.367737637\n",
      "iter421:[loss]:6.007300856254896e-21\n",
      "iter421:[val_loss]:1831838.367737637\n",
      "iter422:[loss]:6.007300856254896e-21\n",
      "iter422:[val_loss]:1831838.367737637\n",
      "iter423:[loss]:6.007300856254896e-21\n",
      "iter423:[val_loss]:1831838.367737637\n",
      "iter424:[loss]:6.007300856254896e-21\n",
      "iter424:[val_loss]:1831838.367737637\n",
      "iter425:[loss]:6.007300856254896e-21\n",
      "iter425:[val_loss]:1831838.367737637\n",
      "iter426:[loss]:6.007300856254896e-21\n",
      "iter426:[val_loss]:1831838.367737637\n",
      "iter427:[loss]:6.007300856254896e-21\n",
      "iter427:[val_loss]:1831838.367737637\n",
      "iter428:[loss]:6.007300856254896e-21\n",
      "iter428:[val_loss]:1831838.367737637\n",
      "iter429:[loss]:6.007300856254896e-21\n",
      "iter429:[val_loss]:1831838.367737637\n",
      "iter430:[loss]:6.007300856254896e-21\n",
      "iter430:[val_loss]:1831838.367737637\n",
      "iter431:[loss]:6.007300856254896e-21\n",
      "iter431:[val_loss]:1831838.367737637\n",
      "iter432:[loss]:6.007300856254896e-21\n",
      "iter432:[val_loss]:1831838.367737637\n",
      "iter433:[loss]:6.007300856254896e-21\n",
      "iter433:[val_loss]:1831838.367737637\n",
      "iter434:[loss]:6.007300856254896e-21\n",
      "iter434:[val_loss]:1831838.367737637\n",
      "iter435:[loss]:6.007300856254896e-21\n",
      "iter435:[val_loss]:1831838.367737637\n",
      "iter436:[loss]:6.007300856254896e-21\n",
      "iter436:[val_loss]:1831838.367737637\n",
      "iter437:[loss]:6.007300856254896e-21\n",
      "iter437:[val_loss]:1831838.367737637\n",
      "iter438:[loss]:6.007300856254896e-21\n",
      "iter438:[val_loss]:1831838.367737637\n",
      "iter439:[loss]:6.007300856254896e-21\n",
      "iter439:[val_loss]:1831838.367737637\n",
      "iter440:[loss]:6.007300856254896e-21\n",
      "iter440:[val_loss]:1831838.367737637\n",
      "iter441:[loss]:6.007300856254896e-21\n",
      "iter441:[val_loss]:1831838.367737637\n",
      "iter442:[loss]:6.007300856254896e-21\n",
      "iter442:[val_loss]:1831838.367737637\n",
      "iter443:[loss]:6.007300856254896e-21\n",
      "iter443:[val_loss]:1831838.367737637\n",
      "iter444:[loss]:6.007300856254896e-21\n",
      "iter444:[val_loss]:1831838.367737637\n",
      "iter445:[loss]:6.007300856254896e-21\n",
      "iter445:[val_loss]:1831838.367737637\n",
      "iter446:[loss]:6.007300856254896e-21\n",
      "iter446:[val_loss]:1831838.367737637\n",
      "iter447:[loss]:6.007300856254896e-21\n",
      "iter447:[val_loss]:1831838.367737637\n",
      "iter448:[loss]:6.007300856254896e-21\n",
      "iter448:[val_loss]:1831838.367737637\n",
      "iter449:[loss]:6.007300856254896e-21\n",
      "iter449:[val_loss]:1831838.367737637\n",
      "iter450:[loss]:6.007300856254896e-21\n",
      "iter450:[val_loss]:1831838.367737637\n",
      "iter451:[loss]:6.007300856254896e-21\n",
      "iter451:[val_loss]:1831838.367737637\n",
      "iter452:[loss]:6.007300856254896e-21\n",
      "iter452:[val_loss]:1831838.367737637\n",
      "iter453:[loss]:6.007300856254896e-21\n",
      "iter453:[val_loss]:1831838.367737637\n",
      "iter454:[loss]:6.007300856254896e-21\n",
      "iter454:[val_loss]:1831838.367737637\n",
      "iter455:[loss]:6.007300856254896e-21\n",
      "iter455:[val_loss]:1831838.367737637\n",
      "iter456:[loss]:6.007300856254896e-21\n",
      "iter456:[val_loss]:1831838.367737637\n",
      "iter457:[loss]:6.007300856254896e-21\n",
      "iter457:[val_loss]:1831838.367737637\n",
      "iter458:[loss]:6.007300856254896e-21\n",
      "iter458:[val_loss]:1831838.367737637\n",
      "iter459:[loss]:6.007300856254896e-21\n",
      "iter459:[val_loss]:1831838.367737637\n",
      "iter460:[loss]:6.007300856254896e-21\n",
      "iter460:[val_loss]:1831838.367737637\n",
      "iter461:[loss]:6.007300856254896e-21\n",
      "iter461:[val_loss]:1831838.367737637\n",
      "iter462:[loss]:6.007300856254896e-21\n",
      "iter462:[val_loss]:1831838.367737637\n",
      "iter463:[loss]:6.007300856254896e-21\n",
      "iter463:[val_loss]:1831838.367737637\n",
      "iter464:[loss]:6.007300856254896e-21\n",
      "iter464:[val_loss]:1831838.367737637\n",
      "iter465:[loss]:6.007300856254896e-21\n",
      "iter465:[val_loss]:1831838.367737637\n",
      "iter466:[loss]:6.007300856254896e-21\n",
      "iter466:[val_loss]:1831838.367737637\n",
      "iter467:[loss]:6.007300856254896e-21\n",
      "iter467:[val_loss]:1831838.367737637\n",
      "iter468:[loss]:6.007300856254896e-21\n",
      "iter468:[val_loss]:1831838.367737637\n",
      "iter469:[loss]:6.007300856254896e-21\n",
      "iter469:[val_loss]:1831838.367737637\n",
      "iter470:[loss]:6.007300856254896e-21\n",
      "iter470:[val_loss]:1831838.367737637\n",
      "iter471:[loss]:6.007300856254896e-21\n",
      "iter471:[val_loss]:1831838.367737637\n",
      "iter472:[loss]:6.007300856254896e-21\n",
      "iter472:[val_loss]:1831838.367737637\n",
      "iter473:[loss]:6.007300856254896e-21\n",
      "iter473:[val_loss]:1831838.367737637\n",
      "iter474:[loss]:6.007300856254896e-21\n",
      "iter474:[val_loss]:1831838.367737637\n",
      "iter475:[loss]:6.007300856254896e-21\n",
      "iter475:[val_loss]:1831838.367737637\n",
      "iter476:[loss]:6.007300856254896e-21\n",
      "iter476:[val_loss]:1831838.367737637\n",
      "iter477:[loss]:6.007300856254896e-21\n",
      "iter477:[val_loss]:1831838.367737637\n",
      "iter478:[loss]:6.007300856254896e-21\n",
      "iter478:[val_loss]:1831838.367737637\n",
      "iter479:[loss]:6.007300856254896e-21\n",
      "iter479:[val_loss]:1831838.367737637\n",
      "iter480:[loss]:6.007300856254896e-21\n",
      "iter480:[val_loss]:1831838.367737637\n",
      "iter481:[loss]:6.007300856254896e-21\n",
      "iter481:[val_loss]:1831838.367737637\n",
      "iter482:[loss]:6.007300856254896e-21\n",
      "iter482:[val_loss]:1831838.367737637\n",
      "iter483:[loss]:6.007300856254896e-21\n",
      "iter483:[val_loss]:1831838.367737637\n",
      "iter484:[loss]:6.007300856254896e-21\n",
      "iter484:[val_loss]:1831838.367737637\n",
      "iter485:[loss]:6.007300856254896e-21\n",
      "iter485:[val_loss]:1831838.367737637\n",
      "iter486:[loss]:6.007300856254896e-21\n",
      "iter486:[val_loss]:1831838.367737637\n",
      "iter487:[loss]:6.007300856254896e-21\n",
      "iter487:[val_loss]:1831838.367737637\n",
      "iter488:[loss]:6.007300856254896e-21\n",
      "iter488:[val_loss]:1831838.367737637\n",
      "iter489:[loss]:6.007300856254896e-21\n",
      "iter489:[val_loss]:1831838.367737637\n",
      "iter490:[loss]:6.007300856254896e-21\n",
      "iter490:[val_loss]:1831838.367737637\n",
      "iter491:[loss]:6.007300856254896e-21\n",
      "iter491:[val_loss]:1831838.367737637\n",
      "iter492:[loss]:6.007300856254896e-21\n",
      "iter492:[val_loss]:1831838.367737637\n",
      "iter493:[loss]:6.007300856254896e-21\n",
      "iter493:[val_loss]:1831838.367737637\n",
      "iter494:[loss]:6.007300856254896e-21\n",
      "iter494:[val_loss]:1831838.367737637\n",
      "iter495:[loss]:6.007300856254896e-21\n",
      "iter495:[val_loss]:1831838.367737637\n",
      "iter496:[loss]:6.007300856254896e-21\n",
      "iter496:[val_loss]:1831838.367737637\n",
      "iter497:[loss]:6.007300856254896e-21\n",
      "iter497:[val_loss]:1831838.367737637\n",
      "iter498:[loss]:6.007300856254896e-21\n",
      "iter498:[val_loss]:1831838.367737637\n",
      "iter499:[loss]:6.007300856254896e-21\n",
      "iter499:[val_loss]:1831838.367737637\n"
     ]
    }
   ],
   "source": [
    "scr_lr = ScratchLinearRegression(num_iter=500, \n",
    "                                 lr=0.01, \n",
    "                                 no_bias = False,\n",
    "                                 verbose=True)\n",
    "\n",
    "scr_lr.fit(X_train_scaler, y_train, X_test_scaler, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題7】学習曲線のプロット\n",
    "学習曲線を表示する関数を作成し、実行してください。グラフを見て損失が適切に下がっているかどうか確認してください。\n",
    "\n",
    "\n",
    "線形回帰クラスの雛形ではself.loss, self.val_lossに損失を記録しておくようになっているため、入力にはこれを利用してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 描画\n",
    "x = np.arange(1, len(scr_lr.loss)+1)\n",
    "\n",
    "plt.plot(x, scr_lr.loss, label=\"train_loss\", linewidth=10)\n",
    "plt.plot(x, scr_lr.val_loss, label=\"val_loss\", linewidth=5)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lossもval_lossも収束し始めたが、val_lossは100ループくらいから値動きしなくなった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題8】（アドバンス課題）バイアス項の除去\n",
    "バイアス項 $\\theta_0$ を抜くと学習がどう変化するか検証してください。また、線形回帰モデルにおけるバイアス項の役割の考察・調査を行ってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter0:[loss]:16332235713.197973\n",
      "iter0:[val_loss]:16490121431.560722\n",
      "iter1:[loss]:16332235713.197968\n",
      "iter1:[val_loss]:16509477140.032347\n",
      "iter2:[loss]:16332235713.197968\n",
      "iter2:[val_loss]:16526788642.392958\n",
      "iter3:[loss]:16332235713.197964\n",
      "iter3:[val_loss]:16542279473.774931\n",
      "iter4:[loss]:16332235713.197964\n",
      "iter4:[val_loss]:16556147977.36653\n",
      "iter5:[loss]:16332235713.197964\n",
      "iter5:[val_loss]:16568570204.104736\n",
      "iter6:[loss]:16332235713.197964\n",
      "iter6:[val_loss]:16579702476.36492\n",
      "iter7:[loss]:16332235713.197964\n",
      "iter7:[val_loss]:16589683653.923973\n",
      "iter8:[loss]:16332235713.197958\n",
      "iter8:[val_loss]:16598637136.38181\n",
      "iter9:[loss]:16332235713.197958\n",
      "iter9:[val_loss]:16606672632.49497\n",
      "iter10:[loss]:16332235713.197958\n",
      "iter10:[val_loss]:16613887723.496357\n",
      "iter11:[loss]:16332235713.197964\n",
      "iter11:[val_loss]:16620369244.427399\n",
      "iter12:[loss]:16332235713.197952\n",
      "iter12:[val_loss]:16626194504.773878\n",
      "iter13:[loss]:16332235713.197958\n",
      "iter13:[val_loss]:16631432367.249641\n",
      "iter14:[loss]:16332235713.197952\n",
      "iter14:[val_loss]:16636144201.38983\n",
      "iter15:[loss]:16332235713.197958\n",
      "iter15:[val_loss]:16640384726.673225\n",
      "iter16:[loss]:16332235713.197952\n",
      "iter16:[val_loss]:16644202758.168943\n",
      "iter17:[loss]:16332235713.197958\n",
      "iter17:[val_loss]:16647641866.173721\n",
      "iter18:[loss]:16332235713.197958\n",
      "iter18:[val_loss]:16650740959.952806\n",
      "iter19:[loss]:16332235713.197952\n",
      "iter19:[val_loss]:16653534804.50137\n",
      "iter20:[loss]:16332235713.197958\n",
      "iter20:[val_loss]:16656054478.185932\n",
      "iter21:[loss]:16332235713.197952\n",
      "iter21:[val_loss]:16658327778.193068\n",
      "iter22:[loss]:16332235713.197958\n",
      "iter22:[val_loss]:16660379579.88999\n",
      "iter23:[loss]:16332235713.197952\n",
      "iter23:[val_loss]:16662232155.476671\n",
      "iter24:[loss]:16332235713.197952\n",
      "iter24:[val_loss]:16663905456.67016\n",
      "iter25:[loss]:16332235713.197952\n",
      "iter25:[val_loss]:16665417365.599442\n",
      "iter26:[loss]:16332235713.197958\n",
      "iter26:[val_loss]:16666783917.593735\n",
      "iter27:[loss]:16332235713.197952\n",
      "iter27:[val_loss]:16668019499.110937\n",
      "iter28:[loss]:16332235713.197958\n",
      "iter28:[val_loss]:16669137023.669237\n",
      "iter29:[loss]:16332235713.197952\n",
      "iter29:[val_loss]:16670148088.3069\n",
      "iter30:[loss]:16332235713.197952\n",
      "iter30:[val_loss]:16671063112.797886\n",
      "iter31:[loss]:16332235713.197952\n",
      "iter31:[val_loss]:16671891463.589241\n",
      "iter32:[loss]:16332235713.197952\n",
      "iter32:[val_loss]:16672641564.19558\n",
      "iter33:[loss]:16332235713.197952\n",
      "iter33:[val_loss]:16673320993.583414\n",
      "iter34:[loss]:16332235713.197952\n",
      "iter34:[val_loss]:16673936573.89889\n",
      "iter35:[loss]:16332235713.197952\n",
      "iter35:[val_loss]:16674494448.735703\n",
      "iter36:[loss]:16332235713.197952\n",
      "iter36:[val_loss]:16675000153.000874\n",
      "iter37:[loss]:16332235713.197958\n",
      "iter37:[val_loss]:16675458675.31417\n",
      "iter38:[loss]:16332235713.197952\n",
      "iter38:[val_loss]:16675874513.768972\n",
      "iter39:[loss]:16332235713.197958\n",
      "iter39:[val_loss]:16676251725.7879\n",
      "iter40:[loss]:16332235713.197952\n",
      "iter40:[val_loss]:16676593972.722141\n",
      "iter41:[loss]:16332235713.197952\n",
      "iter41:[val_loss]:16676904559.769972\n",
      "iter42:[loss]:16332235713.197958\n",
      "iter42:[val_loss]:16677186471.724653\n",
      "iter43:[loss]:16332235713.197958\n",
      "iter43:[val_loss]:16677442405.003904\n",
      "iter44:[loss]:16332235713.197958\n",
      "iter44:[val_loss]:16677674796.36286\n",
      "iter45:[loss]:16332235713.197952\n",
      "iter45:[val_loss]:16677885848.646803\n",
      "iter46:[loss]:16332235713.197952\n",
      "iter46:[val_loss]:16678077553.900742\n",
      "iter47:[loss]:16332235713.197952\n",
      "iter47:[val_loss]:16678251714.117178\n",
      "iter48:[loss]:16332235713.197952\n",
      "iter48:[val_loss]:16678409959.872757\n",
      "iter49:[loss]:16332235713.197952\n",
      "iter49:[val_loss]:16678553767.076557\n",
      "iter50:[loss]:16332235713.197952\n",
      "iter50:[val_loss]:16678684472.028507\n",
      "iter51:[loss]:16332235713.197952\n",
      "iter51:[val_loss]:16678803284.964739\n",
      "iter52:[loss]:16332235713.197958\n",
      "iter52:[val_loss]:16678911302.247377\n",
      "iter53:[loss]:16332235713.197952\n",
      "iter53:[val_loss]:16679009517.339436\n",
      "iter54:[loss]:16332235713.197958\n",
      "iter54:[val_loss]:16679098830.690088\n",
      "iter55:[loss]:16332235713.197952\n",
      "iter55:[val_loss]:16679180058.64242\n",
      "iter56:[loss]:16332235713.197952\n",
      "iter56:[val_loss]:16679253941.46353\n",
      "iter57:[loss]:16332235713.197952\n",
      "iter57:[val_loss]:16679321150.586512\n",
      "iter58:[loss]:16332235713.197952\n",
      "iter58:[val_loss]:16679382295.144184\n",
      "iter59:[loss]:16332235713.197952\n",
      "iter59:[val_loss]:16679437927.86617\n",
      "iter60:[loss]:16332235713.197952\n",
      "iter60:[val_loss]:16679488550.40333\n",
      "iter61:[loss]:16332235713.197952\n",
      "iter61:[val_loss]:16679534618.13684\n",
      "iter62:[loss]:16332235713.197952\n",
      "iter62:[val_loss]:16679576544.52355\n",
      "iter63:[loss]:16332235713.197952\n",
      "iter63:[val_loss]:16679614705.0234\n",
      "iter64:[loss]:16332235713.197952\n",
      "iter64:[val_loss]:16679649440.650597\n",
      "iter65:[loss]:16332235713.197952\n",
      "iter65:[val_loss]:16679681061.18533\n",
      "iter66:[loss]:16332235713.197952\n",
      "iter66:[val_loss]:16679709848.079687\n",
      "iter67:[loss]:16332235713.197952\n",
      "iter67:[val_loss]:16679736057.08738\n",
      "iter68:[loss]:16332235713.197958\n",
      "iter68:[val_loss]:16679759920.644547\n",
      "iter69:[loss]:16332235713.197952\n",
      "iter69:[val_loss]:16679781650.025562\n",
      "iter70:[loss]:16332235713.197952\n",
      "iter70:[val_loss]:16679801437.29576\n",
      "iter71:[loss]:16332235713.197952\n",
      "iter71:[val_loss]:16679819457.080688\n",
      "iter72:[loss]:16332235713.197952\n",
      "iter72:[val_loss]:16679835868.169537\n",
      "iter73:[loss]:16332235713.197958\n",
      "iter73:[val_loss]:16679850814.968525\n",
      "iter74:[loss]:16332235713.197958\n",
      "iter74:[val_loss]:16679864428.818851\n",
      "iter75:[loss]:16332235713.197952\n",
      "iter75:[val_loss]:16679876829.19181\n",
      "iter76:[loss]:16332235713.197958\n",
      "iter76:[val_loss]:16679888124.773062\n",
      "iter77:[loss]:16332235713.197958\n",
      "iter77:[val_loss]:16679898414.446245\n",
      "iter78:[loss]:16332235713.197952\n",
      "iter78:[val_loss]:16679907788.1857\n",
      "iter79:[loss]:16332235713.197952\n",
      "iter79:[val_loss]:16679916327.86681\n",
      "iter80:[loss]:16332235713.197952\n",
      "iter80:[val_loss]:16679924108.001541\n",
      "iter81:[loss]:16332235713.197952\n",
      "iter81:[val_loss]:16679931196.406467\n",
      "iter82:[loss]:16332235713.197958\n",
      "iter82:[val_loss]:16679937654.809399\n",
      "iter83:[loss]:16332235713.197952\n",
      "iter83:[val_loss]:16679943539.400366\n",
      "iter84:[loss]:16332235713.197952\n",
      "iter84:[val_loss]:16679948901.332256\n",
      "iter85:[loss]:16332235713.197952\n",
      "iter85:[val_loss]:16679953787.175686\n",
      "iter86:[loss]:16332235713.197952\n",
      "iter86:[val_loss]:16679958239.33231\n",
      "iter87:[loss]:16332235713.197952\n",
      "iter87:[val_loss]:16679962296.410564\n",
      "iter88:[loss]:16332235713.197952\n",
      "iter88:[val_loss]:16679965993.567173\n",
      "iter89:[loss]:16332235713.197952\n",
      "iter89:[val_loss]:16679969362.817633\n",
      "iter90:[loss]:16332235713.197952\n",
      "iter90:[val_loss]:16679972433.318542\n",
      "iter91:[loss]:16332235713.197958\n",
      "iter91:[val_loss]:16679975231.62433\n",
      "iter92:[loss]:16332235713.197952\n",
      "iter92:[val_loss]:16679977781.920734\n",
      "iter93:[loss]:16332235713.197952\n",
      "iter93:[val_loss]:16679980106.237188\n",
      "iter94:[loss]:16332235713.197952\n",
      "iter94:[val_loss]:16679982224.640015\n",
      "iter95:[loss]:16332235713.197958\n",
      "iter95:[val_loss]:16679984155.4082\n",
      "iter96:[loss]:16332235713.197952\n",
      "iter96:[val_loss]:16679985915.193277\n",
      "iter97:[loss]:16332235713.197958\n",
      "iter97:[val_loss]:16679987519.164877\n",
      "iter98:[loss]:16332235713.197952\n",
      "iter98:[val_loss]:16679988981.143173\n",
      "iter99:[loss]:16332235713.197952\n",
      "iter99:[val_loss]:16679990313.719355\n",
      "iter100:[loss]:16332235713.197952\n",
      "iter100:[val_loss]:16679991528.365334\n",
      "iter101:[loss]:16332235713.197952\n",
      "iter101:[val_loss]:16679992635.533646\n",
      "iter102:[loss]:16332235713.197952\n",
      "iter102:[val_loss]:16679993644.748264\n",
      "iter103:[loss]:16332235713.197952\n",
      "iter103:[val_loss]:16679994564.687433\n",
      "iter104:[loss]:16332235713.197952\n",
      "iter104:[val_loss]:16679995403.258966\n",
      "iter105:[loss]:16332235713.197952\n",
      "iter105:[val_loss]:16679996167.668858\n",
      "iter106:[loss]:16332235713.197958\n",
      "iter106:[val_loss]:16679996864.483725\n",
      "iter107:[loss]:16332235713.197952\n",
      "iter107:[val_loss]:16679997499.687737\n",
      "iter108:[loss]:16332235713.197952\n",
      "iter108:[val_loss]:16679998078.734377\n",
      "iter109:[loss]:16332235713.197958\n",
      "iter109:[val_loss]:16679998606.593634\n",
      "iter110:[loss]:16332235713.197952\n",
      "iter110:[val_loss]:16679999087.794973\n",
      "iter111:[loss]:16332235713.197958\n",
      "iter111:[val_loss]:16679999526.46645\n",
      "iter112:[loss]:16332235713.197952\n",
      "iter112:[val_loss]:16679999926.370388\n",
      "iter113:[loss]:16332235713.197952\n",
      "iter113:[val_loss]:16680000290.935856\n",
      "iter114:[loss]:16332235713.197958\n",
      "iter114:[val_loss]:16680000623.288181\n",
      "iter115:[loss]:16332235713.197958\n",
      "iter115:[val_loss]:16680000926.275995\n",
      "iter116:[loss]:16332235713.197952\n",
      "iter116:[val_loss]:16680001202.495705\n",
      "iter117:[loss]:16332235713.197958\n",
      "iter117:[val_loss]:16680001454.313896\n",
      "iter118:[loss]:16332235713.197952\n",
      "iter118:[val_loss]:16680001683.887697\n",
      "iter119:[loss]:16332235713.197952\n",
      "iter119:[val_loss]:16680001893.183352\n",
      "iter120:[loss]:16332235713.197952\n",
      "iter120:[val_loss]:16680002083.993137\n",
      "iter121:[loss]:16332235713.197952\n",
      "iter121:[val_loss]:16680002257.950771\n",
      "iter122:[loss]:16332235713.197952\n",
      "iter122:[val_loss]:16680002416.545464\n",
      "iter123:[loss]:16332235713.197952\n",
      "iter123:[val_loss]:16680002561.134718\n",
      "iter124:[loss]:16332235713.197952\n",
      "iter124:[val_loss]:16680002692.955992\n",
      "iter125:[loss]:16332235713.197952\n",
      "iter125:[val_loss]:16680002813.137302\n",
      "iter126:[loss]:16332235713.197952\n",
      "iter126:[val_loss]:16680002922.706964\n",
      "iter127:[loss]:16332235713.197952\n",
      "iter127:[val_loss]:16680003022.602373\n",
      "iter128:[loss]:16332235713.197952\n",
      "iter128:[val_loss]:16680003113.678055\n",
      "iter129:[loss]:16332235713.197952\n",
      "iter129:[val_loss]:16680003196.71303\n",
      "iter130:[loss]:16332235713.197952\n",
      "iter130:[val_loss]:16680003272.417435\n",
      "iter131:[loss]:16332235713.197958\n",
      "iter131:[val_loss]:16680003341.438696\n",
      "iter132:[loss]:16332235713.197958\n",
      "iter132:[val_loss]:16680003404.36699\n",
      "iter133:[loss]:16332235713.197952\n",
      "iter133:[val_loss]:16680003461.740374\n",
      "iter134:[loss]:16332235713.197952\n",
      "iter134:[val_loss]:16680003514.049347\n",
      "iter135:[loss]:16332235713.197952\n",
      "iter135:[val_loss]:16680003561.741095\n",
      "iter136:[loss]:16332235713.197952\n",
      "iter136:[val_loss]:16680003605.22328\n",
      "iter137:[loss]:16332235713.197952\n",
      "iter137:[val_loss]:16680003644.867582\n",
      "iter138:[loss]:16332235713.197952\n",
      "iter138:[val_loss]:16680003681.012827\n",
      "iter139:[loss]:16332235713.197952\n",
      "iter139:[val_loss]:16680003713.967926\n",
      "iter140:[loss]:16332235713.197958\n",
      "iter140:[val_loss]:16680003744.014505\n",
      "iter141:[loss]:16332235713.197958\n",
      "iter141:[val_loss]:16680003771.40932\n",
      "iter142:[loss]:16332235713.197952\n",
      "iter142:[val_loss]:16680003796.386454\n",
      "iter143:[loss]:16332235713.197952\n",
      "iter143:[val_loss]:16680003819.159317\n",
      "iter144:[loss]:16332235713.197958\n",
      "iter144:[val_loss]:16680003839.92249\n",
      "iter145:[loss]:16332235713.197952\n",
      "iter145:[val_loss]:16680003858.853342\n",
      "iter146:[loss]:16332235713.197958\n",
      "iter146:[val_loss]:16680003876.113615\n",
      "iter147:[loss]:16332235713.197958\n",
      "iter147:[val_loss]:16680003891.850754\n",
      "iter148:[loss]:16332235713.197952\n",
      "iter148:[val_loss]:16680003906.199184\n",
      "iter149:[loss]:16332235713.197952\n",
      "iter149:[val_loss]:16680003919.281488\n",
      "iter150:[loss]:16332235713.197952\n",
      "iter150:[val_loss]:16680003931.209389\n",
      "iter151:[loss]:16332235713.197952\n",
      "iter151:[val_loss]:16680003942.084763\n",
      "iter152:[loss]:16332235713.197952\n",
      "iter152:[val_loss]:16680003952.000515\n",
      "iter153:[loss]:16332235713.197958\n",
      "iter153:[val_loss]:16680003961.041328\n",
      "iter154:[loss]:16332235713.197952\n",
      "iter154:[val_loss]:16680003969.28441\n",
      "iter155:[loss]:16332235713.197952\n",
      "iter155:[val_loss]:16680003976.800152\n",
      "iter156:[loss]:16332235713.197952\n",
      "iter156:[val_loss]:16680003983.65276\n",
      "iter157:[loss]:16332235713.197952\n",
      "iter157:[val_loss]:16680003989.90073\n",
      "iter158:[loss]:16332235713.197952\n",
      "iter158:[val_loss]:16680003995.597422\n",
      "iter159:[loss]:16332235713.197952\n",
      "iter159:[val_loss]:16680004000.791483\n",
      "iter160:[loss]:16332235713.197952\n",
      "iter160:[val_loss]:16680004005.52727\n",
      "iter161:[loss]:16332235713.197952\n",
      "iter161:[val_loss]:16680004009.84521\n",
      "iter162:[loss]:16332235713.197958\n",
      "iter162:[val_loss]:16680004013.782185\n",
      "iter163:[loss]:16332235713.197952\n",
      "iter163:[val_loss]:16680004017.3718\n",
      "iter164:[loss]:16332235713.197952\n",
      "iter164:[val_loss]:16680004020.644718\n",
      "iter165:[loss]:16332235713.197952\n",
      "iter165:[val_loss]:16680004023.628864\n",
      "iter166:[loss]:16332235713.197958\n",
      "iter166:[val_loss]:16680004026.349733\n",
      "iter167:[loss]:16332235713.197952\n",
      "iter167:[val_loss]:16680004028.83055\n",
      "iter168:[loss]:16332235713.197952\n",
      "iter168:[val_loss]:16680004031.09249\n",
      "iter169:[loss]:16332235713.197952\n",
      "iter169:[val_loss]:16680004033.154867\n",
      "iter170:[loss]:16332235713.197952\n",
      "iter170:[val_loss]:16680004035.035297\n",
      "iter171:[loss]:16332235713.197958\n",
      "iter171:[val_loss]:16680004036.749828\n",
      "iter172:[loss]:16332235713.197952\n",
      "iter172:[val_loss]:16680004038.313095\n",
      "iter173:[loss]:16332235713.197958\n",
      "iter173:[val_loss]:16680004039.73844\n",
      "iter174:[loss]:16332235713.197958\n",
      "iter174:[val_loss]:16680004041.038036\n",
      "iter175:[loss]:16332235713.197958\n",
      "iter175:[val_loss]:16680004042.222982\n",
      "iter176:[loss]:16332235713.197952\n",
      "iter176:[val_loss]:16680004043.303383\n",
      "iter177:[loss]:16332235713.197952\n",
      "iter177:[val_loss]:16680004044.288475\n",
      "iter178:[loss]:16332235713.197952\n",
      "iter178:[val_loss]:16680004045.186657\n",
      "iter179:[loss]:16332235713.197952\n",
      "iter179:[val_loss]:16680004046.005606\n",
      "iter180:[loss]:16332235713.197958\n",
      "iter180:[val_loss]:16680004046.752296\n",
      "iter181:[loss]:16332235713.197952\n",
      "iter181:[val_loss]:16680004047.433125\n",
      "iter182:[loss]:16332235713.197952\n",
      "iter182:[val_loss]:16680004048.053885\n",
      "iter183:[loss]:16332235713.197952\n",
      "iter183:[val_loss]:16680004048.619877\n",
      "iter184:[loss]:16332235713.197952\n",
      "iter184:[val_loss]:16680004049.13594\n",
      "iter185:[loss]:16332235713.197958\n",
      "iter185:[val_loss]:16680004049.606478\n",
      "iter186:[loss]:16332235713.197958\n",
      "iter186:[val_loss]:16680004050.0355\n",
      "iter187:[loss]:16332235713.197958\n",
      "iter187:[val_loss]:16680004050.426685\n",
      "iter188:[loss]:16332235713.197958\n",
      "iter188:[val_loss]:16680004050.783344\n",
      "iter189:[loss]:16332235713.197952\n",
      "iter189:[val_loss]:16680004051.108545\n",
      "iter190:[loss]:16332235713.197952\n",
      "iter190:[val_loss]:16680004051.405062\n",
      "iter191:[loss]:16332235713.197952\n",
      "iter191:[val_loss]:16680004051.67542\n",
      "iter192:[loss]:16332235713.197952\n",
      "iter192:[val_loss]:16680004051.92192\n",
      "iter193:[loss]:16332235713.197952\n",
      "iter193:[val_loss]:16680004052.146687\n",
      "iter194:[loss]:16332235713.197952\n",
      "iter194:[val_loss]:16680004052.351618\n",
      "iter195:[loss]:16332235713.197958\n",
      "iter195:[val_loss]:16680004052.538462\n",
      "iter196:[loss]:16332235713.197952\n",
      "iter196:[val_loss]:16680004052.708841\n",
      "iter197:[loss]:16332235713.197958\n",
      "iter197:[val_loss]:16680004052.864183\n",
      "iter198:[loss]:16332235713.197958\n",
      "iter198:[val_loss]:16680004053.005816\n",
      "iter199:[loss]:16332235713.197958\n",
      "iter199:[val_loss]:16680004053.13495\n",
      "iter200:[loss]:16332235713.197952\n",
      "iter200:[val_loss]:16680004053.252699\n",
      "iter201:[loss]:16332235713.197952\n",
      "iter201:[val_loss]:16680004053.360065\n",
      "iter202:[loss]:16332235713.197952\n",
      "iter202:[val_loss]:16680004053.45795\n",
      "iter203:[loss]:16332235713.197952\n",
      "iter203:[val_loss]:16680004053.547207\n",
      "iter204:[loss]:16332235713.197958\n",
      "iter204:[val_loss]:16680004053.628586\n",
      "iter205:[loss]:16332235713.197952\n",
      "iter205:[val_loss]:16680004053.702793\n",
      "iter206:[loss]:16332235713.197958\n",
      "iter206:[val_loss]:16680004053.77045\n",
      "iter207:[loss]:16332235713.197958\n",
      "iter207:[val_loss]:16680004053.832136\n",
      "iter208:[loss]:16332235713.197952\n",
      "iter208:[val_loss]:16680004053.888376\n",
      "iter209:[loss]:16332235713.197958\n",
      "iter209:[val_loss]:16680004053.939661\n",
      "iter210:[loss]:16332235713.197952\n",
      "iter210:[val_loss]:16680004053.98642\n",
      "iter211:[loss]:16332235713.197952\n",
      "iter211:[val_loss]:16680004054.029057\n",
      "iter212:[loss]:16332235713.197952\n",
      "iter212:[val_loss]:16680004054.067924\n",
      "iter213:[loss]:16332235713.197958\n",
      "iter213:[val_loss]:16680004054.103376\n",
      "iter214:[loss]:16332235713.197952\n",
      "iter214:[val_loss]:16680004054.13569\n",
      "iter215:[loss]:16332235713.197952\n",
      "iter215:[val_loss]:16680004054.165155\n",
      "iter216:[loss]:16332235713.197958\n",
      "iter216:[val_loss]:16680004054.192026\n",
      "iter217:[loss]:16332235713.197952\n",
      "iter217:[val_loss]:16680004054.216522\n",
      "iter218:[loss]:16332235713.197958\n",
      "iter218:[val_loss]:16680004054.238863\n",
      "iter219:[loss]:16332235713.197952\n",
      "iter219:[val_loss]:16680004054.259222\n",
      "iter220:[loss]:16332235713.197952\n",
      "iter220:[val_loss]:16680004054.27779\n",
      "iter221:[loss]:16332235713.197952\n",
      "iter221:[val_loss]:16680004054.294722\n",
      "iter222:[loss]:16332235713.197958\n",
      "iter222:[val_loss]:16680004054.310163\n",
      "iter223:[loss]:16332235713.197952\n",
      "iter223:[val_loss]:16680004054.324234\n",
      "iter224:[loss]:16332235713.197952\n",
      "iter224:[val_loss]:16680004054.337067\n",
      "iter225:[loss]:16332235713.197958\n",
      "iter225:[val_loss]:16680004054.348772\n",
      "iter226:[loss]:16332235713.197952\n",
      "iter226:[val_loss]:16680004054.35944\n",
      "iter227:[loss]:16332235713.197952\n",
      "iter227:[val_loss]:16680004054.369173\n",
      "iter228:[loss]:16332235713.197952\n",
      "iter228:[val_loss]:16680004054.37804\n",
      "iter229:[loss]:16332235713.197958\n",
      "iter229:[val_loss]:16680004054.386126\n",
      "iter230:[loss]:16332235713.197952\n",
      "iter230:[val_loss]:16680004054.393503\n",
      "iter231:[loss]:16332235713.197952\n",
      "iter231:[val_loss]:16680004054.400223\n",
      "iter232:[loss]:16332235713.197952\n",
      "iter232:[val_loss]:16680004054.406357\n",
      "iter233:[loss]:16332235713.197952\n",
      "iter233:[val_loss]:16680004054.41195\n",
      "iter234:[loss]:16332235713.197952\n",
      "iter234:[val_loss]:16680004054.417042\n",
      "iter235:[loss]:16332235713.197952\n",
      "iter235:[val_loss]:16680004054.421688\n",
      "iter236:[loss]:16332235713.197952\n",
      "iter236:[val_loss]:16680004054.42593\n",
      "iter237:[loss]:16332235713.197958\n",
      "iter237:[val_loss]:16680004054.429789\n",
      "iter238:[loss]:16332235713.197952\n",
      "iter238:[val_loss]:16680004054.43332\n",
      "iter239:[loss]:16332235713.197952\n",
      "iter239:[val_loss]:16680004054.436523\n",
      "iter240:[loss]:16332235713.197952\n",
      "iter240:[val_loss]:16680004054.439453\n",
      "iter241:[loss]:16332235713.197952\n",
      "iter241:[val_loss]:16680004054.442122\n",
      "iter242:[loss]:16332235713.197952\n",
      "iter242:[val_loss]:16680004054.444555\n",
      "iter243:[loss]:16332235713.197952\n",
      "iter243:[val_loss]:16680004054.446777\n",
      "iter244:[loss]:16332235713.197952\n",
      "iter244:[val_loss]:16680004054.448803\n",
      "iter245:[loss]:16332235713.197952\n",
      "iter245:[val_loss]:16680004054.450647\n",
      "iter246:[loss]:16332235713.197958\n",
      "iter246:[val_loss]:16680004054.452322\n",
      "iter247:[loss]:16332235713.197952\n",
      "iter247:[val_loss]:16680004054.453857\n",
      "iter248:[loss]:16332235713.197952\n",
      "iter248:[val_loss]:16680004054.455256\n",
      "iter249:[loss]:16332235713.197952\n",
      "iter249:[val_loss]:16680004054.456537\n",
      "iter250:[loss]:16332235713.197952\n",
      "iter250:[val_loss]:16680004054.4577\n",
      "iter251:[loss]:16332235713.197952\n",
      "iter251:[val_loss]:16680004054.45876\n",
      "iter252:[loss]:16332235713.197952\n",
      "iter252:[val_loss]:16680004054.459726\n",
      "iter253:[loss]:16332235713.197952\n",
      "iter253:[val_loss]:16680004054.46061\n",
      "iter254:[loss]:16332235713.197958\n",
      "iter254:[val_loss]:16680004054.461412\n",
      "iter255:[loss]:16332235713.197952\n",
      "iter255:[val_loss]:16680004054.462145\n",
      "iter256:[loss]:16332235713.197958\n",
      "iter256:[val_loss]:16680004054.462814\n",
      "iter257:[loss]:16332235713.197952\n",
      "iter257:[val_loss]:16680004054.46342\n",
      "iter258:[loss]:16332235713.197958\n",
      "iter258:[val_loss]:16680004054.46398\n",
      "iter259:[loss]:16332235713.197952\n",
      "iter259:[val_loss]:16680004054.464485\n",
      "iter260:[loss]:16332235713.197952\n",
      "iter260:[val_loss]:16680004054.464947\n",
      "iter261:[loss]:16332235713.197952\n",
      "iter261:[val_loss]:16680004054.465372\n",
      "iter262:[loss]:16332235713.197952\n",
      "iter262:[val_loss]:16680004054.465755\n",
      "iter263:[loss]:16332235713.197952\n",
      "iter263:[val_loss]:16680004054.4661\n",
      "iter264:[loss]:16332235713.197952\n",
      "iter264:[val_loss]:16680004054.466425\n",
      "iter265:[loss]:16332235713.197958\n",
      "iter265:[val_loss]:16680004054.466717\n",
      "iter266:[loss]:16332235713.197958\n",
      "iter266:[val_loss]:16680004054.466978\n",
      "iter267:[loss]:16332235713.197958\n",
      "iter267:[val_loss]:16680004054.467216\n",
      "iter268:[loss]:16332235713.197958\n",
      "iter268:[val_loss]:16680004054.46744\n",
      "iter269:[loss]:16332235713.197952\n",
      "iter269:[val_loss]:16680004054.467642\n",
      "iter270:[loss]:16332235713.197952\n",
      "iter270:[val_loss]:16680004054.467829\n",
      "iter271:[loss]:16332235713.197958\n",
      "iter271:[val_loss]:16680004054.467993\n",
      "iter272:[loss]:16332235713.197952\n",
      "iter272:[val_loss]:16680004054.468147\n",
      "iter273:[loss]:16332235713.197952\n",
      "iter273:[val_loss]:16680004054.468279\n",
      "iter274:[loss]:16332235713.197952\n",
      "iter274:[val_loss]:16680004054.468407\n",
      "iter275:[loss]:16332235713.197952\n",
      "iter275:[val_loss]:16680004054.468525\n",
      "iter276:[loss]:16332235713.197958\n",
      "iter276:[val_loss]:16680004054.46863\n",
      "iter277:[loss]:16332235713.197952\n",
      "iter277:[val_loss]:16680004054.468721\n",
      "iter278:[loss]:16332235713.197958\n",
      "iter278:[val_loss]:16680004054.468817\n",
      "iter279:[loss]:16332235713.197958\n",
      "iter279:[val_loss]:16680004054.468897\n",
      "iter280:[loss]:16332235713.197952\n",
      "iter280:[val_loss]:16680004054.468966\n",
      "iter281:[loss]:16332235713.197958\n",
      "iter281:[val_loss]:16680004054.469028\n",
      "iter282:[loss]:16332235713.197952\n",
      "iter282:[val_loss]:16680004054.469093\n",
      "iter283:[loss]:16332235713.197952\n",
      "iter283:[val_loss]:16680004054.469152\n",
      "iter284:[loss]:16332235713.197952\n",
      "iter284:[val_loss]:16680004054.4692\n",
      "iter285:[loss]:16332235713.197952\n",
      "iter285:[val_loss]:16680004054.469242\n",
      "iter286:[loss]:16332235713.197952\n",
      "iter286:[val_loss]:16680004054.46929\n",
      "iter287:[loss]:16332235713.197958\n",
      "iter287:[val_loss]:16680004054.469328\n",
      "iter288:[loss]:16332235713.197952\n",
      "iter288:[val_loss]:16680004054.469364\n",
      "iter289:[loss]:16332235713.197952\n",
      "iter289:[val_loss]:16680004054.46939\n",
      "iter290:[loss]:16332235713.197952\n",
      "iter290:[val_loss]:16680004054.469418\n",
      "iter291:[loss]:16332235713.197952\n",
      "iter291:[val_loss]:16680004054.469444\n",
      "iter292:[loss]:16332235713.197952\n",
      "iter292:[val_loss]:16680004054.469477\n",
      "iter293:[loss]:16332235713.197958\n",
      "iter293:[val_loss]:16680004054.469492\n",
      "iter294:[loss]:16332235713.197958\n",
      "iter294:[val_loss]:16680004054.469513\n",
      "iter295:[loss]:16332235713.197952\n",
      "iter295:[val_loss]:16680004054.469534\n",
      "iter296:[loss]:16332235713.197958\n",
      "iter296:[val_loss]:16680004054.469551\n",
      "iter297:[loss]:16332235713.197952\n",
      "iter297:[val_loss]:16680004054.46956\n",
      "iter298:[loss]:16332235713.197958\n",
      "iter298:[val_loss]:16680004054.469578\n",
      "iter299:[loss]:16332235713.197952\n",
      "iter299:[val_loss]:16680004054.469593\n",
      "iter300:[loss]:16332235713.197952\n",
      "iter300:[val_loss]:16680004054.469603\n",
      "iter301:[loss]:16332235713.197952\n",
      "iter301:[val_loss]:16680004054.469608\n",
      "iter302:[loss]:16332235713.197952\n",
      "iter302:[val_loss]:16680004054.46962\n",
      "iter303:[loss]:16332235713.197952\n",
      "iter303:[val_loss]:16680004054.46963\n",
      "iter304:[loss]:16332235713.197952\n",
      "iter304:[val_loss]:16680004054.46964\n",
      "iter305:[loss]:16332235713.197952\n",
      "iter305:[val_loss]:16680004054.469646\n",
      "iter306:[loss]:16332235713.197958\n",
      "iter306:[val_loss]:16680004054.469652\n",
      "iter307:[loss]:16332235713.197952\n",
      "iter307:[val_loss]:16680004054.469656\n",
      "iter308:[loss]:16332235713.197952\n",
      "iter308:[val_loss]:16680004054.469662\n",
      "iter309:[loss]:16332235713.197952\n",
      "iter309:[val_loss]:16680004054.469667\n",
      "iter310:[loss]:16332235713.197952\n",
      "iter310:[val_loss]:16680004054.469667\n",
      "iter311:[loss]:16332235713.197952\n",
      "iter311:[val_loss]:16680004054.469677\n",
      "iter312:[loss]:16332235713.197952\n",
      "iter312:[val_loss]:16680004054.469683\n",
      "iter313:[loss]:16332235713.197952\n",
      "iter313:[val_loss]:16680004054.469688\n",
      "iter314:[loss]:16332235713.197952\n",
      "iter314:[val_loss]:16680004054.469688\n",
      "iter315:[loss]:16332235713.197952\n",
      "iter315:[val_loss]:16680004054.469688\n",
      "iter316:[loss]:16332235713.197952\n",
      "iter316:[val_loss]:16680004054.469688\n",
      "iter317:[loss]:16332235713.197952\n",
      "iter317:[val_loss]:16680004054.4697\n",
      "iter318:[loss]:16332235713.197952\n",
      "iter318:[val_loss]:16680004054.4697\n",
      "iter319:[loss]:16332235713.197952\n",
      "iter319:[val_loss]:16680004054.4697\n",
      "iter320:[loss]:16332235713.197952\n",
      "iter320:[val_loss]:16680004054.469704\n",
      "iter321:[loss]:16332235713.197952\n",
      "iter321:[val_loss]:16680004054.469704\n",
      "iter322:[loss]:16332235713.197952\n",
      "iter322:[val_loss]:16680004054.469704\n",
      "iter323:[loss]:16332235713.197952\n",
      "iter323:[val_loss]:16680004054.469704\n",
      "iter324:[loss]:16332235713.197958\n",
      "iter324:[val_loss]:16680004054.46971\n",
      "iter325:[loss]:16332235713.197952\n",
      "iter325:[val_loss]:16680004054.469704\n",
      "iter326:[loss]:16332235713.197958\n",
      "iter326:[val_loss]:16680004054.46971\n",
      "iter327:[loss]:16332235713.197958\n",
      "iter327:[val_loss]:16680004054.469704\n",
      "iter328:[loss]:16332235713.197958\n",
      "iter328:[val_loss]:16680004054.469704\n",
      "iter329:[loss]:16332235713.197952\n",
      "iter329:[val_loss]:16680004054.469704\n",
      "iter330:[loss]:16332235713.197952\n",
      "iter330:[val_loss]:16680004054.46971\n",
      "iter331:[loss]:16332235713.197958\n",
      "iter331:[val_loss]:16680004054.469715\n",
      "iter332:[loss]:16332235713.197952\n",
      "iter332:[val_loss]:16680004054.469715\n",
      "iter333:[loss]:16332235713.197952\n",
      "iter333:[val_loss]:16680004054.469715\n",
      "iter334:[loss]:16332235713.197952\n",
      "iter334:[val_loss]:16680004054.469715\n",
      "iter335:[loss]:16332235713.197952\n",
      "iter335:[val_loss]:16680004054.469715\n",
      "iter336:[loss]:16332235713.197952\n",
      "iter336:[val_loss]:16680004054.469715\n",
      "iter337:[loss]:16332235713.197952\n",
      "iter337:[val_loss]:16680004054.46972\n",
      "iter338:[loss]:16332235713.197952\n",
      "iter338:[val_loss]:16680004054.469715\n",
      "iter339:[loss]:16332235713.197952\n",
      "iter339:[val_loss]:16680004054.469715\n",
      "iter340:[loss]:16332235713.197952\n",
      "iter340:[val_loss]:16680004054.469715\n",
      "iter341:[loss]:16332235713.197952\n",
      "iter341:[val_loss]:16680004054.469715\n",
      "iter342:[loss]:16332235713.197952\n",
      "iter342:[val_loss]:16680004054.469715\n",
      "iter343:[loss]:16332235713.197952\n",
      "iter343:[val_loss]:16680004054.469715\n",
      "iter344:[loss]:16332235713.197952\n",
      "iter344:[val_loss]:16680004054.469715\n",
      "iter345:[loss]:16332235713.197952\n",
      "iter345:[val_loss]:16680004054.469715\n",
      "iter346:[loss]:16332235713.197952\n",
      "iter346:[val_loss]:16680004054.469715\n",
      "iter347:[loss]:16332235713.197952\n",
      "iter347:[val_loss]:16680004054.46972\n",
      "iter348:[loss]:16332235713.197952\n",
      "iter348:[val_loss]:16680004054.469715\n",
      "iter349:[loss]:16332235713.197952\n",
      "iter349:[val_loss]:16680004054.469715\n",
      "iter350:[loss]:16332235713.197952\n",
      "iter350:[val_loss]:16680004054.469715\n",
      "iter351:[loss]:16332235713.197952\n",
      "iter351:[val_loss]:16680004054.469715\n",
      "iter352:[loss]:16332235713.197952\n",
      "iter352:[val_loss]:16680004054.469715\n",
      "iter353:[loss]:16332235713.197952\n",
      "iter353:[val_loss]:16680004054.46972\n",
      "iter354:[loss]:16332235713.197952\n",
      "iter354:[val_loss]:16680004054.46972\n",
      "iter355:[loss]:16332235713.197952\n",
      "iter355:[val_loss]:16680004054.46972\n",
      "iter356:[loss]:16332235713.197952\n",
      "iter356:[val_loss]:16680004054.469715\n",
      "iter357:[loss]:16332235713.197952\n",
      "iter357:[val_loss]:16680004054.469715\n",
      "iter358:[loss]:16332235713.197952\n",
      "iter358:[val_loss]:16680004054.46972\n",
      "iter359:[loss]:16332235713.197952\n",
      "iter359:[val_loss]:16680004054.46972\n",
      "iter360:[loss]:16332235713.197952\n",
      "iter360:[val_loss]:16680004054.46972\n",
      "iter361:[loss]:16332235713.197952\n",
      "iter361:[val_loss]:16680004054.46972\n",
      "iter362:[loss]:16332235713.197952\n",
      "iter362:[val_loss]:16680004054.46972\n",
      "iter363:[loss]:16332235713.197952\n",
      "iter363:[val_loss]:16680004054.46972\n",
      "iter364:[loss]:16332235713.197952\n",
      "iter364:[val_loss]:16680004054.46972\n",
      "iter365:[loss]:16332235713.197952\n",
      "iter365:[val_loss]:16680004054.46972\n",
      "iter366:[loss]:16332235713.197952\n",
      "iter366:[val_loss]:16680004054.46972\n",
      "iter367:[loss]:16332235713.197952\n",
      "iter367:[val_loss]:16680004054.46972\n",
      "iter368:[loss]:16332235713.197952\n",
      "iter368:[val_loss]:16680004054.46972\n",
      "iter369:[loss]:16332235713.197952\n",
      "iter369:[val_loss]:16680004054.46972\n",
      "iter370:[loss]:16332235713.197952\n",
      "iter370:[val_loss]:16680004054.46972\n",
      "iter371:[loss]:16332235713.197952\n",
      "iter371:[val_loss]:16680004054.46972\n",
      "iter372:[loss]:16332235713.197952\n",
      "iter372:[val_loss]:16680004054.46972\n",
      "iter373:[loss]:16332235713.197952\n",
      "iter373:[val_loss]:16680004054.46972\n",
      "iter374:[loss]:16332235713.197952\n",
      "iter374:[val_loss]:16680004054.46972\n",
      "iter375:[loss]:16332235713.197952\n",
      "iter375:[val_loss]:16680004054.46972\n",
      "iter376:[loss]:16332235713.197952\n",
      "iter376:[val_loss]:16680004054.46972\n",
      "iter377:[loss]:16332235713.197952\n",
      "iter377:[val_loss]:16680004054.46972\n",
      "iter378:[loss]:16332235713.197952\n",
      "iter378:[val_loss]:16680004054.46972\n",
      "iter379:[loss]:16332235713.197952\n",
      "iter379:[val_loss]:16680004054.46972\n",
      "iter380:[loss]:16332235713.197952\n",
      "iter380:[val_loss]:16680004054.46972\n",
      "iter381:[loss]:16332235713.197952\n",
      "iter381:[val_loss]:16680004054.46972\n",
      "iter382:[loss]:16332235713.197952\n",
      "iter382:[val_loss]:16680004054.46972\n",
      "iter383:[loss]:16332235713.197952\n",
      "iter383:[val_loss]:16680004054.46972\n",
      "iter384:[loss]:16332235713.197952\n",
      "iter384:[val_loss]:16680004054.46972\n",
      "iter385:[loss]:16332235713.197952\n",
      "iter385:[val_loss]:16680004054.46972\n",
      "iter386:[loss]:16332235713.197952\n",
      "iter386:[val_loss]:16680004054.46972\n",
      "iter387:[loss]:16332235713.197952\n",
      "iter387:[val_loss]:16680004054.46972\n",
      "iter388:[loss]:16332235713.197952\n",
      "iter388:[val_loss]:16680004054.46972\n",
      "iter389:[loss]:16332235713.197952\n",
      "iter389:[val_loss]:16680004054.46972\n",
      "iter390:[loss]:16332235713.197952\n",
      "iter390:[val_loss]:16680004054.46972\n",
      "iter391:[loss]:16332235713.197952\n",
      "iter391:[val_loss]:16680004054.46972\n",
      "iter392:[loss]:16332235713.197952\n",
      "iter392:[val_loss]:16680004054.46972\n",
      "iter393:[loss]:16332235713.197952\n",
      "iter393:[val_loss]:16680004054.46972\n",
      "iter394:[loss]:16332235713.197952\n",
      "iter394:[val_loss]:16680004054.46972\n",
      "iter395:[loss]:16332235713.197952\n",
      "iter395:[val_loss]:16680004054.46972\n",
      "iter396:[loss]:16332235713.197952\n",
      "iter396:[val_loss]:16680004054.46972\n",
      "iter397:[loss]:16332235713.197952\n",
      "iter397:[val_loss]:16680004054.46972\n",
      "iter398:[loss]:16332235713.197952\n",
      "iter398:[val_loss]:16680004054.46972\n",
      "iter399:[loss]:16332235713.197952\n",
      "iter399:[val_loss]:16680004054.46972\n",
      "iter400:[loss]:16332235713.197952\n",
      "iter400:[val_loss]:16680004054.46972\n",
      "iter401:[loss]:16332235713.197952\n",
      "iter401:[val_loss]:16680004054.46972\n",
      "iter402:[loss]:16332235713.197952\n",
      "iter402:[val_loss]:16680004054.46972\n",
      "iter403:[loss]:16332235713.197952\n",
      "iter403:[val_loss]:16680004054.46972\n",
      "iter404:[loss]:16332235713.197952\n",
      "iter404:[val_loss]:16680004054.46972\n",
      "iter405:[loss]:16332235713.197952\n",
      "iter405:[val_loss]:16680004054.46972\n",
      "iter406:[loss]:16332235713.197952\n",
      "iter406:[val_loss]:16680004054.46972\n",
      "iter407:[loss]:16332235713.197952\n",
      "iter407:[val_loss]:16680004054.46972\n",
      "iter408:[loss]:16332235713.197952\n",
      "iter408:[val_loss]:16680004054.46972\n",
      "iter409:[loss]:16332235713.197952\n",
      "iter409:[val_loss]:16680004054.46972\n",
      "iter410:[loss]:16332235713.197952\n",
      "iter410:[val_loss]:16680004054.46972\n",
      "iter411:[loss]:16332235713.197952\n",
      "iter411:[val_loss]:16680004054.46972\n",
      "iter412:[loss]:16332235713.197952\n",
      "iter412:[val_loss]:16680004054.46972\n",
      "iter413:[loss]:16332235713.197952\n",
      "iter413:[val_loss]:16680004054.46972\n",
      "iter414:[loss]:16332235713.197952\n",
      "iter414:[val_loss]:16680004054.46972\n",
      "iter415:[loss]:16332235713.197952\n",
      "iter415:[val_loss]:16680004054.46972\n",
      "iter416:[loss]:16332235713.197952\n",
      "iter416:[val_loss]:16680004054.46972\n",
      "iter417:[loss]:16332235713.197952\n",
      "iter417:[val_loss]:16680004054.46972\n",
      "iter418:[loss]:16332235713.197952\n",
      "iter418:[val_loss]:16680004054.46972\n",
      "iter419:[loss]:16332235713.197952\n",
      "iter419:[val_loss]:16680004054.46972\n",
      "iter420:[loss]:16332235713.197952\n",
      "iter420:[val_loss]:16680004054.46972\n",
      "iter421:[loss]:16332235713.197952\n",
      "iter421:[val_loss]:16680004054.46972\n",
      "iter422:[loss]:16332235713.197952\n",
      "iter422:[val_loss]:16680004054.46972\n",
      "iter423:[loss]:16332235713.197952\n",
      "iter423:[val_loss]:16680004054.46972\n",
      "iter424:[loss]:16332235713.197952\n",
      "iter424:[val_loss]:16680004054.46972\n",
      "iter425:[loss]:16332235713.197952\n",
      "iter425:[val_loss]:16680004054.46972\n",
      "iter426:[loss]:16332235713.197952\n",
      "iter426:[val_loss]:16680004054.46972\n",
      "iter427:[loss]:16332235713.197952\n",
      "iter427:[val_loss]:16680004054.46972\n",
      "iter428:[loss]:16332235713.197952\n",
      "iter428:[val_loss]:16680004054.46972\n",
      "iter429:[loss]:16332235713.197952\n",
      "iter429:[val_loss]:16680004054.46972\n",
      "iter430:[loss]:16332235713.197952\n",
      "iter430:[val_loss]:16680004054.46972\n",
      "iter431:[loss]:16332235713.197952\n",
      "iter431:[val_loss]:16680004054.46972\n",
      "iter432:[loss]:16332235713.197952\n",
      "iter432:[val_loss]:16680004054.46972\n",
      "iter433:[loss]:16332235713.197952\n",
      "iter433:[val_loss]:16680004054.46972\n",
      "iter434:[loss]:16332235713.197952\n",
      "iter434:[val_loss]:16680004054.46972\n",
      "iter435:[loss]:16332235713.197952\n",
      "iter435:[val_loss]:16680004054.46972\n",
      "iter436:[loss]:16332235713.197952\n",
      "iter436:[val_loss]:16680004054.46972\n",
      "iter437:[loss]:16332235713.197952\n",
      "iter437:[val_loss]:16680004054.46972\n",
      "iter438:[loss]:16332235713.197952\n",
      "iter438:[val_loss]:16680004054.46972\n",
      "iter439:[loss]:16332235713.197952\n",
      "iter439:[val_loss]:16680004054.46972\n",
      "iter440:[loss]:16332235713.197952\n",
      "iter440:[val_loss]:16680004054.46972\n",
      "iter441:[loss]:16332235713.197952\n",
      "iter441:[val_loss]:16680004054.46972\n",
      "iter442:[loss]:16332235713.197952\n",
      "iter442:[val_loss]:16680004054.46972\n",
      "iter443:[loss]:16332235713.197952\n",
      "iter443:[val_loss]:16680004054.46972\n",
      "iter444:[loss]:16332235713.197952\n",
      "iter444:[val_loss]:16680004054.46972\n",
      "iter445:[loss]:16332235713.197952\n",
      "iter445:[val_loss]:16680004054.46972\n",
      "iter446:[loss]:16332235713.197952\n",
      "iter446:[val_loss]:16680004054.46972\n",
      "iter447:[loss]:16332235713.197952\n",
      "iter447:[val_loss]:16680004054.46972\n",
      "iter448:[loss]:16332235713.197952\n",
      "iter448:[val_loss]:16680004054.46972\n",
      "iter449:[loss]:16332235713.197952\n",
      "iter449:[val_loss]:16680004054.46972\n",
      "iter450:[loss]:16332235713.197952\n",
      "iter450:[val_loss]:16680004054.46972\n",
      "iter451:[loss]:16332235713.197952\n",
      "iter451:[val_loss]:16680004054.46972\n",
      "iter452:[loss]:16332235713.197952\n",
      "iter452:[val_loss]:16680004054.46972\n",
      "iter453:[loss]:16332235713.197952\n",
      "iter453:[val_loss]:16680004054.46972\n",
      "iter454:[loss]:16332235713.197952\n",
      "iter454:[val_loss]:16680004054.46972\n",
      "iter455:[loss]:16332235713.197952\n",
      "iter455:[val_loss]:16680004054.46972\n",
      "iter456:[loss]:16332235713.197952\n",
      "iter456:[val_loss]:16680004054.46972\n",
      "iter457:[loss]:16332235713.197952\n",
      "iter457:[val_loss]:16680004054.46972\n",
      "iter458:[loss]:16332235713.197952\n",
      "iter458:[val_loss]:16680004054.46972\n",
      "iter459:[loss]:16332235713.197952\n",
      "iter459:[val_loss]:16680004054.46972\n",
      "iter460:[loss]:16332235713.197952\n",
      "iter460:[val_loss]:16680004054.46972\n",
      "iter461:[loss]:16332235713.197952\n",
      "iter461:[val_loss]:16680004054.46972\n",
      "iter462:[loss]:16332235713.197952\n",
      "iter462:[val_loss]:16680004054.46972\n",
      "iter463:[loss]:16332235713.197952\n",
      "iter463:[val_loss]:16680004054.46972\n",
      "iter464:[loss]:16332235713.197952\n",
      "iter464:[val_loss]:16680004054.46972\n",
      "iter465:[loss]:16332235713.197952\n",
      "iter465:[val_loss]:16680004054.46972\n",
      "iter466:[loss]:16332235713.197952\n",
      "iter466:[val_loss]:16680004054.46972\n",
      "iter467:[loss]:16332235713.197952\n",
      "iter467:[val_loss]:16680004054.46972\n",
      "iter468:[loss]:16332235713.197952\n",
      "iter468:[val_loss]:16680004054.46972\n",
      "iter469:[loss]:16332235713.197952\n",
      "iter469:[val_loss]:16680004054.46972\n",
      "iter470:[loss]:16332235713.197952\n",
      "iter470:[val_loss]:16680004054.46972\n",
      "iter471:[loss]:16332235713.197952\n",
      "iter471:[val_loss]:16680004054.46972\n",
      "iter472:[loss]:16332235713.197952\n",
      "iter472:[val_loss]:16680004054.46972\n",
      "iter473:[loss]:16332235713.197952\n",
      "iter473:[val_loss]:16680004054.46972\n",
      "iter474:[loss]:16332235713.197952\n",
      "iter474:[val_loss]:16680004054.46972\n",
      "iter475:[loss]:16332235713.197952\n",
      "iter475:[val_loss]:16680004054.46972\n",
      "iter476:[loss]:16332235713.197952\n",
      "iter476:[val_loss]:16680004054.46972\n",
      "iter477:[loss]:16332235713.197952\n",
      "iter477:[val_loss]:16680004054.46972\n",
      "iter478:[loss]:16332235713.197952\n",
      "iter478:[val_loss]:16680004054.46972\n",
      "iter479:[loss]:16332235713.197952\n",
      "iter479:[val_loss]:16680004054.46972\n",
      "iter480:[loss]:16332235713.197952\n",
      "iter480:[val_loss]:16680004054.46972\n",
      "iter481:[loss]:16332235713.197952\n",
      "iter481:[val_loss]:16680004054.46972\n",
      "iter482:[loss]:16332235713.197952\n",
      "iter482:[val_loss]:16680004054.46972\n",
      "iter483:[loss]:16332235713.197952\n",
      "iter483:[val_loss]:16680004054.46972\n",
      "iter484:[loss]:16332235713.197952\n",
      "iter484:[val_loss]:16680004054.46972\n",
      "iter485:[loss]:16332235713.197952\n",
      "iter485:[val_loss]:16680004054.46972\n",
      "iter486:[loss]:16332235713.197952\n",
      "iter486:[val_loss]:16680004054.46972\n",
      "iter487:[loss]:16332235713.197952\n",
      "iter487:[val_loss]:16680004054.46972\n",
      "iter488:[loss]:16332235713.197952\n",
      "iter488:[val_loss]:16680004054.46972\n",
      "iter489:[loss]:16332235713.197952\n",
      "iter489:[val_loss]:16680004054.46972\n",
      "iter490:[loss]:16332235713.197952\n",
      "iter490:[val_loss]:16680004054.46972\n",
      "iter491:[loss]:16332235713.197952\n",
      "iter491:[val_loss]:16680004054.46972\n",
      "iter492:[loss]:16332235713.197952\n",
      "iter492:[val_loss]:16680004054.46972\n",
      "iter493:[loss]:16332235713.197952\n",
      "iter493:[val_loss]:16680004054.46972\n",
      "iter494:[loss]:16332235713.197952\n",
      "iter494:[val_loss]:16680004054.46972\n",
      "iter495:[loss]:16332235713.197952\n",
      "iter495:[val_loss]:16680004054.46972\n",
      "iter496:[loss]:16332235713.197952\n",
      "iter496:[val_loss]:16680004054.46972\n",
      "iter497:[loss]:16332235713.197952\n",
      "iter497:[val_loss]:16680004054.46972\n",
      "iter498:[loss]:16332235713.197952\n",
      "iter498:[val_loss]:16680004054.46972\n",
      "iter499:[loss]:16332235713.197952\n",
      "iter499:[val_loss]:16680004054.46972\n"
     ]
    }
   ],
   "source": [
    "scr_lr = ScratchLinearRegression(num_iter=500, \n",
    "                                 lr=0.01, \n",
    "                                 no_bias = True,\n",
    "                                 verbose=True)\n",
    "\n",
    "scr_lr.fit(X_train_scaler, y_train, X_test_scaler, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 考察\n",
    "- 結果としてlossデータで何も値動きしないようになった。\n",
    "  - バイアス項がないことで、X（特徴量）とy（目的変数）間の係数の関係しか調べられない。切片も更新されないと係数＝直線関係の傾斜も更新されないということだと思います。\n",
    "  - 過程の計算式を含めて考察すると、最初にランダムに決まるtheta（_linear_hypothesis)の値が更新されず、何回ループしてもXとyの直線関係しか計算されないということだと思います。\n",
    "  \n",
    "- 結論\n",
    "  バイアス項（切片）があることで、thetaの値が更新され、最終的に適切な切片と各特徴量間の係数を求めることができ、適切な回帰直線を引くことができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題9】（アドバンス課題）特徴量の多次元化\n",
    "特徴量の二乗や三乗を入力に利用すると学習結果がどう変化するか検証してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化していないX_trainとX_testを2乗・3乗して計算\n",
    "X_train_2 = X_train ** 2\n",
    "X_test_2 = X_test ** 2\n",
    "X_train_3 = X_train ** 3\n",
    "X_test_3 = X_test ** 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter0:[loss]:6.61028896330827e+37\n",
      "iter0:[val_loss]:6.565009141734661e+37\n",
      "iter1:[loss]:4.199612492417478e+62\n",
      "iter1:[val_loss]:4.169350511158625e+62\n",
      "iter2:[loss]:2.679363383032737e+87\n",
      "iter2:[val_loss]:2.659956903387517e+87\n",
      "iter3:[loss]:1.7101910283057716e+112\n",
      "iter3:[val_loss]:1.697797631897649e+112\n",
      "iter4:[loss]:1.0916349155828812e+137\n",
      "iter4:[val_loss]:1.083723629985235e+137\n",
      "iter5:[loss]:6.968066171907929e+161\n",
      "iter5:[val_loss]:6.917566983926503e+161\n",
      "iter6:[loss]:4.447821274379942e+186\n",
      "iter6:[val_loss]:4.415586865228805e+186\n",
      "iter7:[loss]:2.8391112553966305e+211\n",
      "iter7:[val_loss]:2.8185355456669216e+211\n",
      "iter8:[loss]:1.8122474501368867e+236\n",
      "iter8:[val_loss]:1.7991136648158483e+236\n",
      "iter9:[loss]:1.1567848269729843e+261\n",
      "iter9:[val_loss]:1.148401334095652e+261\n",
      "iter10:[loss]:7.383931680467317e+285\n",
      "iter10:[val_loss]:7.330418583467113e+285\n",
      "iter11:[loss]:inf\n",
      "iter11:[val_loss]:inf\n",
      "iter12:[loss]:inf\n",
      "iter12:[val_loss]:inf\n",
      "iter13:[loss]:inf\n",
      "iter13:[val_loss]:inf\n",
      "iter14:[loss]:inf\n",
      "iter14:[val_loss]:inf\n",
      "iter15:[loss]:inf\n",
      "iter15:[val_loss]:inf\n",
      "iter16:[loss]:inf\n",
      "iter16:[val_loss]:inf\n",
      "iter17:[loss]:inf\n",
      "iter17:[val_loss]:inf\n",
      "iter18:[loss]:inf\n",
      "iter18:[val_loss]:inf\n",
      "iter19:[loss]:inf\n",
      "iter19:[val_loss]:inf\n",
      "iter20:[loss]:inf\n",
      "iter20:[val_loss]:inf\n",
      "iter21:[loss]:inf\n",
      "iter21:[val_loss]:inf\n",
      "iter22:[loss]:inf\n",
      "iter22:[val_loss]:inf\n",
      "iter23:[loss]:inf\n",
      "iter23:[val_loss]:inf\n",
      "iter24:[loss]:inf\n",
      "iter24:[val_loss]:inf\n",
      "iter25:[loss]:nan\n",
      "iter25:[val_loss]:nan\n",
      "iter26:[loss]:nan\n",
      "iter26:[val_loss]:nan\n",
      "iter27:[loss]:nan\n",
      "iter27:[val_loss]:nan\n",
      "iter28:[loss]:nan\n",
      "iter28:[val_loss]:nan\n",
      "iter29:[loss]:nan\n",
      "iter29:[val_loss]:nan\n",
      "iter30:[loss]:nan\n",
      "iter30:[val_loss]:nan\n",
      "iter31:[loss]:nan\n",
      "iter31:[val_loss]:nan\n",
      "iter32:[loss]:nan\n",
      "iter32:[val_loss]:nan\n",
      "iter33:[loss]:nan\n",
      "iter33:[val_loss]:nan\n",
      "iter34:[loss]:nan\n",
      "iter34:[val_loss]:nan\n",
      "iter35:[loss]:nan\n",
      "iter35:[val_loss]:nan\n",
      "iter36:[loss]:nan\n",
      "iter36:[val_loss]:nan\n",
      "iter37:[loss]:nan\n",
      "iter37:[val_loss]:nan\n",
      "iter38:[loss]:nan\n",
      "iter38:[val_loss]:nan\n",
      "iter39:[loss]:nan\n",
      "iter39:[val_loss]:nan\n",
      "iter40:[loss]:nan\n",
      "iter40:[val_loss]:nan\n",
      "iter41:[loss]:nan\n",
      "iter41:[val_loss]:nan\n",
      "iter42:[loss]:nan\n",
      "iter42:[val_loss]:nan\n",
      "iter43:[loss]:nan\n",
      "iter43:[val_loss]:nan\n",
      "iter44:[loss]:nan\n",
      "iter44:[val_loss]:nan\n",
      "iter45:[loss]:nan\n",
      "iter45:[val_loss]:nan\n",
      "iter46:[loss]:nan\n",
      "iter46:[val_loss]:nan\n",
      "iter47:[loss]:nan\n",
      "iter47:[val_loss]:nan\n",
      "iter48:[loss]:nan\n",
      "iter48:[val_loss]:nan\n",
      "iter49:[loss]:nan\n",
      "iter49:[val_loss]:nan\n",
      "iter50:[loss]:nan\n",
      "iter50:[val_loss]:nan\n",
      "iter51:[loss]:nan\n",
      "iter51:[val_loss]:nan\n",
      "iter52:[loss]:nan\n",
      "iter52:[val_loss]:nan\n",
      "iter53:[loss]:nan\n",
      "iter53:[val_loss]:nan\n",
      "iter54:[loss]:nan\n",
      "iter54:[val_loss]:nan\n",
      "iter55:[loss]:nan\n",
      "iter55:[val_loss]:nan\n",
      "iter56:[loss]:nan\n",
      "iter56:[val_loss]:nan\n",
      "iter57:[loss]:nan\n",
      "iter57:[val_loss]:nan\n",
      "iter58:[loss]:nan\n",
      "iter58:[val_loss]:nan\n",
      "iter59:[loss]:nan\n",
      "iter59:[val_loss]:nan\n",
      "iter60:[loss]:nan\n",
      "iter60:[val_loss]:nan\n",
      "iter61:[loss]:nan\n",
      "iter61:[val_loss]:nan\n",
      "iter62:[loss]:nan\n",
      "iter62:[val_loss]:nan\n",
      "iter63:[loss]:nan\n",
      "iter63:[val_loss]:nan\n",
      "iter64:[loss]:nan\n",
      "iter64:[val_loss]:nan\n",
      "iter65:[loss]:nan\n",
      "iter65:[val_loss]:nan\n",
      "iter66:[loss]:nan\n",
      "iter66:[val_loss]:nan\n",
      "iter67:[loss]:nan\n",
      "iter67:[val_loss]:nan\n",
      "iter68:[loss]:nan\n",
      "iter68:[val_loss]:nan\n",
      "iter69:[loss]:nan\n",
      "iter69:[val_loss]:nan\n",
      "iter70:[loss]:nan\n",
      "iter70:[val_loss]:nan\n",
      "iter71:[loss]:nan\n",
      "iter71:[val_loss]:nan\n",
      "iter72:[loss]:nan\n",
      "iter72:[val_loss]:nan\n",
      "iter73:[loss]:nan\n",
      "iter73:[val_loss]:nan\n",
      "iter74:[loss]:nan\n",
      "iter74:[val_loss]:nan\n",
      "iter75:[loss]:nan\n",
      "iter75:[val_loss]:nan\n",
      "iter76:[loss]:nan\n",
      "iter76:[val_loss]:nan\n",
      "iter77:[loss]:nan\n",
      "iter77:[val_loss]:nan\n",
      "iter78:[loss]:nan\n",
      "iter78:[val_loss]:nan\n",
      "iter79:[loss]:nan\n",
      "iter79:[val_loss]:nan\n",
      "iter80:[loss]:nan\n",
      "iter80:[val_loss]:nan\n",
      "iter81:[loss]:nan\n",
      "iter81:[val_loss]:nan\n",
      "iter82:[loss]:nan\n",
      "iter82:[val_loss]:nan\n",
      "iter83:[loss]:nan\n",
      "iter83:[val_loss]:nan\n",
      "iter84:[loss]:nan\n",
      "iter84:[val_loss]:nan\n",
      "iter85:[loss]:nan\n",
      "iter85:[val_loss]:nan\n",
      "iter86:[loss]:nan\n",
      "iter86:[val_loss]:nan\n",
      "iter87:[loss]:nan\n",
      "iter87:[val_loss]:nan\n",
      "iter88:[loss]:nan\n",
      "iter88:[val_loss]:nan\n",
      "iter89:[loss]:nan\n",
      "iter89:[val_loss]:nan\n",
      "iter90:[loss]:nan\n",
      "iter90:[val_loss]:nan\n",
      "iter91:[loss]:nan\n",
      "iter91:[val_loss]:nan\n",
      "iter92:[loss]:nan\n",
      "iter92:[val_loss]:nan\n",
      "iter93:[loss]:nan\n",
      "iter93:[val_loss]:nan\n",
      "iter94:[loss]:nan\n",
      "iter94:[val_loss]:nan\n",
      "iter95:[loss]:nan\n",
      "iter95:[val_loss]:nan\n",
      "iter96:[loss]:nan\n",
      "iter96:[val_loss]:nan\n",
      "iter97:[loss]:nan\n",
      "iter97:[val_loss]:nan\n",
      "iter98:[loss]:nan\n",
      "iter98:[val_loss]:nan\n",
      "iter99:[loss]:nan\n",
      "iter99:[val_loss]:nan\n",
      "iter100:[loss]:nan\n",
      "iter100:[val_loss]:nan\n",
      "iter101:[loss]:nan\n",
      "iter101:[val_loss]:nan\n",
      "iter102:[loss]:nan\n",
      "iter102:[val_loss]:nan\n",
      "iter103:[loss]:nan\n",
      "iter103:[val_loss]:nan\n",
      "iter104:[loss]:nan\n",
      "iter104:[val_loss]:nan\n",
      "iter105:[loss]:nan\n",
      "iter105:[val_loss]:nan\n",
      "iter106:[loss]:nan\n",
      "iter106:[val_loss]:nan\n",
      "iter107:[loss]:nan\n",
      "iter107:[val_loss]:nan\n",
      "iter108:[loss]:nan\n",
      "iter108:[val_loss]:nan\n",
      "iter109:[loss]:nan\n",
      "iter109:[val_loss]:nan\n",
      "iter110:[loss]:nan\n",
      "iter110:[val_loss]:nan\n",
      "iter111:[loss]:nan\n",
      "iter111:[val_loss]:nan\n",
      "iter112:[loss]:nan\n",
      "iter112:[val_loss]:nan\n",
      "iter113:[loss]:nan\n",
      "iter113:[val_loss]:nan\n",
      "iter114:[loss]:nan\n",
      "iter114:[val_loss]:nan\n",
      "iter115:[loss]:nan\n",
      "iter115:[val_loss]:nan\n",
      "iter116:[loss]:nan\n",
      "iter116:[val_loss]:nan\n",
      "iter117:[loss]:nan\n",
      "iter117:[val_loss]:nan\n",
      "iter118:[loss]:nan\n",
      "iter118:[val_loss]:nan\n",
      "iter119:[loss]:nan\n",
      "iter119:[val_loss]:nan\n",
      "iter120:[loss]:nan\n",
      "iter120:[val_loss]:nan\n",
      "iter121:[loss]:nan\n",
      "iter121:[val_loss]:nan\n",
      "iter122:[loss]:nan\n",
      "iter122:[val_loss]:nan\n",
      "iter123:[loss]:nan\n",
      "iter123:[val_loss]:nan\n",
      "iter124:[loss]:nan\n",
      "iter124:[val_loss]:nan\n",
      "iter125:[loss]:nan\n",
      "iter125:[val_loss]:nan\n",
      "iter126:[loss]:nan\n",
      "iter126:[val_loss]:nan\n",
      "iter127:[loss]:nan\n",
      "iter127:[val_loss]:nan\n",
      "iter128:[loss]:nan\n",
      "iter128:[val_loss]:nan\n",
      "iter129:[loss]:nan\n",
      "iter129:[val_loss]:nan\n",
      "iter130:[loss]:nan\n",
      "iter130:[val_loss]:nan\n",
      "iter131:[loss]:nan\n",
      "iter131:[val_loss]:nan\n",
      "iter132:[loss]:nan\n",
      "iter132:[val_loss]:nan\n",
      "iter133:[loss]:nan\n",
      "iter133:[val_loss]:nan\n",
      "iter134:[loss]:nan\n",
      "iter134:[val_loss]:nan\n",
      "iter135:[loss]:nan\n",
      "iter135:[val_loss]:nan\n",
      "iter136:[loss]:nan\n",
      "iter136:[val_loss]:nan\n",
      "iter137:[loss]:nan\n",
      "iter137:[val_loss]:nan\n",
      "iter138:[loss]:nan\n",
      "iter138:[val_loss]:nan\n",
      "iter139:[loss]:nan\n",
      "iter139:[val_loss]:nan\n",
      "iter140:[loss]:nan\n",
      "iter140:[val_loss]:nan\n",
      "iter141:[loss]:nan\n",
      "iter141:[val_loss]:nan\n",
      "iter142:[loss]:nan\n",
      "iter142:[val_loss]:nan\n",
      "iter143:[loss]:nan\n",
      "iter143:[val_loss]:nan\n",
      "iter144:[loss]:nan\n",
      "iter144:[val_loss]:nan\n",
      "iter145:[loss]:nan\n",
      "iter145:[val_loss]:nan\n",
      "iter146:[loss]:nan\n",
      "iter146:[val_loss]:nan\n",
      "iter147:[loss]:nan\n",
      "iter147:[val_loss]:nan\n",
      "iter148:[loss]:nan\n",
      "iter148:[val_loss]:nan\n",
      "iter149:[loss]:nan\n",
      "iter149:[val_loss]:nan\n",
      "iter150:[loss]:nan\n",
      "iter150:[val_loss]:nan\n",
      "iter151:[loss]:nan\n",
      "iter151:[val_loss]:nan\n",
      "iter152:[loss]:nan\n",
      "iter152:[val_loss]:nan\n",
      "iter153:[loss]:nan\n",
      "iter153:[val_loss]:nan\n",
      "iter154:[loss]:nan\n",
      "iter154:[val_loss]:nan\n",
      "iter155:[loss]:nan\n",
      "iter155:[val_loss]:nan\n",
      "iter156:[loss]:nan\n",
      "iter156:[val_loss]:nan\n",
      "iter157:[loss]:nan\n",
      "iter157:[val_loss]:nan\n",
      "iter158:[loss]:nan\n",
      "iter158:[val_loss]:nan\n",
      "iter159:[loss]:nan\n",
      "iter159:[val_loss]:nan\n",
      "iter160:[loss]:nan\n",
      "iter160:[val_loss]:nan\n",
      "iter161:[loss]:nan\n",
      "iter161:[val_loss]:nan\n",
      "iter162:[loss]:nan\n",
      "iter162:[val_loss]:nan\n",
      "iter163:[loss]:nan\n",
      "iter163:[val_loss]:nan\n",
      "iter164:[loss]:nan\n",
      "iter164:[val_loss]:nan\n",
      "iter165:[loss]:nan\n",
      "iter165:[val_loss]:nan\n",
      "iter166:[loss]:nan\n",
      "iter166:[val_loss]:nan\n",
      "iter167:[loss]:nan\n",
      "iter167:[val_loss]:nan\n",
      "iter168:[loss]:nan\n",
      "iter168:[val_loss]:nan\n",
      "iter169:[loss]:nan\n",
      "iter169:[val_loss]:nan\n",
      "iter170:[loss]:nan\n",
      "iter170:[val_loss]:nan\n",
      "iter171:[loss]:nan\n",
      "iter171:[val_loss]:nan\n",
      "iter172:[loss]:nan\n",
      "iter172:[val_loss]:nan\n",
      "iter173:[loss]:nan\n",
      "iter173:[val_loss]:nan\n",
      "iter174:[loss]:nan\n",
      "iter174:[val_loss]:nan\n",
      "iter175:[loss]:nan\n",
      "iter175:[val_loss]:nan\n",
      "iter176:[loss]:nan\n",
      "iter176:[val_loss]:nan\n",
      "iter177:[loss]:nan\n",
      "iter177:[val_loss]:nan\n",
      "iter178:[loss]:nan\n",
      "iter178:[val_loss]:nan\n",
      "iter179:[loss]:nan\n",
      "iter179:[val_loss]:nan\n",
      "iter180:[loss]:nan\n",
      "iter180:[val_loss]:nan\n",
      "iter181:[loss]:nan\n",
      "iter181:[val_loss]:nan\n",
      "iter182:[loss]:nan\n",
      "iter182:[val_loss]:nan\n",
      "iter183:[loss]:nan\n",
      "iter183:[val_loss]:nan\n",
      "iter184:[loss]:nan\n",
      "iter184:[val_loss]:nan\n",
      "iter185:[loss]:nan\n",
      "iter185:[val_loss]:nan\n",
      "iter186:[loss]:nan\n",
      "iter186:[val_loss]:nan\n",
      "iter187:[loss]:nan\n",
      "iter187:[val_loss]:nan\n",
      "iter188:[loss]:nan\n",
      "iter188:[val_loss]:nan\n",
      "iter189:[loss]:nan\n",
      "iter189:[val_loss]:nan\n",
      "iter190:[loss]:nan\n",
      "iter190:[val_loss]:nan\n",
      "iter191:[loss]:nan\n",
      "iter191:[val_loss]:nan\n",
      "iter192:[loss]:nan\n",
      "iter192:[val_loss]:nan\n",
      "iter193:[loss]:nan\n",
      "iter193:[val_loss]:nan\n",
      "iter194:[loss]:nan\n",
      "iter194:[val_loss]:nan\n",
      "iter195:[loss]:nan\n",
      "iter195:[val_loss]:nan\n",
      "iter196:[loss]:nan\n",
      "iter196:[val_loss]:nan\n",
      "iter197:[loss]:nan\n",
      "iter197:[val_loss]:nan\n",
      "iter198:[loss]:nan\n",
      "iter198:[val_loss]:nan\n",
      "iter199:[loss]:nan\n",
      "iter199:[val_loss]:nan\n",
      "iter200:[loss]:nan\n",
      "iter200:[val_loss]:nan\n",
      "iter201:[loss]:nan\n",
      "iter201:[val_loss]:nan\n",
      "iter202:[loss]:nan\n",
      "iter202:[val_loss]:nan\n",
      "iter203:[loss]:nan\n",
      "iter203:[val_loss]:nan\n",
      "iter204:[loss]:nan\n",
      "iter204:[val_loss]:nan\n",
      "iter205:[loss]:nan\n",
      "iter205:[val_loss]:nan\n",
      "iter206:[loss]:nan\n",
      "iter206:[val_loss]:nan\n",
      "iter207:[loss]:nan\n",
      "iter207:[val_loss]:nan\n",
      "iter208:[loss]:nan\n",
      "iter208:[val_loss]:nan\n",
      "iter209:[loss]:nan\n",
      "iter209:[val_loss]:nan\n",
      "iter210:[loss]:nan\n",
      "iter210:[val_loss]:nan\n",
      "iter211:[loss]:nan\n",
      "iter211:[val_loss]:nan\n",
      "iter212:[loss]:nan\n",
      "iter212:[val_loss]:nan\n",
      "iter213:[loss]:nan\n",
      "iter213:[val_loss]:nan\n",
      "iter214:[loss]:nan\n",
      "iter214:[val_loss]:nan\n",
      "iter215:[loss]:nan\n",
      "iter215:[val_loss]:nan\n",
      "iter216:[loss]:nan\n",
      "iter216:[val_loss]:nan\n",
      "iter217:[loss]:nan\n",
      "iter217:[val_loss]:nan\n",
      "iter218:[loss]:nan\n",
      "iter218:[val_loss]:nan\n",
      "iter219:[loss]:nan\n",
      "iter219:[val_loss]:nan\n",
      "iter220:[loss]:nan\n",
      "iter220:[val_loss]:nan\n",
      "iter221:[loss]:nan\n",
      "iter221:[val_loss]:nan\n",
      "iter222:[loss]:nan\n",
      "iter222:[val_loss]:nan\n",
      "iter223:[loss]:nan\n",
      "iter223:[val_loss]:nan\n",
      "iter224:[loss]:nan\n",
      "iter224:[val_loss]:nan\n",
      "iter225:[loss]:nan\n",
      "iter225:[val_loss]:nan\n",
      "iter226:[loss]:nan\n",
      "iter226:[val_loss]:nan\n",
      "iter227:[loss]:nan\n",
      "iter227:[val_loss]:nan\n",
      "iter228:[loss]:nan\n",
      "iter228:[val_loss]:nan\n",
      "iter229:[loss]:nan\n",
      "iter229:[val_loss]:nan\n",
      "iter230:[loss]:nan\n",
      "iter230:[val_loss]:nan\n",
      "iter231:[loss]:nan\n",
      "iter231:[val_loss]:nan\n",
      "iter232:[loss]:nan\n",
      "iter232:[val_loss]:nan\n",
      "iter233:[loss]:nan\n",
      "iter233:[val_loss]:nan\n",
      "iter234:[loss]:nan\n",
      "iter234:[val_loss]:nan\n",
      "iter235:[loss]:nan\n",
      "iter235:[val_loss]:nan\n",
      "iter236:[loss]:nan\n",
      "iter236:[val_loss]:nan\n",
      "iter237:[loss]:nan\n",
      "iter237:[val_loss]:nan\n",
      "iter238:[loss]:nan\n",
      "iter238:[val_loss]:nan\n",
      "iter239:[loss]:nan\n",
      "iter239:[val_loss]:nan\n",
      "iter240:[loss]:nan\n",
      "iter240:[val_loss]:nan\n",
      "iter241:[loss]:nan\n",
      "iter241:[val_loss]:nan\n",
      "iter242:[loss]:nan\n",
      "iter242:[val_loss]:nan\n",
      "iter243:[loss]:nan\n",
      "iter243:[val_loss]:nan\n",
      "iter244:[loss]:nan\n",
      "iter244:[val_loss]:nan\n",
      "iter245:[loss]:nan\n",
      "iter245:[val_loss]:nan\n",
      "iter246:[loss]:nan\n",
      "iter246:[val_loss]:nan\n",
      "iter247:[loss]:nan\n",
      "iter247:[val_loss]:nan\n",
      "iter248:[loss]:nan\n",
      "iter248:[val_loss]:nan\n",
      "iter249:[loss]:nan\n",
      "iter249:[val_loss]:nan\n",
      "iter250:[loss]:nan\n",
      "iter250:[val_loss]:nan\n",
      "iter251:[loss]:nan\n",
      "iter251:[val_loss]:nan\n",
      "iter252:[loss]:nan\n",
      "iter252:[val_loss]:nan\n",
      "iter253:[loss]:nan\n",
      "iter253:[val_loss]:nan\n",
      "iter254:[loss]:nan\n",
      "iter254:[val_loss]:nan\n",
      "iter255:[loss]:nan\n",
      "iter255:[val_loss]:nan\n",
      "iter256:[loss]:nan\n",
      "iter256:[val_loss]:nan\n",
      "iter257:[loss]:nan\n",
      "iter257:[val_loss]:nan\n",
      "iter258:[loss]:nan\n",
      "iter258:[val_loss]:nan\n",
      "iter259:[loss]:nan\n",
      "iter259:[val_loss]:nan\n",
      "iter260:[loss]:nan\n",
      "iter260:[val_loss]:nan\n",
      "iter261:[loss]:nan\n",
      "iter261:[val_loss]:nan\n",
      "iter262:[loss]:nan\n",
      "iter262:[val_loss]:nan\n",
      "iter263:[loss]:nan\n",
      "iter263:[val_loss]:nan\n",
      "iter264:[loss]:nan\n",
      "iter264:[val_loss]:nan\n",
      "iter265:[loss]:nan\n",
      "iter265:[val_loss]:nan\n",
      "iter266:[loss]:nan\n",
      "iter266:[val_loss]:nan\n",
      "iter267:[loss]:nan\n",
      "iter267:[val_loss]:nan\n",
      "iter268:[loss]:nan\n",
      "iter268:[val_loss]:nan\n",
      "iter269:[loss]:nan\n",
      "iter269:[val_loss]:nan\n",
      "iter270:[loss]:nan\n",
      "iter270:[val_loss]:nan\n",
      "iter271:[loss]:nan\n",
      "iter271:[val_loss]:nan\n",
      "iter272:[loss]:nan\n",
      "iter272:[val_loss]:nan\n",
      "iter273:[loss]:nan\n",
      "iter273:[val_loss]:nan\n",
      "iter274:[loss]:nan\n",
      "iter274:[val_loss]:nan\n",
      "iter275:[loss]:nan\n",
      "iter275:[val_loss]:nan\n",
      "iter276:[loss]:nan\n",
      "iter276:[val_loss]:nan\n",
      "iter277:[loss]:nan\n",
      "iter277:[val_loss]:nan\n",
      "iter278:[loss]:nan\n",
      "iter278:[val_loss]:nan\n",
      "iter279:[loss]:nan\n",
      "iter279:[val_loss]:nan\n",
      "iter280:[loss]:nan\n",
      "iter280:[val_loss]:nan\n",
      "iter281:[loss]:nan\n",
      "iter281:[val_loss]:nan\n",
      "iter282:[loss]:nan\n",
      "iter282:[val_loss]:nan\n",
      "iter283:[loss]:nan\n",
      "iter283:[val_loss]:nan\n",
      "iter284:[loss]:nan\n",
      "iter284:[val_loss]:nan\n",
      "iter285:[loss]:nan\n",
      "iter285:[val_loss]:nan\n",
      "iter286:[loss]:nan\n",
      "iter286:[val_loss]:nan\n",
      "iter287:[loss]:nan\n",
      "iter287:[val_loss]:nan\n",
      "iter288:[loss]:nan\n",
      "iter288:[val_loss]:nan\n",
      "iter289:[loss]:nan\n",
      "iter289:[val_loss]:nan\n",
      "iter290:[loss]:nan\n",
      "iter290:[val_loss]:nan\n",
      "iter291:[loss]:nan\n",
      "iter291:[val_loss]:nan\n",
      "iter292:[loss]:nan\n",
      "iter292:[val_loss]:nan\n",
      "iter293:[loss]:nan\n",
      "iter293:[val_loss]:nan\n",
      "iter294:[loss]:nan\n",
      "iter294:[val_loss]:nan\n",
      "iter295:[loss]:nan\n",
      "iter295:[val_loss]:nan\n",
      "iter296:[loss]:nan\n",
      "iter296:[val_loss]:nan\n",
      "iter297:[loss]:nan\n",
      "iter297:[val_loss]:nan\n",
      "iter298:[loss]:nan\n",
      "iter298:[val_loss]:nan\n",
      "iter299:[loss]:nan\n",
      "iter299:[val_loss]:nan\n",
      "iter300:[loss]:nan\n",
      "iter300:[val_loss]:nan\n",
      "iter301:[loss]:nan\n",
      "iter301:[val_loss]:nan\n",
      "iter302:[loss]:nan\n",
      "iter302:[val_loss]:nan\n",
      "iter303:[loss]:nan\n",
      "iter303:[val_loss]:nan\n",
      "iter304:[loss]:nan\n",
      "iter304:[val_loss]:nan\n",
      "iter305:[loss]:nan\n",
      "iter305:[val_loss]:nan\n",
      "iter306:[loss]:nan\n",
      "iter306:[val_loss]:nan\n",
      "iter307:[loss]:nan\n",
      "iter307:[val_loss]:nan\n",
      "iter308:[loss]:nan\n",
      "iter308:[val_loss]:nan\n",
      "iter309:[loss]:nan\n",
      "iter309:[val_loss]:nan\n",
      "iter310:[loss]:nan\n",
      "iter310:[val_loss]:nan\n",
      "iter311:[loss]:nan\n",
      "iter311:[val_loss]:nan\n",
      "iter312:[loss]:nan\n",
      "iter312:[val_loss]:nan\n",
      "iter313:[loss]:nan\n",
      "iter313:[val_loss]:nan\n",
      "iter314:[loss]:nan\n",
      "iter314:[val_loss]:nan\n",
      "iter315:[loss]:nan\n",
      "iter315:[val_loss]:nan\n",
      "iter316:[loss]:nan\n",
      "iter316:[val_loss]:nan\n",
      "iter317:[loss]:nan\n",
      "iter317:[val_loss]:nan\n",
      "iter318:[loss]:nan\n",
      "iter318:[val_loss]:nan\n",
      "iter319:[loss]:nan\n",
      "iter319:[val_loss]:nan\n",
      "iter320:[loss]:nan\n",
      "iter320:[val_loss]:nan\n",
      "iter321:[loss]:nan\n",
      "iter321:[val_loss]:nan\n",
      "iter322:[loss]:nan\n",
      "iter322:[val_loss]:nan\n",
      "iter323:[loss]:nan\n",
      "iter323:[val_loss]:nan\n",
      "iter324:[loss]:nan\n",
      "iter324:[val_loss]:nan\n",
      "iter325:[loss]:nan\n",
      "iter325:[val_loss]:nan\n",
      "iter326:[loss]:nan\n",
      "iter326:[val_loss]:nan\n",
      "iter327:[loss]:nan\n",
      "iter327:[val_loss]:nan\n",
      "iter328:[loss]:nan\n",
      "iter328:[val_loss]:nan\n",
      "iter329:[loss]:nan\n",
      "iter329:[val_loss]:nan\n",
      "iter330:[loss]:nan\n",
      "iter330:[val_loss]:nan\n",
      "iter331:[loss]:nan\n",
      "iter331:[val_loss]:nan\n",
      "iter332:[loss]:nan\n",
      "iter332:[val_loss]:nan\n",
      "iter333:[loss]:nan\n",
      "iter333:[val_loss]:nan\n",
      "iter334:[loss]:nan\n",
      "iter334:[val_loss]:nan\n",
      "iter335:[loss]:nan\n",
      "iter335:[val_loss]:nan\n",
      "iter336:[loss]:nan\n",
      "iter336:[val_loss]:nan\n",
      "iter337:[loss]:nan\n",
      "iter337:[val_loss]:nan\n",
      "iter338:[loss]:nan\n",
      "iter338:[val_loss]:nan\n",
      "iter339:[loss]:nan\n",
      "iter339:[val_loss]:nan\n",
      "iter340:[loss]:nan\n",
      "iter340:[val_loss]:nan\n",
      "iter341:[loss]:nan\n",
      "iter341:[val_loss]:nan\n",
      "iter342:[loss]:nan\n",
      "iter342:[val_loss]:nan\n",
      "iter343:[loss]:nan\n",
      "iter343:[val_loss]:nan\n",
      "iter344:[loss]:nan\n",
      "iter344:[val_loss]:nan\n",
      "iter345:[loss]:nan\n",
      "iter345:[val_loss]:nan\n",
      "iter346:[loss]:nan\n",
      "iter346:[val_loss]:nan\n",
      "iter347:[loss]:nan\n",
      "iter347:[val_loss]:nan\n",
      "iter348:[loss]:nan\n",
      "iter348:[val_loss]:nan\n",
      "iter349:[loss]:nan\n",
      "iter349:[val_loss]:nan\n",
      "iter350:[loss]:nan\n",
      "iter350:[val_loss]:nan\n",
      "iter351:[loss]:nan\n",
      "iter351:[val_loss]:nan\n",
      "iter352:[loss]:nan\n",
      "iter352:[val_loss]:nan\n",
      "iter353:[loss]:nan\n",
      "iter353:[val_loss]:nan\n",
      "iter354:[loss]:nan\n",
      "iter354:[val_loss]:nan\n",
      "iter355:[loss]:nan\n",
      "iter355:[val_loss]:nan\n",
      "iter356:[loss]:nan\n",
      "iter356:[val_loss]:nan\n",
      "iter357:[loss]:nan\n",
      "iter357:[val_loss]:nan\n",
      "iter358:[loss]:nan\n",
      "iter358:[val_loss]:nan\n",
      "iter359:[loss]:nan\n",
      "iter359:[val_loss]:nan\n",
      "iter360:[loss]:nan\n",
      "iter360:[val_loss]:nan\n",
      "iter361:[loss]:nan\n",
      "iter361:[val_loss]:nan\n",
      "iter362:[loss]:nan\n",
      "iter362:[val_loss]:nan\n",
      "iter363:[loss]:nan\n",
      "iter363:[val_loss]:nan\n",
      "iter364:[loss]:nan\n",
      "iter364:[val_loss]:nan\n",
      "iter365:[loss]:nan\n",
      "iter365:[val_loss]:nan\n",
      "iter366:[loss]:nan\n",
      "iter366:[val_loss]:nan\n",
      "iter367:[loss]:nan\n",
      "iter367:[val_loss]:nan\n",
      "iter368:[loss]:nan\n",
      "iter368:[val_loss]:nan\n",
      "iter369:[loss]:nan\n",
      "iter369:[val_loss]:nan\n",
      "iter370:[loss]:nan\n",
      "iter370:[val_loss]:nan\n",
      "iter371:[loss]:nan\n",
      "iter371:[val_loss]:nan\n",
      "iter372:[loss]:nan\n",
      "iter372:[val_loss]:nan\n",
      "iter373:[loss]:nan\n",
      "iter373:[val_loss]:nan\n",
      "iter374:[loss]:nan\n",
      "iter374:[val_loss]:nan\n",
      "iter375:[loss]:nan\n",
      "iter375:[val_loss]:nan\n",
      "iter376:[loss]:nan\n",
      "iter376:[val_loss]:nan\n",
      "iter377:[loss]:nan\n",
      "iter377:[val_loss]:nan\n",
      "iter378:[loss]:nan\n",
      "iter378:[val_loss]:nan\n",
      "iter379:[loss]:nan\n",
      "iter379:[val_loss]:nan\n",
      "iter380:[loss]:nan\n",
      "iter380:[val_loss]:nan\n",
      "iter381:[loss]:nan\n",
      "iter381:[val_loss]:nan\n",
      "iter382:[loss]:nan\n",
      "iter382:[val_loss]:nan\n",
      "iter383:[loss]:nan\n",
      "iter383:[val_loss]:nan\n",
      "iter384:[loss]:nan\n",
      "iter384:[val_loss]:nan\n",
      "iter385:[loss]:nan\n",
      "iter385:[val_loss]:nan\n",
      "iter386:[loss]:nan\n",
      "iter386:[val_loss]:nan\n",
      "iter387:[loss]:nan\n",
      "iter387:[val_loss]:nan\n",
      "iter388:[loss]:nan\n",
      "iter388:[val_loss]:nan\n",
      "iter389:[loss]:nan\n",
      "iter389:[val_loss]:nan\n",
      "iter390:[loss]:nan\n",
      "iter390:[val_loss]:nan\n",
      "iter391:[loss]:nan\n",
      "iter391:[val_loss]:nan\n",
      "iter392:[loss]:nan\n",
      "iter392:[val_loss]:nan\n",
      "iter393:[loss]:nan\n",
      "iter393:[val_loss]:nan\n",
      "iter394:[loss]:nan\n",
      "iter394:[val_loss]:nan\n",
      "iter395:[loss]:nan\n",
      "iter395:[val_loss]:nan\n",
      "iter396:[loss]:nan\n",
      "iter396:[val_loss]:nan\n",
      "iter397:[loss]:nan\n",
      "iter397:[val_loss]:nan\n",
      "iter398:[loss]:nan\n",
      "iter398:[val_loss]:nan\n",
      "iter399:[loss]:nan\n",
      "iter399:[val_loss]:nan\n",
      "iter400:[loss]:nan\n",
      "iter400:[val_loss]:nan\n",
      "iter401:[loss]:nan\n",
      "iter401:[val_loss]:nan\n",
      "iter402:[loss]:nan\n",
      "iter402:[val_loss]:nan\n",
      "iter403:[loss]:nan\n",
      "iter403:[val_loss]:nan\n",
      "iter404:[loss]:nan\n",
      "iter404:[val_loss]:nan\n",
      "iter405:[loss]:nan\n",
      "iter405:[val_loss]:nan\n",
      "iter406:[loss]:nan\n",
      "iter406:[val_loss]:nan\n",
      "iter407:[loss]:nan\n",
      "iter407:[val_loss]:nan\n",
      "iter408:[loss]:nan\n",
      "iter408:[val_loss]:nan\n",
      "iter409:[loss]:nan\n",
      "iter409:[val_loss]:nan\n",
      "iter410:[loss]:nan\n",
      "iter410:[val_loss]:nan\n",
      "iter411:[loss]:nan\n",
      "iter411:[val_loss]:nan\n",
      "iter412:[loss]:nan\n",
      "iter412:[val_loss]:nan\n",
      "iter413:[loss]:nan\n",
      "iter413:[val_loss]:nan\n",
      "iter414:[loss]:nan\n",
      "iter414:[val_loss]:nan\n",
      "iter415:[loss]:nan\n",
      "iter415:[val_loss]:nan\n",
      "iter416:[loss]:nan\n",
      "iter416:[val_loss]:nan\n",
      "iter417:[loss]:nan\n",
      "iter417:[val_loss]:nan\n",
      "iter418:[loss]:nan\n",
      "iter418:[val_loss]:nan\n",
      "iter419:[loss]:nan\n",
      "iter419:[val_loss]:nan\n",
      "iter420:[loss]:nan\n",
      "iter420:[val_loss]:nan\n",
      "iter421:[loss]:nan\n",
      "iter421:[val_loss]:nan\n",
      "iter422:[loss]:nan\n",
      "iter422:[val_loss]:nan\n",
      "iter423:[loss]:nan\n",
      "iter423:[val_loss]:nan\n",
      "iter424:[loss]:nan\n",
      "iter424:[val_loss]:nan\n",
      "iter425:[loss]:nan\n",
      "iter425:[val_loss]:nan\n",
      "iter426:[loss]:nan\n",
      "iter426:[val_loss]:nan\n",
      "iter427:[loss]:nan\n",
      "iter427:[val_loss]:nan\n",
      "iter428:[loss]:nan\n",
      "iter428:[val_loss]:nan\n",
      "iter429:[loss]:nan\n",
      "iter429:[val_loss]:nan\n",
      "iter430:[loss]:nan\n",
      "iter430:[val_loss]:nan\n",
      "iter431:[loss]:nan\n",
      "iter431:[val_loss]:nan\n",
      "iter432:[loss]:nan\n",
      "iter432:[val_loss]:nan\n",
      "iter433:[loss]:nan\n",
      "iter433:[val_loss]:nan\n",
      "iter434:[loss]:nan\n",
      "iter434:[val_loss]:nan\n",
      "iter435:[loss]:nan\n",
      "iter435:[val_loss]:nan\n",
      "iter436:[loss]:nan\n",
      "iter436:[val_loss]:nan\n",
      "iter437:[loss]:nan\n",
      "iter437:[val_loss]:nan\n",
      "iter438:[loss]:nan\n",
      "iter438:[val_loss]:nan\n",
      "iter439:[loss]:nan\n",
      "iter439:[val_loss]:nan\n",
      "iter440:[loss]:nan\n",
      "iter440:[val_loss]:nan\n",
      "iter441:[loss]:nan\n",
      "iter441:[val_loss]:nan\n",
      "iter442:[loss]:nan\n",
      "iter442:[val_loss]:nan\n",
      "iter443:[loss]:nan\n",
      "iter443:[val_loss]:nan\n",
      "iter444:[loss]:nan\n",
      "iter444:[val_loss]:nan\n",
      "iter445:[loss]:nan\n",
      "iter445:[val_loss]:nan\n",
      "iter446:[loss]:nan\n",
      "iter446:[val_loss]:nan\n",
      "iter447:[loss]:nan\n",
      "iter447:[val_loss]:nan\n",
      "iter448:[loss]:nan\n",
      "iter448:[val_loss]:nan\n",
      "iter449:[loss]:nan\n",
      "iter449:[val_loss]:nan\n",
      "iter450:[loss]:nan\n",
      "iter450:[val_loss]:nan\n",
      "iter451:[loss]:nan\n",
      "iter451:[val_loss]:nan\n",
      "iter452:[loss]:nan\n",
      "iter452:[val_loss]:nan\n",
      "iter453:[loss]:nan\n",
      "iter453:[val_loss]:nan\n",
      "iter454:[loss]:nan\n",
      "iter454:[val_loss]:nan\n",
      "iter455:[loss]:nan\n",
      "iter455:[val_loss]:nan\n",
      "iter456:[loss]:nan\n",
      "iter456:[val_loss]:nan\n",
      "iter457:[loss]:nan\n",
      "iter457:[val_loss]:nan\n",
      "iter458:[loss]:nan\n",
      "iter458:[val_loss]:nan\n",
      "iter459:[loss]:nan\n",
      "iter459:[val_loss]:nan\n",
      "iter460:[loss]:nan\n",
      "iter460:[val_loss]:nan\n",
      "iter461:[loss]:nan\n",
      "iter461:[val_loss]:nan\n",
      "iter462:[loss]:nan\n",
      "iter462:[val_loss]:nan\n",
      "iter463:[loss]:nan\n",
      "iter463:[val_loss]:nan\n",
      "iter464:[loss]:nan\n",
      "iter464:[val_loss]:nan\n",
      "iter465:[loss]:nan\n",
      "iter465:[val_loss]:nan\n",
      "iter466:[loss]:nan\n",
      "iter466:[val_loss]:nan\n",
      "iter467:[loss]:nan\n",
      "iter467:[val_loss]:nan\n",
      "iter468:[loss]:nan\n",
      "iter468:[val_loss]:nan\n",
      "iter469:[loss]:nan\n",
      "iter469:[val_loss]:nan\n",
      "iter470:[loss]:nan\n",
      "iter470:[val_loss]:nan\n",
      "iter471:[loss]:nan\n",
      "iter471:[val_loss]:nan\n",
      "iter472:[loss]:nan\n",
      "iter472:[val_loss]:nan\n",
      "iter473:[loss]:nan\n",
      "iter473:[val_loss]:nan\n",
      "iter474:[loss]:nan\n",
      "iter474:[val_loss]:nan\n",
      "iter475:[loss]:nan\n",
      "iter475:[val_loss]:nan\n",
      "iter476:[loss]:nan\n",
      "iter476:[val_loss]:nan\n",
      "iter477:[loss]:nan\n",
      "iter477:[val_loss]:nan\n",
      "iter478:[loss]:nan\n",
      "iter478:[val_loss]:nan\n",
      "iter479:[loss]:nan\n",
      "iter479:[val_loss]:nan\n",
      "iter480:[loss]:nan\n",
      "iter480:[val_loss]:nan\n",
      "iter481:[loss]:nan\n",
      "iter481:[val_loss]:nan\n",
      "iter482:[loss]:nan\n",
      "iter482:[val_loss]:nan\n",
      "iter483:[loss]:nan\n",
      "iter483:[val_loss]:nan\n",
      "iter484:[loss]:nan\n",
      "iter484:[val_loss]:nan\n",
      "iter485:[loss]:nan\n",
      "iter485:[val_loss]:nan\n",
      "iter486:[loss]:nan\n",
      "iter486:[val_loss]:nan\n",
      "iter487:[loss]:nan\n",
      "iter487:[val_loss]:nan\n",
      "iter488:[loss]:nan\n",
      "iter488:[val_loss]:nan\n",
      "iter489:[loss]:nan\n",
      "iter489:[val_loss]:nan\n",
      "iter490:[loss]:nan\n",
      "iter490:[val_loss]:nan\n",
      "iter491:[loss]:nan\n",
      "iter491:[val_loss]:nan\n",
      "iter492:[loss]:nan\n",
      "iter492:[val_loss]:nan\n",
      "iter493:[loss]:nan\n",
      "iter493:[val_loss]:nan\n",
      "iter494:[loss]:nan\n",
      "iter494:[val_loss]:nan\n",
      "iter495:[loss]:nan\n",
      "iter495:[val_loss]:nan\n",
      "iter496:[loss]:nan\n",
      "iter496:[val_loss]:nan\n",
      "iter497:[loss]:nan\n",
      "iter497:[val_loss]:nan\n",
      "iter498:[loss]:nan\n",
      "iter498:[val_loss]:nan\n",
      "iter499:[loss]:nan\n",
      "iter499:[val_loss]:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adachi-yuya/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/ipykernel_launcher.py:179: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/adachi-yuya/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/ipykernel_launcher.py:194: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/adachi-yuya/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/ipykernel_launcher.py:147: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    }
   ],
   "source": [
    "scr_lr2 = ScratchLinearRegression(num_iter=500, \n",
    "                                 lr=0.01, \n",
    "                                 no_bias = False,\n",
    "                                 verbose=True)\n",
    "\n",
    "scr_lr2.fit(X_train_2, y_train, X_test_2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter0:[loss]:4.504821434256266e+57\n",
      "iter0:[val_loss]:4.641010560652106e+57\n",
      "iter1:[loss]:5.2032522857682434e+95\n",
      "iter1:[val_loss]:5.377163592959146e+95\n",
      "iter2:[loss]:6.23152383284328e+133\n",
      "iter2:[val_loss]:6.444872202231301e+133\n",
      "iter3:[loss]:7.53132348557672e+171\n",
      "iter3:[val_loss]:7.790698034593165e+171\n",
      "iter4:[loss]:9.122850579842947e+209\n",
      "iter4:[val_loss]:9.437493611174878e+209\n",
      "iter5:[loss]:1.1056883308748838e+248\n",
      "iter5:[val_loss]:1.1438367199730324e+248\n",
      "iter6:[loss]:1.3402780606314682e+286\n",
      "iter6:[val_loss]:1.3865243504609071e+286\n",
      "iter7:[loss]:inf\n",
      "iter7:[val_loss]:inf\n",
      "iter8:[loss]:inf\n",
      "iter8:[val_loss]:inf\n",
      "iter9:[loss]:inf\n",
      "iter9:[val_loss]:inf\n",
      "iter10:[loss]:inf\n",
      "iter10:[val_loss]:inf\n",
      "iter11:[loss]:inf\n",
      "iter11:[val_loss]:inf\n",
      "iter12:[loss]:inf\n",
      "iter12:[val_loss]:inf\n",
      "iter13:[loss]:inf\n",
      "iter13:[val_loss]:inf\n",
      "iter14:[loss]:inf\n",
      "iter14:[val_loss]:inf\n",
      "iter15:[loss]:inf\n",
      "iter15:[val_loss]:inf\n",
      "iter16:[loss]:nan\n",
      "iter16:[val_loss]:nan\n",
      "iter17:[loss]:nan\n",
      "iter17:[val_loss]:nan\n",
      "iter18:[loss]:nan\n",
      "iter18:[val_loss]:nan\n",
      "iter19:[loss]:nan\n",
      "iter19:[val_loss]:nan\n",
      "iter20:[loss]:nan\n",
      "iter20:[val_loss]:nan\n",
      "iter21:[loss]:nan\n",
      "iter21:[val_loss]:nan\n",
      "iter22:[loss]:nan\n",
      "iter22:[val_loss]:nan\n",
      "iter23:[loss]:nan\n",
      "iter23:[val_loss]:nan\n",
      "iter24:[loss]:nan\n",
      "iter24:[val_loss]:nan\n",
      "iter25:[loss]:nan\n",
      "iter25:[val_loss]:nan\n",
      "iter26:[loss]:nan\n",
      "iter26:[val_loss]:nan\n",
      "iter27:[loss]:nan\n",
      "iter27:[val_loss]:nan\n",
      "iter28:[loss]:nan\n",
      "iter28:[val_loss]:nan\n",
      "iter29:[loss]:nan\n",
      "iter29:[val_loss]:nan\n",
      "iter30:[loss]:nan\n",
      "iter30:[val_loss]:nan\n",
      "iter31:[loss]:nan\n",
      "iter31:[val_loss]:nan\n",
      "iter32:[loss]:nan\n",
      "iter32:[val_loss]:nan\n",
      "iter33:[loss]:nan\n",
      "iter33:[val_loss]:nan\n",
      "iter34:[loss]:nan\n",
      "iter34:[val_loss]:nan\n",
      "iter35:[loss]:nan\n",
      "iter35:[val_loss]:nan\n",
      "iter36:[loss]:nan\n",
      "iter36:[val_loss]:nan\n",
      "iter37:[loss]:nan\n",
      "iter37:[val_loss]:nan\n",
      "iter38:[loss]:nan\n",
      "iter38:[val_loss]:nan\n",
      "iter39:[loss]:nan\n",
      "iter39:[val_loss]:nan\n",
      "iter40:[loss]:nan\n",
      "iter40:[val_loss]:nan\n",
      "iter41:[loss]:nan\n",
      "iter41:[val_loss]:nan\n",
      "iter42:[loss]:nan\n",
      "iter42:[val_loss]:nan\n",
      "iter43:[loss]:nan\n",
      "iter43:[val_loss]:nan\n",
      "iter44:[loss]:nan\n",
      "iter44:[val_loss]:nan\n",
      "iter45:[loss]:nan\n",
      "iter45:[val_loss]:nan\n",
      "iter46:[loss]:nan\n",
      "iter46:[val_loss]:nan\n",
      "iter47:[loss]:nan\n",
      "iter47:[val_loss]:nan\n",
      "iter48:[loss]:nan\n",
      "iter48:[val_loss]:nan\n",
      "iter49:[loss]:nan\n",
      "iter49:[val_loss]:nan\n",
      "iter50:[loss]:nan\n",
      "iter50:[val_loss]:nan\n",
      "iter51:[loss]:nan\n",
      "iter51:[val_loss]:nan\n",
      "iter52:[loss]:nan\n",
      "iter52:[val_loss]:nan\n",
      "iter53:[loss]:nan\n",
      "iter53:[val_loss]:nan\n",
      "iter54:[loss]:nan\n",
      "iter54:[val_loss]:nan\n",
      "iter55:[loss]:nan\n",
      "iter55:[val_loss]:nan\n",
      "iter56:[loss]:nan\n",
      "iter56:[val_loss]:nan\n",
      "iter57:[loss]:nan\n",
      "iter57:[val_loss]:nan\n",
      "iter58:[loss]:nan\n",
      "iter58:[val_loss]:nan\n",
      "iter59:[loss]:nan\n",
      "iter59:[val_loss]:nan\n",
      "iter60:[loss]:nan\n",
      "iter60:[val_loss]:nan\n",
      "iter61:[loss]:nan\n",
      "iter61:[val_loss]:nan\n",
      "iter62:[loss]:nan\n",
      "iter62:[val_loss]:nan\n",
      "iter63:[loss]:nan\n",
      "iter63:[val_loss]:nan\n",
      "iter64:[loss]:nan\n",
      "iter64:[val_loss]:nan\n",
      "iter65:[loss]:nan\n",
      "iter65:[val_loss]:nan\n",
      "iter66:[loss]:nan\n",
      "iter66:[val_loss]:nan\n",
      "iter67:[loss]:nan\n",
      "iter67:[val_loss]:nan\n",
      "iter68:[loss]:nan\n",
      "iter68:[val_loss]:nan\n",
      "iter69:[loss]:nan\n",
      "iter69:[val_loss]:nan\n",
      "iter70:[loss]:nan\n",
      "iter70:[val_loss]:nan\n",
      "iter71:[loss]:nan\n",
      "iter71:[val_loss]:nan\n",
      "iter72:[loss]:nan\n",
      "iter72:[val_loss]:nan\n",
      "iter73:[loss]:nan\n",
      "iter73:[val_loss]:nan\n",
      "iter74:[loss]:nan\n",
      "iter74:[val_loss]:nan\n",
      "iter75:[loss]:nan\n",
      "iter75:[val_loss]:nan\n",
      "iter76:[loss]:nan\n",
      "iter76:[val_loss]:nan\n",
      "iter77:[loss]:nan\n",
      "iter77:[val_loss]:nan\n",
      "iter78:[loss]:nan\n",
      "iter78:[val_loss]:nan\n",
      "iter79:[loss]:nan\n",
      "iter79:[val_loss]:nan\n",
      "iter80:[loss]:nan\n",
      "iter80:[val_loss]:nan\n",
      "iter81:[loss]:nan\n",
      "iter81:[val_loss]:nan\n",
      "iter82:[loss]:nan\n",
      "iter82:[val_loss]:nan\n",
      "iter83:[loss]:nan\n",
      "iter83:[val_loss]:nan\n",
      "iter84:[loss]:nan\n",
      "iter84:[val_loss]:nan\n",
      "iter85:[loss]:nan\n",
      "iter85:[val_loss]:nan\n",
      "iter86:[loss]:nan\n",
      "iter86:[val_loss]:nan\n",
      "iter87:[loss]:nan\n",
      "iter87:[val_loss]:nan\n",
      "iter88:[loss]:nan\n",
      "iter88:[val_loss]:nan\n",
      "iter89:[loss]:nan\n",
      "iter89:[val_loss]:nan\n",
      "iter90:[loss]:nan\n",
      "iter90:[val_loss]:nan\n",
      "iter91:[loss]:nan\n",
      "iter91:[val_loss]:nan\n",
      "iter92:[loss]:nan\n",
      "iter92:[val_loss]:nan\n",
      "iter93:[loss]:nan\n",
      "iter93:[val_loss]:nan\n",
      "iter94:[loss]:nan\n",
      "iter94:[val_loss]:nan\n",
      "iter95:[loss]:nan\n",
      "iter95:[val_loss]:nan\n",
      "iter96:[loss]:nan\n",
      "iter96:[val_loss]:nan\n",
      "iter97:[loss]:nan\n",
      "iter97:[val_loss]:nan\n",
      "iter98:[loss]:nan\n",
      "iter98:[val_loss]:nan\n",
      "iter99:[loss]:nan\n",
      "iter99:[val_loss]:nan\n",
      "iter100:[loss]:nan\n",
      "iter100:[val_loss]:nan\n",
      "iter101:[loss]:nan\n",
      "iter101:[val_loss]:nan\n",
      "iter102:[loss]:nan\n",
      "iter102:[val_loss]:nan\n",
      "iter103:[loss]:nan\n",
      "iter103:[val_loss]:nan\n",
      "iter104:[loss]:nan\n",
      "iter104:[val_loss]:nan\n",
      "iter105:[loss]:nan\n",
      "iter105:[val_loss]:nan\n",
      "iter106:[loss]:nan\n",
      "iter106:[val_loss]:nan\n",
      "iter107:[loss]:nan\n",
      "iter107:[val_loss]:nan\n",
      "iter108:[loss]:nan\n",
      "iter108:[val_loss]:nan\n",
      "iter109:[loss]:nan\n",
      "iter109:[val_loss]:nan\n",
      "iter110:[loss]:nan\n",
      "iter110:[val_loss]:nan\n",
      "iter111:[loss]:nan\n",
      "iter111:[val_loss]:nan\n",
      "iter112:[loss]:nan\n",
      "iter112:[val_loss]:nan\n",
      "iter113:[loss]:nan\n",
      "iter113:[val_loss]:nan\n",
      "iter114:[loss]:nan\n",
      "iter114:[val_loss]:nan\n",
      "iter115:[loss]:nan\n",
      "iter115:[val_loss]:nan\n",
      "iter116:[loss]:nan\n",
      "iter116:[val_loss]:nan\n",
      "iter117:[loss]:nan\n",
      "iter117:[val_loss]:nan\n",
      "iter118:[loss]:nan\n",
      "iter118:[val_loss]:nan\n",
      "iter119:[loss]:nan\n",
      "iter119:[val_loss]:nan\n",
      "iter120:[loss]:nan\n",
      "iter120:[val_loss]:nan\n",
      "iter121:[loss]:nan\n",
      "iter121:[val_loss]:nan\n",
      "iter122:[loss]:nan\n",
      "iter122:[val_loss]:nan\n",
      "iter123:[loss]:nan\n",
      "iter123:[val_loss]:nan\n",
      "iter124:[loss]:nan\n",
      "iter124:[val_loss]:nan\n",
      "iter125:[loss]:nan\n",
      "iter125:[val_loss]:nan\n",
      "iter126:[loss]:nan\n",
      "iter126:[val_loss]:nan\n",
      "iter127:[loss]:nan\n",
      "iter127:[val_loss]:nan\n",
      "iter128:[loss]:nan\n",
      "iter128:[val_loss]:nan\n",
      "iter129:[loss]:nan\n",
      "iter129:[val_loss]:nan\n",
      "iter130:[loss]:nan\n",
      "iter130:[val_loss]:nan\n",
      "iter131:[loss]:nan\n",
      "iter131:[val_loss]:nan\n",
      "iter132:[loss]:nan\n",
      "iter132:[val_loss]:nan\n",
      "iter133:[loss]:nan\n",
      "iter133:[val_loss]:nan\n",
      "iter134:[loss]:nan\n",
      "iter134:[val_loss]:nan\n",
      "iter135:[loss]:nan\n",
      "iter135:[val_loss]:nan\n",
      "iter136:[loss]:nan\n",
      "iter136:[val_loss]:nan\n",
      "iter137:[loss]:nan\n",
      "iter137:[val_loss]:nan\n",
      "iter138:[loss]:nan\n",
      "iter138:[val_loss]:nan\n",
      "iter139:[loss]:nan\n",
      "iter139:[val_loss]:nan\n",
      "iter140:[loss]:nan\n",
      "iter140:[val_loss]:nan\n",
      "iter141:[loss]:nan\n",
      "iter141:[val_loss]:nan\n",
      "iter142:[loss]:nan\n",
      "iter142:[val_loss]:nan\n",
      "iter143:[loss]:nan\n",
      "iter143:[val_loss]:nan\n",
      "iter144:[loss]:nan\n",
      "iter144:[val_loss]:nan\n",
      "iter145:[loss]:nan\n",
      "iter145:[val_loss]:nan\n",
      "iter146:[loss]:nan\n",
      "iter146:[val_loss]:nan\n",
      "iter147:[loss]:nan\n",
      "iter147:[val_loss]:nan\n",
      "iter148:[loss]:nan\n",
      "iter148:[val_loss]:nan\n",
      "iter149:[loss]:nan\n",
      "iter149:[val_loss]:nan\n",
      "iter150:[loss]:nan\n",
      "iter150:[val_loss]:nan\n",
      "iter151:[loss]:nan\n",
      "iter151:[val_loss]:nan\n",
      "iter152:[loss]:nan\n",
      "iter152:[val_loss]:nan\n",
      "iter153:[loss]:nan\n",
      "iter153:[val_loss]:nan\n",
      "iter154:[loss]:nan\n",
      "iter154:[val_loss]:nan\n",
      "iter155:[loss]:nan\n",
      "iter155:[val_loss]:nan\n",
      "iter156:[loss]:nan\n",
      "iter156:[val_loss]:nan\n",
      "iter157:[loss]:nan\n",
      "iter157:[val_loss]:nan\n",
      "iter158:[loss]:nan\n",
      "iter158:[val_loss]:nan\n",
      "iter159:[loss]:nan\n",
      "iter159:[val_loss]:nan\n",
      "iter160:[loss]:nan\n",
      "iter160:[val_loss]:nan\n",
      "iter161:[loss]:nan\n",
      "iter161:[val_loss]:nan\n",
      "iter162:[loss]:nan\n",
      "iter162:[val_loss]:nan\n",
      "iter163:[loss]:nan\n",
      "iter163:[val_loss]:nan\n",
      "iter164:[loss]:nan\n",
      "iter164:[val_loss]:nan\n",
      "iter165:[loss]:nan\n",
      "iter165:[val_loss]:nan\n",
      "iter166:[loss]:nan\n",
      "iter166:[val_loss]:nan\n",
      "iter167:[loss]:nan\n",
      "iter167:[val_loss]:nan\n",
      "iter168:[loss]:nan\n",
      "iter168:[val_loss]:nan\n",
      "iter169:[loss]:nan\n",
      "iter169:[val_loss]:nan\n",
      "iter170:[loss]:nan\n",
      "iter170:[val_loss]:nan\n",
      "iter171:[loss]:nan\n",
      "iter171:[val_loss]:nan\n",
      "iter172:[loss]:nan\n",
      "iter172:[val_loss]:nan\n",
      "iter173:[loss]:nan\n",
      "iter173:[val_loss]:nan\n",
      "iter174:[loss]:nan\n",
      "iter174:[val_loss]:nan\n",
      "iter175:[loss]:nan\n",
      "iter175:[val_loss]:nan\n",
      "iter176:[loss]:nan\n",
      "iter176:[val_loss]:nan\n",
      "iter177:[loss]:nan\n",
      "iter177:[val_loss]:nan\n",
      "iter178:[loss]:nan\n",
      "iter178:[val_loss]:nan\n",
      "iter179:[loss]:nan\n",
      "iter179:[val_loss]:nan\n",
      "iter180:[loss]:nan\n",
      "iter180:[val_loss]:nan\n",
      "iter181:[loss]:nan\n",
      "iter181:[val_loss]:nan\n",
      "iter182:[loss]:nan\n",
      "iter182:[val_loss]:nan\n",
      "iter183:[loss]:nan\n",
      "iter183:[val_loss]:nan\n",
      "iter184:[loss]:nan\n",
      "iter184:[val_loss]:nan\n",
      "iter185:[loss]:nan\n",
      "iter185:[val_loss]:nan\n",
      "iter186:[loss]:nan\n",
      "iter186:[val_loss]:nan\n",
      "iter187:[loss]:nan\n",
      "iter187:[val_loss]:nan\n",
      "iter188:[loss]:nan\n",
      "iter188:[val_loss]:nan\n",
      "iter189:[loss]:nan\n",
      "iter189:[val_loss]:nan\n",
      "iter190:[loss]:nan\n",
      "iter190:[val_loss]:nan\n",
      "iter191:[loss]:nan\n",
      "iter191:[val_loss]:nan\n",
      "iter192:[loss]:nan\n",
      "iter192:[val_loss]:nan\n",
      "iter193:[loss]:nan\n",
      "iter193:[val_loss]:nan\n",
      "iter194:[loss]:nan\n",
      "iter194:[val_loss]:nan\n",
      "iter195:[loss]:nan\n",
      "iter195:[val_loss]:nan\n",
      "iter196:[loss]:nan\n",
      "iter196:[val_loss]:nan\n",
      "iter197:[loss]:nan\n",
      "iter197:[val_loss]:nan\n",
      "iter198:[loss]:nan\n",
      "iter198:[val_loss]:nan\n",
      "iter199:[loss]:nan\n",
      "iter199:[val_loss]:nan\n",
      "iter200:[loss]:nan\n",
      "iter200:[val_loss]:nan\n",
      "iter201:[loss]:nan\n",
      "iter201:[val_loss]:nan\n",
      "iter202:[loss]:nan\n",
      "iter202:[val_loss]:nan\n",
      "iter203:[loss]:nan\n",
      "iter203:[val_loss]:nan\n",
      "iter204:[loss]:nan\n",
      "iter204:[val_loss]:nan\n",
      "iter205:[loss]:nan\n",
      "iter205:[val_loss]:nan\n",
      "iter206:[loss]:nan\n",
      "iter206:[val_loss]:nan\n",
      "iter207:[loss]:nan\n",
      "iter207:[val_loss]:nan\n",
      "iter208:[loss]:nan\n",
      "iter208:[val_loss]:nan\n",
      "iter209:[loss]:nan\n",
      "iter209:[val_loss]:nan\n",
      "iter210:[loss]:nan\n",
      "iter210:[val_loss]:nan\n",
      "iter211:[loss]:nan\n",
      "iter211:[val_loss]:nan\n",
      "iter212:[loss]:nan\n",
      "iter212:[val_loss]:nan\n",
      "iter213:[loss]:nan\n",
      "iter213:[val_loss]:nan\n",
      "iter214:[loss]:nan\n",
      "iter214:[val_loss]:nan\n",
      "iter215:[loss]:nan\n",
      "iter215:[val_loss]:nan\n",
      "iter216:[loss]:nan\n",
      "iter216:[val_loss]:nan\n",
      "iter217:[loss]:nan\n",
      "iter217:[val_loss]:nan\n",
      "iter218:[loss]:nan\n",
      "iter218:[val_loss]:nan\n",
      "iter219:[loss]:nan\n",
      "iter219:[val_loss]:nan\n",
      "iter220:[loss]:nan\n",
      "iter220:[val_loss]:nan\n",
      "iter221:[loss]:nan\n",
      "iter221:[val_loss]:nan\n",
      "iter222:[loss]:nan\n",
      "iter222:[val_loss]:nan\n",
      "iter223:[loss]:nan\n",
      "iter223:[val_loss]:nan\n",
      "iter224:[loss]:nan\n",
      "iter224:[val_loss]:nan\n",
      "iter225:[loss]:nan\n",
      "iter225:[val_loss]:nan\n",
      "iter226:[loss]:nan\n",
      "iter226:[val_loss]:nan\n",
      "iter227:[loss]:nan\n",
      "iter227:[val_loss]:nan\n",
      "iter228:[loss]:nan\n",
      "iter228:[val_loss]:nan\n",
      "iter229:[loss]:nan\n",
      "iter229:[val_loss]:nan\n",
      "iter230:[loss]:nan\n",
      "iter230:[val_loss]:nan\n",
      "iter231:[loss]:nan\n",
      "iter231:[val_loss]:nan\n",
      "iter232:[loss]:nan\n",
      "iter232:[val_loss]:nan\n",
      "iter233:[loss]:nan\n",
      "iter233:[val_loss]:nan\n",
      "iter234:[loss]:nan\n",
      "iter234:[val_loss]:nan\n",
      "iter235:[loss]:nan\n",
      "iter235:[val_loss]:nan\n",
      "iter236:[loss]:nan\n",
      "iter236:[val_loss]:nan\n",
      "iter237:[loss]:nan\n",
      "iter237:[val_loss]:nan\n",
      "iter238:[loss]:nan\n",
      "iter238:[val_loss]:nan\n",
      "iter239:[loss]:nan\n",
      "iter239:[val_loss]:nan\n",
      "iter240:[loss]:nan\n",
      "iter240:[val_loss]:nan\n",
      "iter241:[loss]:nan\n",
      "iter241:[val_loss]:nan\n",
      "iter242:[loss]:nan\n",
      "iter242:[val_loss]:nan\n",
      "iter243:[loss]:nan\n",
      "iter243:[val_loss]:nan\n",
      "iter244:[loss]:nan\n",
      "iter244:[val_loss]:nan\n",
      "iter245:[loss]:nan\n",
      "iter245:[val_loss]:nan\n",
      "iter246:[loss]:nan\n",
      "iter246:[val_loss]:nan\n",
      "iter247:[loss]:nan\n",
      "iter247:[val_loss]:nan\n",
      "iter248:[loss]:nan\n",
      "iter248:[val_loss]:nan\n",
      "iter249:[loss]:nan\n",
      "iter249:[val_loss]:nan\n",
      "iter250:[loss]:nan\n",
      "iter250:[val_loss]:nan\n",
      "iter251:[loss]:nan\n",
      "iter251:[val_loss]:nan\n",
      "iter252:[loss]:nan\n",
      "iter252:[val_loss]:nan\n",
      "iter253:[loss]:nan\n",
      "iter253:[val_loss]:nan\n",
      "iter254:[loss]:nan\n",
      "iter254:[val_loss]:nan\n",
      "iter255:[loss]:nan\n",
      "iter255:[val_loss]:nan\n",
      "iter256:[loss]:nan\n",
      "iter256:[val_loss]:nan\n",
      "iter257:[loss]:nan\n",
      "iter257:[val_loss]:nan\n",
      "iter258:[loss]:nan\n",
      "iter258:[val_loss]:nan\n",
      "iter259:[loss]:nan\n",
      "iter259:[val_loss]:nan\n",
      "iter260:[loss]:nan\n",
      "iter260:[val_loss]:nan\n",
      "iter261:[loss]:nan\n",
      "iter261:[val_loss]:nan\n",
      "iter262:[loss]:nan\n",
      "iter262:[val_loss]:nan\n",
      "iter263:[loss]:nan\n",
      "iter263:[val_loss]:nan\n",
      "iter264:[loss]:nan\n",
      "iter264:[val_loss]:nan\n",
      "iter265:[loss]:nan\n",
      "iter265:[val_loss]:nan\n",
      "iter266:[loss]:nan\n",
      "iter266:[val_loss]:nan\n",
      "iter267:[loss]:nan\n",
      "iter267:[val_loss]:nan\n",
      "iter268:[loss]:nan\n",
      "iter268:[val_loss]:nan\n",
      "iter269:[loss]:nan\n",
      "iter269:[val_loss]:nan\n",
      "iter270:[loss]:nan\n",
      "iter270:[val_loss]:nan\n",
      "iter271:[loss]:nan\n",
      "iter271:[val_loss]:nan\n",
      "iter272:[loss]:nan\n",
      "iter272:[val_loss]:nan\n",
      "iter273:[loss]:nan\n",
      "iter273:[val_loss]:nan\n",
      "iter274:[loss]:nan\n",
      "iter274:[val_loss]:nan\n",
      "iter275:[loss]:nan\n",
      "iter275:[val_loss]:nan\n",
      "iter276:[loss]:nan\n",
      "iter276:[val_loss]:nan\n",
      "iter277:[loss]:nan\n",
      "iter277:[val_loss]:nan\n",
      "iter278:[loss]:nan\n",
      "iter278:[val_loss]:nan\n",
      "iter279:[loss]:nan\n",
      "iter279:[val_loss]:nan\n",
      "iter280:[loss]:nan\n",
      "iter280:[val_loss]:nan\n",
      "iter281:[loss]:nan\n",
      "iter281:[val_loss]:nan\n",
      "iter282:[loss]:nan\n",
      "iter282:[val_loss]:nan\n",
      "iter283:[loss]:nan\n",
      "iter283:[val_loss]:nan\n",
      "iter284:[loss]:nan\n",
      "iter284:[val_loss]:nan\n",
      "iter285:[loss]:nan\n",
      "iter285:[val_loss]:nan\n",
      "iter286:[loss]:nan\n",
      "iter286:[val_loss]:nan\n",
      "iter287:[loss]:nan\n",
      "iter287:[val_loss]:nan\n",
      "iter288:[loss]:nan\n",
      "iter288:[val_loss]:nan\n",
      "iter289:[loss]:nan\n",
      "iter289:[val_loss]:nan\n",
      "iter290:[loss]:nan\n",
      "iter290:[val_loss]:nan\n",
      "iter291:[loss]:nan\n",
      "iter291:[val_loss]:nan\n",
      "iter292:[loss]:nan\n",
      "iter292:[val_loss]:nan\n",
      "iter293:[loss]:nan\n",
      "iter293:[val_loss]:nan\n",
      "iter294:[loss]:nan\n",
      "iter294:[val_loss]:nan\n",
      "iter295:[loss]:nan\n",
      "iter295:[val_loss]:nan\n",
      "iter296:[loss]:nan\n",
      "iter296:[val_loss]:nan\n",
      "iter297:[loss]:nan\n",
      "iter297:[val_loss]:nan\n",
      "iter298:[loss]:nan\n",
      "iter298:[val_loss]:nan\n",
      "iter299:[loss]:nan\n",
      "iter299:[val_loss]:nan\n",
      "iter300:[loss]:nan\n",
      "iter300:[val_loss]:nan\n",
      "iter301:[loss]:nan\n",
      "iter301:[val_loss]:nan\n",
      "iter302:[loss]:nan\n",
      "iter302:[val_loss]:nan\n",
      "iter303:[loss]:nan\n",
      "iter303:[val_loss]:nan\n",
      "iter304:[loss]:nan\n",
      "iter304:[val_loss]:nan\n",
      "iter305:[loss]:nan\n",
      "iter305:[val_loss]:nan\n",
      "iter306:[loss]:nan\n",
      "iter306:[val_loss]:nan\n",
      "iter307:[loss]:nan\n",
      "iter307:[val_loss]:nan\n",
      "iter308:[loss]:nan\n",
      "iter308:[val_loss]:nan\n",
      "iter309:[loss]:nan\n",
      "iter309:[val_loss]:nan\n",
      "iter310:[loss]:nan\n",
      "iter310:[val_loss]:nan\n",
      "iter311:[loss]:nan\n",
      "iter311:[val_loss]:nan\n",
      "iter312:[loss]:nan\n",
      "iter312:[val_loss]:nan\n",
      "iter313:[loss]:nan\n",
      "iter313:[val_loss]:nan\n",
      "iter314:[loss]:nan\n",
      "iter314:[val_loss]:nan\n",
      "iter315:[loss]:nan\n",
      "iter315:[val_loss]:nan\n",
      "iter316:[loss]:nan\n",
      "iter316:[val_loss]:nan\n",
      "iter317:[loss]:nan\n",
      "iter317:[val_loss]:nan\n",
      "iter318:[loss]:nan\n",
      "iter318:[val_loss]:nan\n",
      "iter319:[loss]:nan\n",
      "iter319:[val_loss]:nan\n",
      "iter320:[loss]:nan\n",
      "iter320:[val_loss]:nan\n",
      "iter321:[loss]:nan\n",
      "iter321:[val_loss]:nan\n",
      "iter322:[loss]:nan\n",
      "iter322:[val_loss]:nan\n",
      "iter323:[loss]:nan\n",
      "iter323:[val_loss]:nan\n",
      "iter324:[loss]:nan\n",
      "iter324:[val_loss]:nan\n",
      "iter325:[loss]:nan\n",
      "iter325:[val_loss]:nan\n",
      "iter326:[loss]:nan\n",
      "iter326:[val_loss]:nan\n",
      "iter327:[loss]:nan\n",
      "iter327:[val_loss]:nan\n",
      "iter328:[loss]:nan\n",
      "iter328:[val_loss]:nan\n",
      "iter329:[loss]:nan\n",
      "iter329:[val_loss]:nan\n",
      "iter330:[loss]:nan\n",
      "iter330:[val_loss]:nan\n",
      "iter331:[loss]:nan\n",
      "iter331:[val_loss]:nan\n",
      "iter332:[loss]:nan\n",
      "iter332:[val_loss]:nan\n",
      "iter333:[loss]:nan\n",
      "iter333:[val_loss]:nan\n",
      "iter334:[loss]:nan\n",
      "iter334:[val_loss]:nan\n",
      "iter335:[loss]:nan\n",
      "iter335:[val_loss]:nan\n",
      "iter336:[loss]:nan\n",
      "iter336:[val_loss]:nan\n",
      "iter337:[loss]:nan\n",
      "iter337:[val_loss]:nan\n",
      "iter338:[loss]:nan\n",
      "iter338:[val_loss]:nan\n",
      "iter339:[loss]:nan\n",
      "iter339:[val_loss]:nan\n",
      "iter340:[loss]:nan\n",
      "iter340:[val_loss]:nan\n",
      "iter341:[loss]:nan\n",
      "iter341:[val_loss]:nan\n",
      "iter342:[loss]:nan\n",
      "iter342:[val_loss]:nan\n",
      "iter343:[loss]:nan\n",
      "iter343:[val_loss]:nan\n",
      "iter344:[loss]:nan\n",
      "iter344:[val_loss]:nan\n",
      "iter345:[loss]:nan\n",
      "iter345:[val_loss]:nan\n",
      "iter346:[loss]:nan\n",
      "iter346:[val_loss]:nan\n",
      "iter347:[loss]:nan\n",
      "iter347:[val_loss]:nan\n",
      "iter348:[loss]:nan\n",
      "iter348:[val_loss]:nan\n",
      "iter349:[loss]:nan\n",
      "iter349:[val_loss]:nan\n",
      "iter350:[loss]:nan\n",
      "iter350:[val_loss]:nan\n",
      "iter351:[loss]:nan\n",
      "iter351:[val_loss]:nan\n",
      "iter352:[loss]:nan\n",
      "iter352:[val_loss]:nan\n",
      "iter353:[loss]:nan\n",
      "iter353:[val_loss]:nan\n",
      "iter354:[loss]:nan\n",
      "iter354:[val_loss]:nan\n",
      "iter355:[loss]:nan\n",
      "iter355:[val_loss]:nan\n",
      "iter356:[loss]:nan\n",
      "iter356:[val_loss]:nan\n",
      "iter357:[loss]:nan\n",
      "iter357:[val_loss]:nan\n",
      "iter358:[loss]:nan\n",
      "iter358:[val_loss]:nan\n",
      "iter359:[loss]:nan\n",
      "iter359:[val_loss]:nan\n",
      "iter360:[loss]:nan\n",
      "iter360:[val_loss]:nan\n",
      "iter361:[loss]:nan\n",
      "iter361:[val_loss]:nan\n",
      "iter362:[loss]:nan\n",
      "iter362:[val_loss]:nan\n",
      "iter363:[loss]:nan\n",
      "iter363:[val_loss]:nan\n",
      "iter364:[loss]:nan\n",
      "iter364:[val_loss]:nan\n",
      "iter365:[loss]:nan\n",
      "iter365:[val_loss]:nan\n",
      "iter366:[loss]:nan\n",
      "iter366:[val_loss]:nan\n",
      "iter367:[loss]:nan\n",
      "iter367:[val_loss]:nan\n",
      "iter368:[loss]:nan\n",
      "iter368:[val_loss]:nan\n",
      "iter369:[loss]:nan\n",
      "iter369:[val_loss]:nan\n",
      "iter370:[loss]:nan\n",
      "iter370:[val_loss]:nan\n",
      "iter371:[loss]:nan\n",
      "iter371:[val_loss]:nan\n",
      "iter372:[loss]:nan\n",
      "iter372:[val_loss]:nan\n",
      "iter373:[loss]:nan\n",
      "iter373:[val_loss]:nan\n",
      "iter374:[loss]:nan\n",
      "iter374:[val_loss]:nan\n",
      "iter375:[loss]:nan\n",
      "iter375:[val_loss]:nan\n",
      "iter376:[loss]:nan\n",
      "iter376:[val_loss]:nan\n",
      "iter377:[loss]:nan\n",
      "iter377:[val_loss]:nan\n",
      "iter378:[loss]:nan\n",
      "iter378:[val_loss]:nan\n",
      "iter379:[loss]:nan\n",
      "iter379:[val_loss]:nan\n",
      "iter380:[loss]:nan\n",
      "iter380:[val_loss]:nan\n",
      "iter381:[loss]:nan\n",
      "iter381:[val_loss]:nan\n",
      "iter382:[loss]:nan\n",
      "iter382:[val_loss]:nan\n",
      "iter383:[loss]:nan\n",
      "iter383:[val_loss]:nan\n",
      "iter384:[loss]:nan\n",
      "iter384:[val_loss]:nan\n",
      "iter385:[loss]:nan\n",
      "iter385:[val_loss]:nan\n",
      "iter386:[loss]:nan\n",
      "iter386:[val_loss]:nan\n",
      "iter387:[loss]:nan\n",
      "iter387:[val_loss]:nan\n",
      "iter388:[loss]:nan\n",
      "iter388:[val_loss]:nan\n",
      "iter389:[loss]:nan\n",
      "iter389:[val_loss]:nan\n",
      "iter390:[loss]:nan\n",
      "iter390:[val_loss]:nan\n",
      "iter391:[loss]:nan\n",
      "iter391:[val_loss]:nan\n",
      "iter392:[loss]:nan\n",
      "iter392:[val_loss]:nan\n",
      "iter393:[loss]:nan\n",
      "iter393:[val_loss]:nan\n",
      "iter394:[loss]:nan\n",
      "iter394:[val_loss]:nan\n",
      "iter395:[loss]:nan\n",
      "iter395:[val_loss]:nan\n",
      "iter396:[loss]:nan\n",
      "iter396:[val_loss]:nan\n",
      "iter397:[loss]:nan\n",
      "iter397:[val_loss]:nan\n",
      "iter398:[loss]:nan\n",
      "iter398:[val_loss]:nan\n",
      "iter399:[loss]:nan\n",
      "iter399:[val_loss]:nan\n",
      "iter400:[loss]:nan\n",
      "iter400:[val_loss]:nan\n",
      "iter401:[loss]:nan\n",
      "iter401:[val_loss]:nan\n",
      "iter402:[loss]:nan\n",
      "iter402:[val_loss]:nan\n",
      "iter403:[loss]:nan\n",
      "iter403:[val_loss]:nan\n",
      "iter404:[loss]:nan\n",
      "iter404:[val_loss]:nan\n",
      "iter405:[loss]:nan\n",
      "iter405:[val_loss]:nan\n",
      "iter406:[loss]:nan\n",
      "iter406:[val_loss]:nan\n",
      "iter407:[loss]:nan\n",
      "iter407:[val_loss]:nan\n",
      "iter408:[loss]:nan\n",
      "iter408:[val_loss]:nan\n",
      "iter409:[loss]:nan\n",
      "iter409:[val_loss]:nan\n",
      "iter410:[loss]:nan\n",
      "iter410:[val_loss]:nan\n",
      "iter411:[loss]:nan\n",
      "iter411:[val_loss]:nan\n",
      "iter412:[loss]:nan\n",
      "iter412:[val_loss]:nan\n",
      "iter413:[loss]:nan\n",
      "iter413:[val_loss]:nan\n",
      "iter414:[loss]:nan\n",
      "iter414:[val_loss]:nan\n",
      "iter415:[loss]:nan\n",
      "iter415:[val_loss]:nan\n",
      "iter416:[loss]:nan\n",
      "iter416:[val_loss]:nan\n",
      "iter417:[loss]:nan\n",
      "iter417:[val_loss]:nan\n",
      "iter418:[loss]:nan\n",
      "iter418:[val_loss]:nan\n",
      "iter419:[loss]:nan\n",
      "iter419:[val_loss]:nan\n",
      "iter420:[loss]:nan\n",
      "iter420:[val_loss]:nan\n",
      "iter421:[loss]:nan\n",
      "iter421:[val_loss]:nan\n",
      "iter422:[loss]:nan\n",
      "iter422:[val_loss]:nan\n",
      "iter423:[loss]:nan\n",
      "iter423:[val_loss]:nan\n",
      "iter424:[loss]:nan\n",
      "iter424:[val_loss]:nan\n",
      "iter425:[loss]:nan\n",
      "iter425:[val_loss]:nan\n",
      "iter426:[loss]:nan\n",
      "iter426:[val_loss]:nan\n",
      "iter427:[loss]:nan\n",
      "iter427:[val_loss]:nan\n",
      "iter428:[loss]:nan\n",
      "iter428:[val_loss]:nan\n",
      "iter429:[loss]:nan\n",
      "iter429:[val_loss]:nan\n",
      "iter430:[loss]:nan\n",
      "iter430:[val_loss]:nan\n",
      "iter431:[loss]:nan\n",
      "iter431:[val_loss]:nan\n",
      "iter432:[loss]:nan\n",
      "iter432:[val_loss]:nan\n",
      "iter433:[loss]:nan\n",
      "iter433:[val_loss]:nan\n",
      "iter434:[loss]:nan\n",
      "iter434:[val_loss]:nan\n",
      "iter435:[loss]:nan\n",
      "iter435:[val_loss]:nan\n",
      "iter436:[loss]:nan\n",
      "iter436:[val_loss]:nan\n",
      "iter437:[loss]:nan\n",
      "iter437:[val_loss]:nan\n",
      "iter438:[loss]:nan\n",
      "iter438:[val_loss]:nan\n",
      "iter439:[loss]:nan\n",
      "iter439:[val_loss]:nan\n",
      "iter440:[loss]:nan\n",
      "iter440:[val_loss]:nan\n",
      "iter441:[loss]:nan\n",
      "iter441:[val_loss]:nan\n",
      "iter442:[loss]:nan\n",
      "iter442:[val_loss]:nan\n",
      "iter443:[loss]:nan\n",
      "iter443:[val_loss]:nan\n",
      "iter444:[loss]:nan\n",
      "iter444:[val_loss]:nan\n",
      "iter445:[loss]:nan\n",
      "iter445:[val_loss]:nan\n",
      "iter446:[loss]:nan\n",
      "iter446:[val_loss]:nan\n",
      "iter447:[loss]:nan\n",
      "iter447:[val_loss]:nan\n",
      "iter448:[loss]:nan\n",
      "iter448:[val_loss]:nan\n",
      "iter449:[loss]:nan\n",
      "iter449:[val_loss]:nan\n",
      "iter450:[loss]:nan\n",
      "iter450:[val_loss]:nan\n",
      "iter451:[loss]:nan\n",
      "iter451:[val_loss]:nan\n",
      "iter452:[loss]:nan\n",
      "iter452:[val_loss]:nan\n",
      "iter453:[loss]:nan\n",
      "iter453:[val_loss]:nan\n",
      "iter454:[loss]:nan\n",
      "iter454:[val_loss]:nan\n",
      "iter455:[loss]:nan\n",
      "iter455:[val_loss]:nan\n",
      "iter456:[loss]:nan\n",
      "iter456:[val_loss]:nan\n",
      "iter457:[loss]:nan\n",
      "iter457:[val_loss]:nan\n",
      "iter458:[loss]:nan\n",
      "iter458:[val_loss]:nan\n",
      "iter459:[loss]:nan\n",
      "iter459:[val_loss]:nan\n",
      "iter460:[loss]:nan\n",
      "iter460:[val_loss]:nan\n",
      "iter461:[loss]:nan\n",
      "iter461:[val_loss]:nan\n",
      "iter462:[loss]:nan\n",
      "iter462:[val_loss]:nan\n",
      "iter463:[loss]:nan\n",
      "iter463:[val_loss]:nan\n",
      "iter464:[loss]:nan\n",
      "iter464:[val_loss]:nan\n",
      "iter465:[loss]:nan\n",
      "iter465:[val_loss]:nan\n",
      "iter466:[loss]:nan\n",
      "iter466:[val_loss]:nan\n",
      "iter467:[loss]:nan\n",
      "iter467:[val_loss]:nan\n",
      "iter468:[loss]:nan\n",
      "iter468:[val_loss]:nan\n",
      "iter469:[loss]:nan\n",
      "iter469:[val_loss]:nan\n",
      "iter470:[loss]:nan\n",
      "iter470:[val_loss]:nan\n",
      "iter471:[loss]:nan\n",
      "iter471:[val_loss]:nan\n",
      "iter472:[loss]:nan\n",
      "iter472:[val_loss]:nan\n",
      "iter473:[loss]:nan\n",
      "iter473:[val_loss]:nan\n",
      "iter474:[loss]:nan\n",
      "iter474:[val_loss]:nan\n",
      "iter475:[loss]:nan\n",
      "iter475:[val_loss]:nan\n",
      "iter476:[loss]:nan\n",
      "iter476:[val_loss]:nan\n",
      "iter477:[loss]:nan\n",
      "iter477:[val_loss]:nan\n",
      "iter478:[loss]:nan\n",
      "iter478:[val_loss]:nan\n",
      "iter479:[loss]:nan\n",
      "iter479:[val_loss]:nan\n",
      "iter480:[loss]:nan\n",
      "iter480:[val_loss]:nan\n",
      "iter481:[loss]:nan\n",
      "iter481:[val_loss]:nan\n",
      "iter482:[loss]:nan\n",
      "iter482:[val_loss]:nan\n",
      "iter483:[loss]:nan\n",
      "iter483:[val_loss]:nan\n",
      "iter484:[loss]:nan\n",
      "iter484:[val_loss]:nan\n",
      "iter485:[loss]:nan\n",
      "iter485:[val_loss]:nan\n",
      "iter486:[loss]:nan\n",
      "iter486:[val_loss]:nan\n",
      "iter487:[loss]:nan\n",
      "iter487:[val_loss]:nan\n",
      "iter488:[loss]:nan\n",
      "iter488:[val_loss]:nan\n",
      "iter489:[loss]:nan\n",
      "iter489:[val_loss]:nan\n",
      "iter490:[loss]:nan\n",
      "iter490:[val_loss]:nan\n",
      "iter491:[loss]:nan\n",
      "iter491:[val_loss]:nan\n",
      "iter492:[loss]:nan\n",
      "iter492:[val_loss]:nan\n",
      "iter493:[loss]:nan\n",
      "iter493:[val_loss]:nan\n",
      "iter494:[loss]:nan\n",
      "iter494:[val_loss]:nan\n",
      "iter495:[loss]:nan\n",
      "iter495:[val_loss]:nan\n",
      "iter496:[loss]:nan\n",
      "iter496:[val_loss]:nan\n",
      "iter497:[loss]:nan\n",
      "iter497:[val_loss]:nan\n",
      "iter498:[loss]:nan\n",
      "iter498:[val_loss]:nan\n",
      "iter499:[loss]:nan\n",
      "iter499:[val_loss]:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adachi-yuya/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/ipykernel_launcher.py:179: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/adachi-yuya/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/ipykernel_launcher.py:194: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/adachi-yuya/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/ipykernel_launcher.py:147: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    }
   ],
   "source": [
    "scr_lr3 = ScratchLinearRegression(num_iter=500, \n",
    "                                 lr=0.01, \n",
    "                                 no_bias = False,\n",
    "                                 verbose=True)\n",
    "\n",
    "scr_lr3.fit(X_train_3, y_train, X_test_3, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2乗・3乗ともに発散"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題10】（アドバンス課題）更新式の導出\n",
    "最急降下法の更新式は以下でした。この式が導出される過程を説明してください。\n",
    "\n",
    "$$\n",
    "θj\n",
    ":=\n",
    "θj\n",
    "−\n",
    "α\n",
    "\\frac{1}{m}\n",
    "\\sum_{i=1}^{m}\n",
    "[\n",
    "(\n",
    "hθ(x(i))\n",
    "−\n",
    "y(i)\n",
    ")\n",
    "x(i)j\n",
    "]\n",
    "\\tag{式1}\n",
    "$$\n",
    "\n",
    "以下の式から説明をはじめることができます。\n",
    "\n",
    "$$\n",
    "θj\n",
    ":=\n",
    "θj\n",
    "−\n",
    "\\frac{∂}{∂θj}\n",
    "J(θ)\n",
    "\\tag{式2}\n",
    "$$\n",
    "\n",
    "目的関数（損失関数） $J(\\theta)$ は次の式です。\n",
    "\n",
    "$$\n",
    "J(θ)\n",
    "=\n",
    "\\frac{1}{2m}\n",
    "\\sum_{i=1}^{m}\n",
    "(\n",
    "hθ(x(i))\n",
    "−\n",
    "y(i))^2\n",
    "\\tag{式3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回答\n",
    "- 式1のα以降の式は式3をθで微分した式。\n",
    "- 式2の−以降の式は式3をθで微分した式。式1と式2は同じ式。\n",
    "\n",
    "## 説明\n",
    "目的関数(=X0θ0+X1θ1+...Xnθn)を微分することで傾きを算出することができる。傾きはθの更新（式2）により徐々に値が小さくなり、式3の目的関数も小さくなってくる=収束。最終的に目的関数を微分しても0に近い値になっていくことで式1のα以降のマイナス部分がほとんど0になり、θが更新されない＝最適解が導き出されるということである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題11】（アドバンス課題）局所最適解の問題\n",
    "最急降下法には一般的に局所最適解の問題があります。しかし、線形回帰では学習を続ければ必ず最適解を求めることができます。それはなぜか数式やグラフを用いて説明してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合っているか自信はないのですが\n",
    "\n",
    "式3の最小2乗法によって目的関数を求めているため、2乗=つまり２次式である限り、微分すると1次式になるため、1次式の上では必ず降下していくということなのではないかと思います。最小2乗法以外の目的関数の求め方をした場合（3乗4乗とするような方法？、sincosを使った方法など）、微分しても2次式3次式となるので、曲線型になり局所最適解の問題が出てきます。ということなのかと思いました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "467px",
    "left": "1549px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
