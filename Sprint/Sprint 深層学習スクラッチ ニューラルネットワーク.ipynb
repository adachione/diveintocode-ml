{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 深層学習スクラッチ ニューラルネットワーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import copy\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "uint8\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(X_train[0].dtype) # uint8\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "# X_train[index]: (784,)\n",
    "# image: (28, 28)\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -102.35  -87.35  -87.35  -87.35   20.65   30.65\n",
      "    69.65  -79.35   60.65  149.65  141.65   21.65 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -75.35\n",
      "   -69.35  -11.35   48.65   64.65  147.65  147.65  147.65  147.65  147.65\n",
      "   119.65   66.65  147.65  136.65   89.65  -41.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -56.35  132.65\n",
      "   147.65  147.65  147.65  147.65  147.65  147.65  147.65  147.65  145.65\n",
      "   -12.35  -23.35  -23.35  -49.35  -66.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35  113.65\n",
      "   147.65  147.65  147.65  147.65  147.65   92.65   76.65  141.65  135.65\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -25.35\n",
      "    50.65    1.65  147.65  147.65   99.65  -94.35 -105.35  -62.35   48.65\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "   -91.35 -104.35   48.65  147.65  -15.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35   33.65  147.65   84.65 -103.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35  -94.35   84.65  147.65  -35.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35  -70.35  135.65  119.65   54.65    2.65 -104.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35  -24.35  134.65  147.65  147.65   13.65\n",
      "   -80.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35  -60.35   80.65  147.65  147.65\n",
      "    44.65  -78.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -89.35  -12.35  146.65\n",
      "   147.65   81.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  143.65\n",
      "   147.65  143.65  -41.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35  -59.35   24.65   77.65  147.65\n",
      "   147.65  101.65 -103.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35  -66.35   42.65  123.65  147.65  147.65  147.65\n",
      "   144.65   76.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35  -81.35    8.65  115.65  147.65  147.65  147.65  147.65   95.65\n",
      "   -27.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -82.35\n",
      "   -39.35  107.65  147.65  147.65  147.65  147.65   92.65  -24.35 -103.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35   65.65  113.65\n",
      "   147.65  147.65  147.65  147.65   89.65  -25.35  -96.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35  -50.35   66.65  120.65  147.65  147.65\n",
      "   147.65  147.65  138.65   27.65  -94.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35   30.65  147.65  147.65  147.65  106.65\n",
      "    29.65   26.65  -89.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "image = image.astype(np.float) # float型に変換\n",
    "image -= 105.35 # 意図的に負の小数値を作り出してみる\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()\n",
    "print(image) # 値を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbefb573780>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAADQZJREFUeJzt3VvIXfWZx/HvM5kWUSsqYozWQy0SRoRJJYpQmXjA4gwF02ilepNhpOlFo1OYi5HcVBgkMkw7Vi+KqQ1GadMWNWMopa3ooB0cjImHmqptRTJtDiSKStOLIEmeuXhXyqu+e+03+7R28nw/EPbhWYeHTX7vWmv/997/yEwk1fNXXTcgqRuGXyrK8EtFGX6pKMMvFWX4paIMv1SU4ZeKMvxSUX89yZ1FhB8nlMYsM2M+yw115I+I6yPitxHxZkTcOcy2JE1WDPrZ/ohYAPwOuA7YCbwA3JKZr7Ws45FfGrNJHPkvB97MzLcy8wPgR8ANQ2xP0gQNE/5zgD/Oeryzee5DImJVRGyNiK1D7EvSiA3zht9cpxYfO63PzHXAOvC0X5omwxz5dwLnznr8aWD3cO1ImpRhwv8CcFFEfCYiPgl8Bdg8mrYkjdvAp/2ZeTAiVgO/ABYA6zPzNyPrTNJYDTzUN9DOvOaXxm4iH/KRdOwy/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9UlOGXijL8UlGGXyrK8EtFGX6pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqkowy8VZfilogy/VJThl4oy/FJRhl8qyvBLRRl+qaiBp+gGiIgdwH7gEHAwM5eOoikdP84444yetRNPPLF13cWLF7fWn3zyydb6lVde2bN26623tq574MCB1vratWtb62+//XZrfRoMFf7G1Zn5zgi2I2mCPO2Xiho2/An8MiK2RcSqUTQkaTKGPe3/fGbujogzgScj4o3MfHb2As0fBf8wSFNmqCN/Zu5ubvcBm4DL51hmXWYu9c1AaboMHP6IOCkiPnXkPvAFYPuoGpM0XsOc9i8ENkXEke38MDN/PpKuJI3dwOHPzLeAvx1hLxrQkiVLetZOPfXU1nVvvPHGUbczMrt27WqtHzx4sLW+YsWKnrX9+/e3rvvyyy+31o+Fcfx+HOqTijL8UlGGXyrK8EtFGX6pKMMvFRWZObmdRUxuZ1Pk7rvvbq2fcsopE+pkuvT7v3fHHXdMqJPjS2bGfJbzyC8VZfilogy/VJThl4oy/FJRhl8qyvBLRY3i13vVxzvvtP+48TSP82/ZsqW1/t5777XWr7nmmp61Dz74YKCeNBoe+aWiDL9UlOGXijL8UlGGXyrK8EtFGX6pKL/PPwUuvfTS1vpLL73UWr/vvvsG3vcrr7zSWn/wwQcH3nY/bT85Dv1/Pltz8/v8kloZfqkowy8VZfilogy/VJThl4oy/FJRfcf5I2I98EVgX2Ze0jx3OvBj4AJgB3BzZrZ/sRvH+celbbz8tttua1339ttvH3U76tgox/kfAq7/yHN3Ak9l5kXAU81jSceQvuHPzGeBdz/y9A3Ahub+BmD5iPuSNGaDXvMvzMw9AM3tmaNrSdIkjP03/CJiFbBq3PuRdHQGPfLvjYhFAM3tvl4LZua6zFyamUsH3JekMRg0/JuBlc39lcATo2lH0qT0DX9EbAT+F1gcETsj4jbgHuC6iPg9cF3zWNIxpO81f2be0qN07Yh70YDef//9gde96aabWuuPPvrowNvWdPMTflJRhl8qyvBLRRl+qSjDLxVl+KWinKL7OLBjx46etWeeeaZ13WXLlrXWHeo7fnnkl4oy/FJRhl8qyvBLRRl+qSjDLxVl+KWinKK7uHvuaf8phn5fF3766adb61u3bu1ZO3z4cOu6GoxTdEtqZfilogy/VJThl4oy/FJRhl8qyvBLRTnOr1Zr165trZ988skDb3vNmjWt9f379w+87coc55fUyvBLRRl+qSjDLxVl+KWiDL9UlOGXiuo7zh8R64EvAvsy85LmubuArwJvN4utycyf9d2Z4/zHneXLl7fWr7128JncH3jggdb69u3bB9728WyU4/wPAdfP8fx/ZuaS5l/f4EuaLn3Dn5nPAu9OoBdJEzTMNf/qiPh1RKyPiNNG1pGkiRg0/N8FPgssAfYA3+q1YESsioitEdH7x9wkTdxA4c/MvZl5KDMPA98DLm9Zdl1mLs3MpYM2KWn0Bgp/RCya9fBLgG+7SseYvlN0R8RG4CrgjIjYCXwTuCoilgAJ7AC+NsYeJY2B3+dXZ+6///6h1u83Z8CmTZuG2v6xyu/zS2pl+KWiDL9UlOGXijL8UlGGXyqq7zi/NC6HDh1qrS9YsKC1vmzZstZ61aG++fLILxVl+KWiDL9UlOGXijL8UlGGXyrK8EtFOc6voZx11lmt9csuu6xnrd84fj+vvfbaUOtX55FfKsrwS0UZfqkowy8VZfilogy/VJThl4pynL+4iy++uLW+YsWK1vrChQtH2c6HHD58uLW+e/fuse27Ao/8UlGGXyrK8EtFGX6pKMMvFWX4paIMv1RU33H+iDgXeBg4CzgMrMvM70TE6cCPgQuAHcDNmfne+FpVLyeccELP2urVq1vXPf/880fdzrxt27attf7QQw9NppGi5nPkPwj8S2b+DXAF8PWIuBi4E3gqMy8CnmoeSzpG9A1/Zu7JzBeb+/uB14FzgBuADc1iG4Dl42pS0ugd1TV/RFwAfA54HliYmXtg5g8EcOaom5M0PvP+bH9EnAw8BnwjM/8UEfNdbxWwarD2JI3LvI78EfEJZoL/g8x8vHl6b0QsauqLgH1zrZuZ6zJzaWYuHUXDkkajb/hj5hD/feD1zPz2rNJmYGVzfyXwxOjbkzQukZntC0RcCfwKeJWZoT6ANcxc9/8EOA/4A/DlzHy3z7bad6Y59RuuW7x48YQ6+bgtW7a01h955JEJdaIjMnNe1+R9r/kz83+AXhu79miakjQ9/ISfVJThl4oy/FJRhl8qyvBLRRl+qSh/unsErr766tb6kiVLWusXXnjhKNs5Ks8991xrfePGjRPqRJPmkV8qyvBLRRl+qSjDLxVl+KWiDL9UlOGXinKcv9FvrP6KK67oWTv77LNH3c5ROXDgQM/avffe27rurl27Rt2OjhEe+aWiDL9UlOGXijL8UlGGXyrK8EtFGX6pqDLj/Oedd15rfcWKFWPb9xtvvNFa37x5c2v90KFDrfXdu3cfdU+SR36pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKioys32BiHOBh4GzgMPAusz8TkTcBXwVeLtZdE1m/qzPttp3JmlomRnzWW4+4V8ELMrMFyPiU8A2YDlwM/DnzPyP+TZl+KXxm2/4+37CLzP3AHua+/sj4nXgnOHak9S1o7rmj4gLgM8BzzdPrY6IX0fE+og4rcc6qyJia0RsHapTSSPV97T/LwtGnAw8A9ydmY9HxELgHSCBf2Pm0uCf+mzD035pzEZ2zQ8QEZ8Afgr8IjO/PUf9AuCnmXlJn+0YfmnM5hv+vqf9ERHA94HXZwe/eSPwiC8B24+2SUndmc+7/VcCvwJeZWaoD2ANcAuwhJnT/h3A15o3B9u25ZFfGrORnvaPiuGXxm9kp/2Sjk+GXyrK8EtFGX6pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqkowy8VZfiloiY9Rfc7wP/NenxG89w0mtbeprUvsLdBjbK38+e74ES/z/+xnUdszcylnTXQYlp7m9a+wN4G1VVvnvZLRRl+qaiuw7+u4/23mdbeprUvsLdBddJbp9f8krrT9ZFfUkc6CX9EXB8Rv42INyPizi566CUidkTEqxHxctdTjDXToO2LiO2znjs9Ip6MiN83t3NOk9ZRb3dFxK7mtXs5Iv6ho97OjYj/jojXI+I3EfHPzfOdvnYtfXXyuk38tD8iFgC/A64DdgIvALdk5msTbaSHiNgBLM3MzseEI+LvgD8DDx+ZDSki/h14NzPvaf5wnpaZ/zolvd3FUc7cPKbees0s/Y90+NqNcsbrUejiyH858GZmvpWZHwA/Am7ooI+pl5nPAu9+5OkbgA3N/Q3M/OeZuB69TYXM3JOZLzb39wNHZpbu9LVr6asTXYT/HOCPsx7vZLqm/E7glxGxLSJWdd3MHBYemRmpuT2z434+qu/MzZP0kZmlp+a1G2TG61HrIvxzzSYyTUMOn8/MS4G/B77enN5qfr4LfJaZadz2AN/qsplmZunHgG9k5p+67GW2Ofrq5HXrIvw7gXNnPf40sLuDPuaUmbub233AJmYuU6bJ3iOTpDa3+zru5y8yc29mHsrMw8D36PC1a2aWfgz4QWY+3jzd+Ws3V19dvW5dhP8F4KKI+ExEfBL4CrC5gz4+JiJOat6IISJOAr7A9M0+vBlY2dxfCTzRYS8fMi0zN/eaWZqOX7tpm/G6kw/5NEMZ9wILgPWZeffEm5hDRFzIzNEeZr7x+MMue4uIjcBVzHzray/wTeC/gJ8A5wF/AL6cmRN/461Hb1dxlDM3j6m3XjNLP0+Hr90oZ7weST9+wk+qyU/4SUUZfqkowy8VZfilogy/VJThl4oy/FJRhl8q6v8BPy/0k3rnWe4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image, 'gray', vmin = 0, vmax = 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, y, batch_size=20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0] / self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        p0 = item * self.batch_size\n",
    "        p1 = item * self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter * self.batch_size\n",
    "        p1 = self._counter * self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n",
      "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), array([4, 5, 6, 1, 4, 9, 6, 9, 6, 3, 8, 2, 5, 6, 4, 4, 0, 2, 4, 0],\n",
      "      dtype=uint8))\n"
     ]
    }
   ],
   "source": [
    "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "print(len(get_mini_batch)) # 2400\n",
    "print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    # このfor文内でミニバッチが使える\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20 # バッチサイズ\n",
    "n_features = 784 # 特徴量の数\n",
    "n_nodes1 = 400 # 1層目のノード数\n",
    "n_nodes2 = 200 # 2層目のノード数\n",
    "n_output = 10 # 出力のクラス数（3層目のノード数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSimpleNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, epoch=20, n_batch=20, bias=False, func=\"sigmoid\", lr=0.001, n_nodes1=400, n_nodes2=200, n_output=10, verbose=True):\n",
    "        self.verbose = verbose\n",
    "        self.epoch = epoch\n",
    "        self.n_batch = n_batch\n",
    "        self.bias = bias\n",
    "        self.func = func\n",
    "        self.lr = lr\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.epoch)\n",
    "        self.val_loss = np.zeros(self.epoch)\n",
    "        \n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.n_output = n_output\n",
    "        \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, self.n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, self.n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        self.n_features = X.shape[1]\n",
    "\n",
    "        enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        y_train_one_hot = enc.fit_transform(y[:, np.newaxis])\n",
    "        \n",
    "        if y_val is not None:\n",
    "            y_val_one_hot = enc.fit_transform(y_val[:, np.newaxis])\n",
    "        \n",
    "        self.epoch_cnt = 0\n",
    "        self.batch_cnt = 0\n",
    "        \n",
    "        self.W_list, self.b_list = self._init_network()\n",
    "        self.default_W_list, self.default_b_list = copy.deepcopy(self.W_list), copy.deepcopy(self.b_list)\n",
    "                \n",
    "        for i in range(self.epoch):\n",
    "            get_mini_batch = GetMiniBatch(X, y_train_one_hot, batch_size=20)\n",
    "\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                # フォワードプロバゲーション**************************\n",
    "                self.A_list, self.Z_list = self._forward(mini_X_train, self.W_list, self.b_list)\n",
    "\n",
    "                # バックプロバゲーション**************************            \n",
    "                self._backward(mini_X_train, mini_y_train, self.W_list, self.b_list, self.A_list, self.Z_list)\n",
    "            \n",
    "            # クロスエントロピー誤差**************************\n",
    "            self.loss[i] = self._cross_entropy_error(mini_y_train, self.Z_list[-1])\n",
    "        \n",
    "        # 問題7 val_loss計算\n",
    "        if X_val is not None and y_val is not None:\n",
    "            self.val_W_list, self.val_b_list = self._init_network()\n",
    "            self.default_val_W_list, self.default_val_b_list = copy.deepcopy(self.val_W_list), copy.deepcopy(self.val_b_list)\n",
    "            \n",
    "            for i in range(self.epoch):\n",
    "                get_mini_batch = GetMiniBatch(X_val, y_val_one_hot, batch_size=20)\n",
    "\n",
    "                for mini_X_val, mini_y_val in get_mini_batch:\n",
    "                    # フォワードプロバゲーション**************************\n",
    "                    self.val_A_list, self.val_Z_list = self._forward(mini_X_val, self.val_W_list, self.val_b_list)\n",
    "\n",
    "                    # バックプロバゲーション**************************            \n",
    "                    self._backward(mini_X_val, mini_y_val, self.val_W_list, self.val_b_list, self.val_A_list, self.val_Z_list)\n",
    "\n",
    "                self.val_loss[i] = self._cross_entropy_error(mini_y_val, self.val_Z_list[-1])\n",
    "\n",
    "        if self.verbose:\n",
    "            # verboseをTrueにした際は学習過程などを出力する\n",
    "            pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, self.n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        _, Z = self._forward(X, self.W_list, self.b_list)        \n",
    "        pred = np.argmax(Z[-1], axis=1)\n",
    "        return pred\n",
    "    \n",
    "    def accuracy(self, val, pred):\n",
    "        return accuracy_score(val, pred)\n",
    "\n",
    "    # 問題1\n",
    "    # 重み初期化\n",
    "    def _init_network(self):\n",
    "        \"\"\"重み初期値作成関数\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        sigma = 0.01  # ガウス分布の標準偏差\n",
    "        \n",
    "        # 重みは前ノード数の１/ルートが適切\n",
    "        W1 = sigma * np.random.randn(self.n_features, self.n_nodes1)\n",
    "        W2 = sigma * np.random.randn(self.n_nodes1, self.n_nodes2)\n",
    "        W3 = sigma * np.random.randn(self.n_nodes2, self.n_output)\n",
    "        \n",
    "        # バイアス項はランダム値か0かでパラメータ選択\n",
    "        if self.bias==True:\n",
    "            b1 = sigma * np.random.randn(self.n_nodes1)\n",
    "            b2 = sigma * np.random.randn(self.n_nodes2)\n",
    "            b3 = sigma * np.random.randn(self.n_output)\n",
    "        \n",
    "        else:\n",
    "            b1 = np.zeros(self.n_nodes1)\n",
    "            b2 = np.zeros(self.n_nodes2)\n",
    "            b3 = np.zeros(self.n_output)\n",
    "\n",
    "        W_list = [W1, W2, W3]\n",
    "        b_list = [b1, b2, b3]\n",
    "\n",
    "        return W_list, b_list\n",
    "\n",
    "    # 問題2\n",
    "    # 活性化関数（フォワードプロバゲーション）\n",
    "    def _forward(self, X, W, b):\n",
    "        \"\"\"\n",
    "        X :\n",
    "        \"\"\"\n",
    "        # sigmoid\n",
    "        if self.func == \"sigmoid\":            \n",
    "            A1 = np.dot(X, W[0]) + b[0]     #(20, 400)\n",
    "            Z1 = self._sigmoid(A1)\n",
    "            A2 = np.dot(Z1, W[1]) + b[1]   #(20, 200)\n",
    "            Z2 = self._sigmoid(A2)\n",
    "            A3 = np.dot(Z2, W[2]) + b[2]   #(20, 10)\n",
    "            Z3 = self._softmax(A3)\n",
    "        \n",
    "        # tanh\n",
    "        else:\n",
    "            A1 = np.dot(X, W[0]) + b[0]     #(20, 400)\n",
    "            Z1 = self._hyperbolic_tangent(A1)\n",
    "            A2 = np.dot(Z1, W[1]) + b[1]   #(20, 200)\n",
    "            Z2 = self._hyperbolic_tangent(A2)\n",
    "            A3 = np.dot(Z2, W[2]) + b[2]   #(20, 10)\n",
    "            Z3 = self._softmax(A3)\n",
    "\n",
    "        A_list = [A1, A2, A3]\n",
    "        Z_list = [Z1, Z2, Z3]    # Z[-1]:Z3が予測値\n",
    "        \n",
    "        return A_list, Z_list\n",
    "\n",
    "    # 問題4\n",
    "    # 確率的勾配降下法(バックプロパゲーション)\n",
    "    # ここのコード：書き足しで進めて行き、長くなってしまった。分岐自体はシンプルなので、中身は薄い。何かアドバイスがほしい。\n",
    "    def _backward(self, X, y, W, b, A, Z):\n",
    "        if self.func == \"sigmoid\":\n",
    "            # 3層目\n",
    "            gra_a_3 = Z[-1] - y\n",
    "            gra_b_3 = np.sum(gra_a_3, axis=0)\n",
    "            gra_W_3 = np.dot(Z[1].T, gra_a_3)\n",
    "            gra_z_3 = np.dot(gra_a_3, W[-1].T)\n",
    "\n",
    "            # 2層目\n",
    "            gra_a_2 = gra_z_3*np.multiply((1-self._sigmoid(A[1])), self._sigmoid(A[1]))\n",
    "            gra_b_2 = np.sum(gra_a_2, axis=0)\n",
    "            gra_W_2 = np.dot(Z[0].T, gra_a_2)\n",
    "            gra_z_2 = np.dot(gra_a_2, W[1].T)\n",
    "\n",
    "            # 1層目\n",
    "            gra_a_1 = gra_z_2*np.multiply((1-self._sigmoid(A[0])), self._sigmoid(A[0]))\n",
    "            gra_b_1 = np.sum(gra_a_1, axis=0)\n",
    "            gra_W_1 = np.dot(X.T, gra_a_1)\n",
    "\n",
    "            gra_b_list = [gra_b_1, gra_b_2, gra_b_3]\n",
    "            gra_W_list = [gra_W_1, gra_W_2, gra_W_3]\n",
    "\n",
    "            for i in range(3):\n",
    "                W[i] -= self.lr*gra_W_list[i]\n",
    "                b[i] -= self.lr*gra_b_list[i]    \n",
    "\n",
    "        if self.func == \"tanh\":\n",
    "            # 3層目\n",
    "            gra_a_3 = Z[-1] - y\n",
    "            gra_b_3 = np.sum(gra_a_3, axis=0)\n",
    "            gra_W_3 = np.dot(Z[1].T, gra_a_3)\n",
    "            gra_z_3 = np.dot(gra_a_3, W[-1].T)\n",
    "\n",
    "            # 2層目\n",
    "            gra_a_2 = gra_z_3*((1-self._hyperbolic_tangent(A[1])**2))\n",
    "            gra_b_2 = np.sum(gra_a_2, axis=0)\n",
    "            gra_W_2 = np.dot(Z[0].T, gra_a_2)\n",
    "            gra_z_2 = np.dot(gra_a_2, W[1].T)\n",
    "\n",
    "            # 1層目\n",
    "            gra_a_1 = gra_z_2*((1-self._hyperbolic_tangent(A[0])**2))\n",
    "            gra_b_1 = np.sum(gra_a_1, axis=0)\n",
    "            gra_W_1 = np.dot(X.T, gra_a_1)\n",
    "\n",
    "            gra_b_list = [gra_b_1, gra_b_2, gra_b_3]\n",
    "            gra_W_list = [gra_W_1, gra_W_2, gra_W_3]\n",
    "\n",
    "            for i in range(3):\n",
    "                W[i] -= self.lr*gra_W_list[i]\n",
    "                b[i] -= self.lr*gra_b_list[i]    \n",
    "\n",
    "    \n",
    "    # 問題2------------------------------------\n",
    "    # シグモイド関数\n",
    "    def _sigmoid(self, X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "\n",
    "    #ハイパボリックタンジェント関数\n",
    "    def _hyperbolic_tangent(self, X):\n",
    "        return np.tanh(X)\n",
    "\n",
    "    # ソフトマックス関数\n",
    "    def _softmax(self, X):\n",
    "        c = np.max(X)\n",
    "        \n",
    "        return np.exp(X-c) / np.sum(np.exp(X - c), axis=1, keepdims=True)\n",
    "\n",
    "    # 問題３------------------------------------\n",
    "    # クロスエントロピー誤差関数\n",
    "    def _cross_entropy_error(self, y, Z):\n",
    "        if y.ndim == 1:\n",
    "            Z = t.reshape(1, Z.size)\n",
    "            y = y.reshape(1, y.size)        \n",
    "        \n",
    "        batch_size = y.shape[0]\n",
    "        \n",
    "        error = -np.sum(y*np.log(Z + 1e-7)) / batch_size\n",
    "        \n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# backward検算\n",
    "\n",
    "n_features = 784\n",
    "n_nodes1 = 400\n",
    "n_nodes2 = 200\n",
    "n_output = 10\n",
    "sigma = 0.01  # ガウス分布の標準偏差\n",
    "\n",
    "tmpW1 = sigma * np.random.randn(n_features, n_nodes1)\n",
    "tmpW2 = np.random.randn(n_nodes1, n_nodes2) / np.sqrt(n_nodes1)\n",
    "tmpW3 = np.random.randn(n_nodes2, n_output) / np.sqrt(n_nodes2)\n",
    "tmpb1 = sigma * np.random.randn(n_nodes1)\n",
    "tmpb2 = np.random.randn(n_nodes2) / np.sqrt(n_nodes1)\n",
    "tmpb3 = np.random.randn(n_output) / np.sqrt(n_nodes2)\n",
    "\n",
    "tmp_W_list = [tmpW1, tmpW2, tmpW3]\n",
    "tmp_b_list = [tmpb1, tmpb2, tmpb3]\n",
    "\n",
    "tmpA1 = np.dot(mini_X_train, tmp_W_list[0]) + tmp_b_list[0]     #(20, 400)\n",
    "tmpZ1 = scr_NN._sigmoid(tmpA1)\n",
    "tmpA2 = np.dot(tmpZ1, tmp_W_list[1]) + tmp_b_list[1]   #(20, 200)\n",
    "tmpZ2 = scr_NN._sigmoid(tmpA2)\n",
    "tmpA3 = np.dot(tmpZ2, tmp_W_list[2]) + tmp_b_list[2]   #(20, 10)\n",
    "tmpZ3 = scr_NN._softmax(tmpA3)\n",
    "\n",
    "A_list = [tmpA1, tmpA2, tmpA3]\n",
    "Z_list = [tmpZ1, tmpZ2, tmpZ3] \n",
    "\n",
    "gra_a_3 = Z_list[-1] - mini_y_train_hot    # (20, 10)\n",
    "gra_b_3 = np.sum(gra_a_3, axis=0)     #(10,)\n",
    "gra_W_3 = np.dot(Z_list[1].T, gra_a_3)   #(200, 10)\n",
    "gra_z_3 = np.dot(gra_a_3, tmp_W_list[-1].T)    #(20, 200)\n",
    "\n",
    "\n",
    "gra_a_2 = gra_z_3*((1-scr_NN._sigmoid(A_list[1])*scr_NN._sigmoid(A_list[1])))  #(20, 200)\n",
    "gra_b_2 = np.sum(gra_a_2, axis=0)  #(200,)\n",
    "gra_W_2 = np.dot(Z_list[0].T, gra_a_2)  #(400, 200)\n",
    "gra_z_2 = np.dot(gra_a_2, tmp_W_list[1].T)  #(20, 400)\n",
    "\n",
    "gra_a_1 = gra_z_2*((1-scr_NN._sigmoid(A_list[0])*scr_NN._sigmoid(A_list[0])))\n",
    "gra_b_1 = np.sum(gra_a_1, axis=0)\n",
    "gra_W_1 = np.dot(mini_X_train.T, gra_a_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】重みの初期値を決めるコードの作成\n",
    "ニューラルネットワークの各層の重みの初期値を決めるコードを作成してください。\n",
    "\n",
    "\n",
    "重みの初期値は様々な方法が提案されていますが、今回はガウス分布による単純な初期化を行います。バイアスに関しても同様です。\n",
    "\n",
    "\n",
    "以下のコードを参考にしてください。標準偏差の値sigmaはハイパーパラメータです。発展的な重みの初期化方法については次のSprintで扱います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】フォワードプロパゲーションの実装\n",
    "三層のニューラルネットワークの フォワードプロパゲーション を作成してください。以下の説明ではノード数は1層目は400、2層目は200としますが、変更しても構いません。\n",
    "\n",
    "\n",
    "各層の数式を以下に示します。今回はそれぞれの記号が表す配列が、実装上どのようなndarrayのshapeになるかを併記してあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】交差エントロピー誤差の実装\n",
    "目的関数（損失関数）を作成します。\n",
    "\n",
    "\n",
    "多クラス分類の目的関数である交差エントロピー誤差 $L$ は次の数式です。\n",
    "\n",
    "\n",
    "L\n",
    "=\n",
    "−\n",
    "1\n",
    "n\n",
    "b\n",
    "n\n",
    "b\n",
    "∑\n",
    "j\n",
    "  \n",
    "n\n",
    "c\n",
    "∑\n",
    "k\n",
    " \n",
    "y\n",
    "j\n",
    "k\n",
    "l\n",
    "o\n",
    "g\n",
    "(\n",
    "z\n",
    "3\n",
    "_\n",
    "j\n",
    "k\n",
    ")\n",
    "\n",
    "$y_{ij}$ : $j$ 番目のサンプルの $k$ 番目のクラスの正解ラベル（one-hot表現で0か1のスカラー）\n",
    "\n",
    "\n",
    "$z_{3_ij}$ : $j$ 番目のサンプルの $k$ 番目のクラスの確率（スカラー）\n",
    "\n",
    "\n",
    "$n_{b}$ : バッチサイズ、batch_size\n",
    "\n",
    "\n",
    "$n_{c}$ : クラスの数、n_output（今回のMNISTでは10）\n",
    "\n",
    "\n",
    "サンプル1つあたりの誤差が求まります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】バックプロパゲーションの実装\n",
    "三層のニューラルネットワークのバックプロパゲーションを作成してください。確率的勾配降下法を行う部分です。\n",
    "\n",
    "\n",
    "数式を以下に示します。\n",
    "\n",
    "\n",
    "まず、i層目の重みとバイアスの更新式です。 $W_i$ と $B_i$ に対し、更新後の $W_i^{\\prime}$ と $B_i^{\\prime}$ は次の数式で求められます。\n",
    "\n",
    "$$\n",
    "W\n",
    "′\n",
    "i\n",
    "=\n",
    "W\n",
    "i\n",
    "−\n",
    "α\n",
    "\\frac{∂L}{∂Wi}\n",
    "$$\n",
    "\n",
    "$$\n",
    "B′i\n",
    "=\n",
    "B\n",
    "i\n",
    "−\n",
    "α\\frac{∂L}{∂Bi}\n",
    "$$\n",
    "\n",
    "$\\alpha$ : 学習率（層ごとに変えることも可能だが、基本的には全て同じとする）\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_i}$ : $W_i$ に関する損失 $L$ の勾配\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial B_i}$ : $B_i$ に関する損失 $L$ の勾配\n",
    "\n",
    "\n",
    "＊この勾配はミニバッチのサンプル数分の合計または平均を考えます。ここでは合計を計算します。\n",
    "\n",
    "\n",
    "この更新方法はSprint3線形回帰やsprint4ロジスティック回帰における最急降下法と同様です。より効果的な更新方法が知られており、それは次のSprintで扱います。\n",
    "\n",
    "\n",
    "勾配 $\\frac{\\partial L}{\\partial W_i}$ や $\\frac{\\partial L}{\\partial B_i}$ を求めるために、バックプロパゲーションを行います。以下の数式です。ハイパボリックタンジェント関数を使用した例を載せました。シグモイド関数の場合の数式はその後ろにあります。\n",
    "\n",
    "\n",
    "「3層目」\n",
    "\n",
    "$$\n",
    "\\frac{∂L}{∂A3}\n",
    "=\n",
    "Z3−Y\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{∂L}{∂B3}\n",
    "=\n",
    "\\sum_{j}^{n_b} \\quad\\frac{∂L}{∂A3_j}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{∂L}{∂W3}\n",
    "=\n",
    "Z_2^T\n",
    "⋅\n",
    "\\frac{∂L}{∂A3}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{∂L}{∂Z2}\n",
    "=\n",
    "\\frac{∂L}{∂A3}\n",
    "⋅\n",
    "W_3^T\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_3}$ : $A_3$ に関する損失 $L$ の勾配 (batch_size, n_output)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_{3_j}}$ : j番目のサンプルの$A_3$ に関する損失 $L$ の勾配 (n_nodes2,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial B_3}$ : $B_3$ に関する損失 $L$ の勾配 (n_output,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_3}$ : $W_3$ に関する損失 $L$ の勾配 (n_nodes2, n_output)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial Z_2}$ : $Z_2$ に関する損失 $L$ の勾配 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$Z_{3}$ : ソフトマックス関数の出力 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$Y$ : 正解ラベル (batch_size, n_output)\n",
    "\n",
    "\n",
    "$Z_{2}$ : 2層目の活性化関数の出力 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$W_3$ : 3層目の重み (n_nodes2, n_output)\n",
    "\n",
    "\n",
    "「2層目」\n",
    "$$\\frac{∂L}{∂A2}=\\frac{∂L}{∂Z2}⊙{1−tanh^2(A2)}$$\n",
    "\n",
    "$$\\frac{∂L}{∂B2}=\\sum_{j}^{nb}\\quad\\frac{∂L}{∂A2_j}$$\n",
    "\n",
    "$$\\frac{∂L}{∂W2}=Z_1^T⋅\\frac{∂L}{∂A2}$$\n",
    "\n",
    "$$\\frac{∂L}{∂Z1}=\\frac{∂L}{∂A2}⋅W_2^T$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_2}$ : $A_2$ に関する損失 $L$ の勾配 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_{2_j}}$ : j番目のサンプルの$A_2$ に関する損失 $L$ の勾配 (n_nodes2,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial B_2}$ : $B_2$ に関する損失 $L$ の勾配 (n_output,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_2}$ : $W_2$ に関する損失 $L$ の勾配 (n_nodes1, n_nodes2)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial Z_2}$ : $Z_2$ に関する損失 $L$ の勾配 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$A_2$ : 2層目の出力 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$Z_{1}$ : 1層目の活性化関数の出力 (batch_size, n_nodes1)\n",
    "\n",
    "\n",
    "$W_2$ : 2層目の重み (n_nodes1, n_nodes2)\n",
    "\n",
    "\n",
    "「1層目」\n",
    "\n",
    "$$\\frac{∂L}{∂A1}=\\frac{∂L}{∂Z1}⊙{1−tanh^2(A1)}$$\n",
    "\n",
    "$$\\frac{∂L}{∂B1}=\\sum_{j}^{nb} \\quad\\frac{∂L}{∂A1_j}$$\n",
    "\n",
    "$$\\frac{∂L}{∂W1}=X^T⋅\\frac{∂L}{∂A1}$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_1}$ : $A_1$ に関する損失 $L$ の勾配 (batch_size, n_nodes1)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_{1_j}}$ : j番目のサンプルの$A_1$ に関する損失 $L$ の勾配 (n_nodes1,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial B_1}$ : $B_1$ に関する損失 $L$ の勾配 (n_output,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_1}$ : $W_1$ に関する損失 $L$ の勾配 (n_features, n_nodes1)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial Z_1}$ : $Z_1$ に関する損失 $L$ の勾配 (batch_size, n_nodes1)\n",
    "\n",
    "\n",
    "$A_1$ : 1層目の出力 (batch_size, n_nodes1)\n",
    "\n",
    "\n",
    "$X$ : 特徴量ベクトル (batch_size, n_features)\n",
    "\n",
    "\n",
    "$W_1$ : 1層目の重み (n_features, n_nodes1)\n",
    "\n",
    "\n",
    "《補足》\n",
    "\n",
    "\n",
    "活性化関数にシグモイド関数を使用した場合は、次のようになります。\n",
    "$$\n",
    "\\frac{∂L}{∂A2}=\\frac{∂L}{∂Z2}⊙{1−sigmoid(A2)}sigmoid(A2)\n",
    "$$\n",
    "$$\n",
    "\\frac{∂L}{∂A1}=\\frac{∂L}{∂Z1}⊙{1−sigmoid(A1)}sigmoid(A1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】学習と推定\n",
    "MNISTのデータを学習・推定し、Accuracyを計算してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9812\n"
     ]
    }
   ],
   "source": [
    "# 最も正解率の高かったlr:0.01でエポック数を20にして再度実行\n",
    "scr_NN = ScratchSimpleNeuralNetrowkClassifier(epoch=20, lr=0.01, bias=False, func=\"tanh\")\n",
    "\n",
    "scr_NN.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "pred = scr_NN.predict(X_test)\n",
    "print(\"Accuracy:{}\".format(scr_NN.accuracy(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 983, 1134, 1036, 1005,  982,  890,  956, 1030,  974, 1010])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問題なく分類できているようである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題7】学習曲線のプロット\n",
    "学習曲線をプロットしてください。\n",
    "\n",
    "\n",
    "ニューラルネットワークは過学習が発生しやすいため、学習曲線の確認が重要です。訓練データと検証データに対するエポックごとの損失（交差エントロピー誤差）を記録できるようにする必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42675193, 0.3283919 , 0.1830784 , 0.13086055, 0.09298201,\n",
       "       0.06288756, 0.04015959, 0.02767756, 0.01261564, 0.00785663,\n",
       "       0.00608212, 0.00695828, 0.00737417, 0.0034542 , 0.00250979,\n",
       "       0.00191761, 0.0015346 , 0.00127713, 0.00109447, 0.00095934])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scr_NN.loss\n",
    "\n",
    "scr_NN.val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(scr_NN.loss, marker=\".\", label=\"train_loss\")\n",
    "plt.plot(scr_NN.val_loss, marker=\".\", label=\"val_loss\")\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題8】（アドバンス課題）誤分類の確認\n",
    "誤分類した画像はどのようなものだったかを確認してください。推定値を用意し、以下のコードを実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adachi-yuya/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADQAAABBCAYAAACel4eZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAA1NJREFUaIHtmU9IG3kUxz+v1oZhqaykKrqlpXgQ/7QGBA8LbfxzKT1IwUNPVrNCYQ8esqc9LHjw1usuwu6xQVkPgmRZFrwsugdBqSEVLyEptBSaZVVM6SCIydtDNaxLmxnjJBns7wOPMJM3b96X38ub95uIqnKRuFTrBLzGCPI7RpDfMYL8jhF0goi8/5/lReRHh2t+EZEnHzk/LiLPReSdiLwRkacicrmsxFT13AZ8AbwH7jn4vQauf+T8t8Bd4ArwFfAc+L6sXDwSNA68BKSEzx3ghct43wG/lZOLV7+hceCZlh4MHwC/u4x3D9guKxMPVucGkAduOfj9Bdx1ES8CvAGu1aTkgB+AFQefL4F/gDoHv4fA38DtsvPxQFAK+MbB5xHwq4PP/WPR/efK55xivgZs4KqD3zPgcYnvh4BdHLpkNQT9DMQcfAR4CzSX8PkTOOJD6z+xP8rJSY4DVgwR6Qd+UtX+it7omGqNPtNVuk/lV6jamOHU75xpohWRmtanqoqTz4VbISPI7xhBfscI8jvlvVlxQX19PQCdnZ309vbS3d3N8PAwExMTbG+Xt7t2xRm3C+rWIpGIRiIRzefzWigUinZ0dKSxWEwty1LLslzH+5Cqx9uHs0wK4XAYgLGxMXK5HIVCgVQqRXNzMzMzMwwODgKwsrLi+v6f5aRQsZL7lLW1talt2xqNRjUajXpeclUV1N7erplMRtfW1jQYDGowGPRckOddrq6ujo6ODnp6egAYGBggHo+zv7/P/Pw8TU1NjIyMsLu7WzJOQ0MDAKFQiNXVVfcJeLlCfX19Ojc3d6qrqeqp44WFBW1paflkjMbGRp2amtJkMqnJZFLT6XRtSm5ycrLYouPx+CkRh4eHms1mNZvNaj6f14ODA00kEppIJDSVSmk6ndbl5WXN5XJq2/apa5eWlmrTtjc3NwmFQsVj27YBWFxcZHZ2tvgwbW1tJRwOY1kWAENDQ2xsbNDV1UUmk2FnZweAra2t4ufe3t5JNTm2bc9WaHp6WtfX1zUWi+no6KgGAgENBALn7or/NTc5XrjnUMUmhUrwWU4KRpDfMYL8jhHkd4wgv3PhBJ11g7cDvKpEIi646cbJ/CXpd4wgv2ME+R0jyO8YQX7nXzA71VBsgJrBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "語分類結果を並べて表示する。画像の上の表示は「推定結果/正解」である。\n",
    "\n",
    "Parameters:\n",
    "----------\n",
    "y_pred : 推定値のndarray (n_samples,)\n",
    "y_val : 検証データの正解ラベル(n_samples,)\n",
    "X_val : 検証データの特徴量（n_samples, n_features)\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "num = 36 # いくつ表示するか\n",
    "true_false = pred==y_val\n",
    "false_list = np.where(true_false==False)[0].astype(np.int)\n",
    "if false_list.shape[0] < num:\n",
    "    num = false_list.shape[0]\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "fig.subplots_adjust(left=0, right=0.8,  bottom=0, top=0.8, hspace=1, wspace=0.5)\n",
    "for i in range(num):\n",
    "    ax = fig.add_subplot(6, 6, i + 1, xticks=[], yticks=[])\n",
    "    ax.set_title(\"{} / {}\".format(pred[false_list[i]],y_val[false_list[i]]))\n",
    "    ax.imshow(X_val.reshape(-1,28,28)[false_list[i]], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最後の課題は３６枚分出力されませんでしたが、提出させていただきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 711,
   "position": {
    "height": "732.986px",
    "left": "1718.99px",
    "right": "20px",
    "top": "112.99px",
    "width": "406.997px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
