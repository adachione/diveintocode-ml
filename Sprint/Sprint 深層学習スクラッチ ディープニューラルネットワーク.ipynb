{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 深層学習スクラッチ ディープニューラルネットワーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, y, batch_size=20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0] / self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        p0 = item * self.batch_size\n",
    "        p1 = item * self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter * self.batch_size\n",
    "        p1 = self._counter * self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】全結合層のクラス化\n",
    "全結合層のクラス化を行なってください。\n",
    "\n",
    "\n",
    "以下に雛形を載せました。コンストラクタで重みやバイアスの初期化をして、あとはフォワードとバックワードのメソッドを用意します。重みW、バイアスB、およびフォワード時の入力Xをインスタンス変数として保持しておくことで、煩雑な入出力は不要になります。\n",
    "\n",
    "\n",
    "なお、インスタンスも引数として渡すことができます。そのため、初期化方法のインスタンスinitializerをコンストラクタで受け取れば、それにより初期化が行われます。渡すインスタンスを変えれば、初期化方法が変えられます。\n",
    "\n",
    "\n",
    "また、引数として自身のインスタンスselfを渡すこともできます。これを利用してself.optimizer.update(self)という風に層の重みの更新が可能です。更新に必要な値は複数ありますが、全て全結合層が持つインスタンス変数にすることができます。\n",
    "\n",
    "\n",
    "初期化方法と最適化手法のクラスについては後述します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.initializer = initializer\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = self.initializer.W(self.n_nodes1, self.n_nodes2)\n",
    "        self.B = self.initializer.B(self.n_nodes2)\n",
    "        self.dW = 0\n",
    "        self.dB = 0\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        A = np.dot(X, self.W) + self.B   # (batch_size, n_nodes2)\n",
    "\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):   # TODO：Zを引数に渡さないやり方を考える\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        # TODO　dw とdbをバッチサイズで割る　FCで実行\n",
    "        self.dB = np.sum(dA, axis=0)\n",
    "        self.dW = np.dot(self.X.T, dA)\n",
    "        dZ = np.dot(dA, self.W.T)    # (batch_size, n_nodes1)\n",
    "        \n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】初期化方法のクラス化\n",
    "初期化を行うコードをクラス化してください。\n",
    "\n",
    "\n",
    "前述のように、全結合層のコンストラクタに初期化方法のインスタンスを渡せるようにします。以下の雛形に必要なコードを書き加えていってください。標準偏差の値（sigma）はコンストラクタで受け取るようにすることで、全結合層のクラス内にこの値（sigma）を渡さなくてすむようになります。\n",
    "\n",
    "\n",
    "これまで扱ってきた初期化方法はSimpleInitializerクラスと名付けることにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        \n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = np.random.randn(n_nodes2)\n",
    "        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】最適化手法のクラス化\n",
    "最適化手法のクラス化を行なってください。\n",
    "\n",
    "\n",
    "最適化手法に関しても初期化方法同様に全結合層にインスタンスとして渡します。バックワードのときにself.optimizer.update(self)のように更新できるようにします。以下の雛形に必要なコードを書き加えていってください。\n",
    "\n",
    "\n",
    "これまで扱ってきた最適化手法はSGDクラス（Stochastic Gradient Descent、確率的勾配降下法）として作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        # TODO Eの計算\n",
    "        \n",
    "        layer.W -= self.lr * layer.dW\n",
    "        layer.B -= self.lr * layer.dB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】活性化関数のクラス化\n",
    "活性化関数のクラス化を行なってください。\n",
    "\n",
    "\n",
    "ソフトマックス関数のバックプロパゲーションには交差エントロピー誤差の計算も含む実装を行うことで計算が簡略化されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return np.tanh(A)\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        dZ : n層目のバックプロバゲーション\n",
    "        A :　n層目のフォワードプロバゲーションのA\n",
    "        \n",
    "        \"\"\"\n",
    "        y = dZ*((1-self.forward(self.A)**2))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return 1 / (1 + np.exp(-A))\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        dZ : n層目のバックプロバゲーション\n",
    "        A :　n層目のフォワードプロバゲーションのA\n",
    "         \n",
    "        \"\"\"\n",
    "        y = dZ*(1-self.forward(self.A))*(self.forward(self.A))\n",
    "        return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax():\n",
    "    \"\"\"\n",
    "    ソフトマックス関数クラス\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self, A):\n",
    "        # ソフトマックス計算 Zが出力値\n",
    "        self.A = A\n",
    "        c = np.max(A)\n",
    "        self.Z = np.exp(A-c) / np.sum(np.exp(A-c), axis=1, keepdims=True)\n",
    "        \n",
    "        return self.Z\n",
    "    \n",
    "    def backward(self, Z, y):\n",
    "        \"\"\"\n",
    "        dZ　: 最終層のZ\n",
    "        Y　:　（バッチ）サンプルラベル\n",
    "        \"\"\"\n",
    "        dZ = self.Z - y\n",
    "        \n",
    "        # クロスエントロピー誤差計算\n",
    "        batch_size = y.shape[0]\n",
    "        error = -np.sum(y*np.log(self.Z + 1e-7)) / batch_size\n",
    "        \n",
    "        return dZ , error\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】ReLUクラスの作成\n",
    "現在一般的に使われている活性化関数であるReLU（Rectified Linear Unit）をReLUクラスとして実装してください。\n",
    "\n",
    "\n",
    "ReLUは以下の数式です。\n",
    "\n",
    "$$\n",
    "f(x)=ReLU(x)=\n",
    "\\begin{cases}\n",
    "x \\quad x \\geqq 0 \\\\\n",
    "0 \\quad x < 0 \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$x$ : ある特徴量。スカラー\n",
    "\n",
    "\n",
    "実装上はnp.maximumを使い配列に対してまとめて計算が可能です。\n",
    "\n",
    "\n",
    "numpy.maximum — NumPy v1.15 Manual\n",
    "\n",
    "\n",
    "一方、バックプロパゲーションのための $x$ に関する $f(x)$ の微分は以下のようになります。\n",
    "\n",
    "$$\n",
    "\\frac{∂f(x)}{∂x}=\n",
    "        \\begin{cases}\n",
    "        1 \\quad x \\geqq 0 \\\\\n",
    "        0 \\quad x ≦ 0 \\\\\n",
    "        \\end{cases}\n",
    "$$\n",
    "数学的には微分可能ではないですが、 $x=0$ のとき $0$ とすることで対応しています。\n",
    "\n",
    "\n",
    "フォワード時の $x$ の正負により、勾配を逆伝播するかどうかが決まるということになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ゼロつくに乗っていたコード\n",
    "class Relu():\n",
    "    \"\"\"\n",
    "    Relu関数クラス\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, A):\n",
    "        self.mask = (A <= 0)\n",
    "        out = A.copy()\n",
    "        out[self.mask] = 0\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dz):\n",
    "        \"\"\"\n",
    "        Z:\n",
    "        y:\n",
    "        \n",
    "        \"\"\"\n",
    "        dz[self.mask] = 0\n",
    "        y = dz\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 2]\n",
      " [3 4]]\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Relu関数テスト\n",
    "x = np.arange(-5, 5).reshape(5, 2)\n",
    "\n",
    "relu = Relu()\n",
    "\n",
    "print(relu.forward(x))\n",
    "print(relu.backward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】重みの初期値\n",
    "ここまでは重みやバイアスの初期値は単純にガウス分布で、標準偏差をハイパーパラメータとして扱ってきました。しかし、どのような値にすると良いかが知られています。シグモイド関数やハイパボリックタンジェント関数のときは Xavierの初期値 （またはGlorotの初期値）、ReLUのときは Heの初期値 が使われます。\n",
    "\n",
    "\n",
    "XavierInitializerクラスと、HeInitializerクラスを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XavierInitializer:\n",
    "    \"\"\"\n",
    "    Xavierの初期値作成クラス\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        sigma = 1.0 / np.sqrt(n_nodes1)\n",
    "        W = sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        \n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = np.zeros(n_nodes2)\n",
    "        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.96272925e-02 -7.25457924e-03 -6.43566436e-02 -2.43820894e-02\n",
      "   1.44638969e-02 -1.08927026e-02 -7.09560110e-02 -1.40981085e-01\n",
      "  -5.72030007e-02  7.37842821e-02 -6.61378340e-02  8.04202272e-02\n",
      "   5.91680496e-02  3.35842624e-02 -5.43736582e-02  2.80245068e-02\n",
      "   8.49027551e-03  3.39315206e-02  7.59273259e-02 -3.51376168e-02\n",
      "   2.22471587e-02 -6.90453782e-02  1.74384673e-02 -1.34272578e-02\n",
      "  -9.26235320e-02 -7.02170290e-02  1.89832260e-02 -2.32902348e-02\n",
      "   2.52798686e-02  4.46500675e-02 -1.95489644e-02  3.36459040e-02\n",
      "   8.58390121e-02 -3.28112312e-02 -8.32458726e-02 -7.42986386e-03\n",
      "  -6.33928789e-02  4.03879704e-02  2.12108059e-02 -1.51180597e-02\n",
      "   1.20521848e-01 -5.90064276e-03 -1.53881126e-02  5.40379970e-02\n",
      "   3.07673103e-02 -6.93753083e-02  2.44004790e-02 -4.40025149e-03\n",
      "  -4.16833792e-02  6.09292152e-02 -2.23067350e-02 -6.81977636e-02\n",
      "  -4.76240576e-02 -2.23145996e-02 -9.92977309e-03 -2.67828687e-02\n",
      "  -9.21322827e-03 -1.46930959e-02 -1.06973831e-02  6.92195203e-03\n",
      "   2.51000797e-02  5.86379754e-02  2.18317704e-03  1.07035949e-02\n",
      "  -3.09751501e-02 -1.29687151e-02 -2.87398702e-03  4.73899282e-02\n",
      "  -2.36700164e-02 -2.70832183e-02  3.02690711e-03  4.51701488e-02\n",
      "   7.67945033e-02  2.00346337e-02 -4.25997177e-02 -5.40983682e-02\n",
      "  -4.45864091e-02 -5.05623144e-02  5.09255753e-02  8.38660232e-02\n",
      "   1.67978336e-02  6.59703926e-02  3.56271229e-02 -6.86083580e-03\n",
      "   1.57334154e-02  2.68850100e-02 -4.12419423e-02 -3.84159452e-02\n",
      "   2.57710700e-02 -6.61219395e-02 -5.86266431e-02 -6.41201672e-02\n",
      "   9.40220934e-03  4.13992718e-02 -5.52048966e-02  1.65523114e-02\n",
      "   7.43853800e-02  3.93086545e-02 -9.84726892e-02 -6.68719985e-02\n",
      "   1.30036717e-02 -4.88082843e-02  3.21988362e-02 -4.95360592e-02\n",
      "  -3.36326119e-02 -4.55910054e-03  2.80174844e-02 -1.12643974e-02\n",
      "   1.25120336e-02 -2.76353045e-02  2.40837392e-02  1.06935041e-01\n",
      "  -6.62545907e-02  1.78614721e-02  2.33980784e-02 -1.70403974e-02\n",
      "  -2.32714321e-02 -1.59504509e-02 -2.70551197e-03  3.79101583e-02\n",
      "  -2.98084511e-03  3.94716214e-02  4.95403605e-02  2.50242892e-02\n",
      "   4.78369103e-02 -3.05165810e-02  3.00548007e-02  1.29283699e-02\n",
      "   1.18175046e-02 -4.03257726e-02  9.83426535e-02  1.11364405e-02\n",
      "   1.01184400e-02  7.66403163e-02 -8.45267703e-02 -8.30810899e-03\n",
      "   2.56890369e-02 -1.90892397e-02  2.33419071e-02 -9.01827705e-02\n",
      "   1.51610636e-02  1.11630204e-01  3.84997509e-03 -1.47312258e-01\n",
      "  -6.98959724e-02 -7.88151398e-02 -5.36688051e-02 -4.27430044e-02\n",
      "   5.46488189e-02 -6.90901318e-02 -1.43585129e-02  9.16397460e-02\n",
      "   2.64458250e-02 -6.79753791e-04 -4.70340356e-02 -7.82733301e-02\n",
      "  -3.43779211e-02  1.38909228e-02  2.90806436e-03 -4.94047252e-02\n",
      "  -5.19000730e-02  4.96250659e-02 -5.41165212e-03 -1.26017267e-01\n",
      "  -2.47250618e-02  1.97959670e-02  3.69626554e-02  4.79193848e-02\n",
      "  -4.66626251e-02  1.76441097e-02 -1.55241146e-02  1.61221137e-02\n",
      "   2.08592102e-02 -4.21566732e-02 -9.72763382e-02  4.30611427e-02\n",
      "   2.00364539e-02  2.53553118e-02  9.59594077e-02  5.92117435e-04\n",
      "  -3.13090912e-02 -2.29124550e-02  4.64688443e-02  3.69417856e-02\n",
      "  -5.21709879e-02 -1.14731469e-01 -1.86002684e-02  2.15177998e-02\n",
      "  -6.32023366e-02  5.16709233e-02 -4.94265539e-02  4.76772273e-02\n",
      "  -6.68309954e-03  3.86274529e-04 -3.25976482e-02 -1.51247127e-02\n",
      "  -1.22604227e-02  3.09543869e-02 -3.83535181e-02  7.84426912e-02]\n",
      " [ 9.52988858e-02  6.47618937e-02 -2.67861709e-02  1.08438346e-02\n",
      "   8.63752131e-03  3.77497359e-02  3.27640342e-02  5.31977374e-02\n",
      "   5.98468936e-02  4.84923663e-02 -8.56808076e-02  5.66186460e-02\n",
      "   3.16206476e-02 -3.01408227e-02  4.57324678e-02 -7.28852413e-03\n",
      "  -3.39054564e-02 -8.00361290e-03  6.55611481e-02  8.56752190e-02\n",
      "   9.06499210e-03  4.81865667e-02 -6.60076346e-02 -5.04883416e-02\n",
      "  -1.30923203e-02 -1.03751673e-03 -2.53429916e-02 -1.13534717e-01\n",
      "   2.92544745e-02 -1.67940010e-02 -1.93900462e-02 -1.90821326e-02\n",
      "  -3.03438895e-03  1.79093563e-02 -6.20483261e-02 -3.56216333e-02\n",
      "   2.92505976e-02 -4.97485518e-02  1.27189687e-02  4.23986387e-02\n",
      "   2.63602456e-02  5.18951120e-02 -1.21188744e-02 -1.05342165e-02\n",
      "   4.67292831e-02  2.62444054e-02  1.13777258e-02  1.61783687e-02\n",
      "  -8.85046414e-03 -5.73663544e-02  4.32380215e-03  6.85297432e-02\n",
      "   4.75747729e-03  7.18033248e-02 -5.40788944e-02 -5.44443445e-02\n",
      "   8.22424402e-02  1.79327688e-03 -5.67936203e-02 -1.12634206e-01\n",
      "   1.13360418e-01 -9.19742217e-03 -6.31153987e-03  1.44036112e-02\n",
      "  -1.28792662e-02  9.18843798e-03 -3.61798281e-02  2.06827006e-02\n",
      "  -1.38831281e-02 -3.28123618e-02 -2.75775483e-02 -3.26362041e-02\n",
      "  -6.31722683e-03 -1.23423339e-02 -3.90591447e-02  4.53991122e-02\n",
      "   4.70988094e-02 -2.62773770e-02 -4.74863958e-02  9.06739340e-03\n",
      "  -2.56264671e-02 -1.31207716e-02  7.54369138e-02 -1.74430952e-03\n",
      "   1.24779299e-02 -1.84363538e-02 -1.60478547e-02  5.50707053e-03\n",
      "   6.13332907e-02 -6.83025552e-02  4.79302753e-02  3.93397739e-02\n",
      "   2.63904326e-02  3.81728182e-02  1.17216277e-01 -6.91633076e-02\n",
      "  -1.21557400e-02  3.63600792e-02 -3.86740960e-02  9.25678602e-03\n",
      "   7.08495063e-02  4.21502930e-02  2.45170463e-02 -2.16501000e-02\n",
      "  -7.14429086e-02 -3.62753756e-02  1.77656914e-02  1.20261710e-01\n",
      "  -5.16517508e-02  3.04780097e-02 -1.61827658e-02  7.43995776e-02\n",
      "  -4.18486149e-02 -1.63616789e-02 -4.23585561e-02 -1.83675129e-02\n",
      "   3.17249018e-02  2.16750830e-02 -6.70164521e-02  1.01757260e-01\n",
      "   4.73189401e-02  2.83170042e-03  6.52330244e-03 -4.27482450e-02\n",
      "  -4.63429894e-02  1.80231052e-03  1.27211598e-02  6.57852335e-02\n",
      "   2.59322055e-03 -3.34449164e-02  2.96633824e-02  8.71133461e-02\n",
      "   1.97061979e-02  3.91937632e-02 -5.84624379e-02 -1.00433448e-02\n",
      "   1.35580763e-02 -4.13664692e-02 -2.12438671e-02 -3.70626743e-02\n",
      "   3.03497122e-02  4.18320564e-02  2.41223065e-03  5.26193143e-02\n",
      "   4.85262507e-02 -5.73127170e-02 -4.50479425e-02  5.29377908e-02\n",
      "  -2.11972156e-02 -9.33836374e-03 -5.35362534e-02 -3.34573363e-02\n",
      "  -5.03995926e-02  2.17474728e-02 -3.37537150e-02 -2.02863587e-02\n",
      "   4.73119338e-02  2.81754050e-03 -4.85256982e-02  1.69932555e-02\n",
      "   2.31900427e-02  1.62484064e-02 -3.64791539e-03 -7.50523844e-02\n",
      "   9.53467418e-03 -3.11384389e-02 -2.24871222e-02  4.24570752e-02\n",
      "  -6.21769282e-02 -4.73284609e-02  2.02707082e-02 -5.57762278e-02\n",
      "  -9.08490800e-02  1.82355745e-02 -4.25489567e-02 -5.54302824e-02\n",
      "   4.74573698e-02  2.39703949e-02  3.61015527e-02  7.83398096e-03\n",
      "  -3.89846552e-02  3.48108123e-02 -7.92744575e-02  8.96582593e-02\n",
      "  -1.58948298e-02  2.41750488e-02 -4.63467191e-02 -7.59776576e-02\n",
      "   5.31996977e-02  3.97122933e-02  2.18510187e-02 -2.92212639e-02\n",
      "  -5.17275928e-02  1.11865088e-02 -8.95929398e-02  6.36379608e-02\n",
      "   1.63500687e-03 -1.22726698e-02 -1.73032067e-01  3.79134451e-02]\n",
      " [-6.86381990e-03  1.39144590e-02  4.66412864e-02 -6.00144044e-02\n",
      "  -4.84865381e-03  4.18591318e-02  6.79697816e-02 -3.24508809e-02\n",
      "  -1.73839983e-02  7.30640470e-02 -1.15840507e-03  2.00572768e-03\n",
      "   3.21802172e-02  2.73937963e-02  8.97918414e-02  4.90738924e-02\n",
      "  -7.93732920e-02  3.78516155e-03  2.90739841e-03 -7.81129731e-04\n",
      "   2.85055930e-02 -3.35733542e-02  4.19304188e-02 -6.50889910e-02\n",
      "   6.45812385e-02 -9.49655283e-02 -2.38561031e-02 -4.43638650e-02\n",
      "   4.89294807e-02 -6.57447542e-02 -7.07398848e-02 -4.34344478e-02\n",
      "  -5.14383048e-03  8.82398864e-02 -7.78707289e-02  7.91858929e-02\n",
      "   4.41489437e-03  3.31024021e-03 -6.33848089e-02 -3.93440690e-02\n",
      "  -1.20437258e-02  7.10476407e-02 -3.20594674e-02  5.29922424e-02\n",
      "   1.04341907e-01 -2.31502555e-02  1.28480139e-02 -9.08056816e-03\n",
      "  -8.06374520e-02 -2.35414622e-02 -4.14140068e-02  5.98347696e-02\n",
      "   3.56701012e-02 -3.46140603e-02  1.10394726e-01  8.50571197e-02\n",
      "   3.97015919e-02  7.57707088e-02  6.20698192e-02  3.38110192e-02\n",
      "   8.65312998e-02 -2.04204900e-02  1.03937623e-01  1.14562520e-01\n",
      "   3.90357298e-02 -1.63384203e-02 -6.16309593e-02 -1.14835015e-01\n",
      "  -2.84106959e-02  3.99587065e-02 -2.23011087e-02  1.12471573e-02\n",
      "  -7.06221686e-02  1.74696726e-02 -7.01520204e-02 -5.94139120e-02\n",
      "  -3.38512698e-02  3.71290357e-02 -8.13687175e-02 -1.53196649e-02\n",
      "   1.03812368e-01 -7.96784957e-03  6.85933411e-03 -2.53602956e-02\n",
      "   2.20065879e-02 -9.14963345e-02 -6.26810068e-02 -2.00397625e-03\n",
      "  -3.10685521e-02 -1.28811240e-01  2.36093742e-02  4.63929219e-02\n",
      "  -2.12378481e-02  3.16273192e-02  8.02055891e-02 -2.56894109e-02\n",
      "  -3.29287044e-02 -6.61284382e-02 -6.32110409e-02 -6.68373594e-02\n",
      "   1.86347293e-02 -4.51382638e-02 -2.97402682e-02 -8.38093437e-02\n",
      "  -9.75660181e-02  5.21579387e-03  3.21045216e-02 -2.11793275e-02\n",
      "   5.25935838e-02 -5.78194456e-02 -3.37778822e-02 -4.78190227e-02\n",
      "   1.15077608e-02 -5.95557154e-02  6.62313328e-03  2.75038775e-02\n",
      "  -4.61723410e-02  9.57855192e-03  7.98907274e-02  1.69811411e-02\n",
      "   2.51549247e-02  2.64653347e-02 -1.23508840e-01 -2.24503485e-02\n",
      "   3.99096914e-02  6.34383447e-02 -9.86303071e-03  8.01089028e-02\n",
      "  -9.08232399e-03  9.57663049e-02 -5.18345566e-02  3.47521435e-02\n",
      "   1.72387060e-02 -4.74211499e-02  1.37653798e-02  5.83881311e-02\n",
      "   3.40520335e-02  5.41311547e-02 -6.31230265e-03 -6.93382441e-02\n",
      "   7.74001086e-03  1.33365198e-02  1.14591344e-02  4.03996422e-02\n",
      "   4.23669481e-02 -1.32130865e-01 -5.99340819e-02 -4.56391793e-02\n",
      "  -3.93350749e-02  6.53658857e-02 -7.55354885e-02 -1.99433375e-02\n",
      "  -6.83859049e-03 -8.33931460e-02  1.12241559e-01  2.72368347e-02\n",
      "  -3.58071864e-02  2.34960826e-02 -7.40481635e-02  5.86602019e-02\n",
      "  -1.41642799e-03 -3.13078028e-02  3.78648140e-02 -6.74038689e-02\n",
      "   4.14403333e-02 -2.66362403e-02  7.04185125e-02  8.21224444e-03\n",
      "  -1.32090870e-02 -2.03773778e-02 -7.01964747e-02  2.25760076e-02\n",
      "  -2.26014764e-02  8.22597884e-02  2.63435865e-02 -1.17112856e-02\n",
      "  -2.97155939e-03  4.00205253e-02  5.36059392e-02  6.49640055e-03\n",
      "  -4.30575551e-03 -6.96449529e-02  5.45213938e-02  8.27579206e-03\n",
      "  -3.44290284e-02  3.42119899e-02 -2.04225168e-02 -1.88566677e-02\n",
      "  -7.81889154e-03 -3.33390111e-05 -4.37388872e-02 -1.31488667e-02\n",
      "  -5.92958403e-02  3.85132876e-02  1.89854360e-03  2.77359871e-02\n",
      "   7.75229835e-02  2.12145669e-02 -3.20494157e-02  7.61931671e-03]\n",
      " [-8.95145912e-02 -1.11382925e-02  1.00972735e-02  4.30325634e-02\n",
      "   1.12148495e-01  3.03414936e-02  1.77707791e-02 -1.88744454e-02\n",
      "   5.13764364e-02 -6.42479231e-02 -4.22889507e-02  1.41368887e-02\n",
      "   1.29721400e-02  1.47984042e-02  4.38226707e-02  7.55842330e-03\n",
      "   1.27239301e-01 -6.58614415e-02  2.31566110e-02 -2.84764175e-02\n",
      "   7.66872170e-02 -6.55974863e-02  5.06830852e-02 -9.63142766e-02\n",
      "  -1.03889591e-01 -6.58818818e-02 -4.33374715e-02  1.31790724e-02\n",
      "   3.46740025e-02  1.32773155e-02  5.57126276e-02 -2.81656051e-02\n",
      "  -1.81087614e-02 -2.42716297e-03  9.07215936e-04  2.29650526e-02\n",
      "   6.06987765e-02  2.77928063e-02  2.18193645e-02  6.04792110e-03\n",
      "  -4.22966546e-02  4.25926829e-02  3.49617964e-02  4.66088257e-02\n",
      "  -2.25042205e-02  1.15384496e-02  6.59260770e-02  9.33861717e-03\n",
      "   3.02140383e-02 -3.08556095e-02 -6.25082975e-02  1.00245951e-02\n",
      "  -4.89045659e-02 -7.99923078e-02 -1.08412603e-02 -1.37632084e-02\n",
      "  -2.71181007e-02 -5.90239375e-04 -4.95169190e-02  1.90654323e-02\n",
      "  -3.32144508e-02  7.75120921e-02 -8.65254839e-02 -3.03744651e-02\n",
      "   7.78159797e-03 -2.42486576e-03  6.97907395e-02 -2.78574314e-03\n",
      "  -3.49490668e-02  7.34117891e-03 -2.63918133e-02  1.01825789e-02\n",
      "  -2.69687802e-03 -1.51145071e-02  5.68791406e-02  5.51120362e-02\n",
      "   8.43629719e-02 -6.28331346e-02 -1.59902076e-03  7.02101943e-02\n",
      "  -9.39232757e-03 -1.11824244e-02 -3.92851315e-02  5.28702576e-03\n",
      "   8.68449082e-02  4.91890177e-02  4.22235470e-02  1.41787067e-02\n",
      "  -3.52903273e-02 -7.13947765e-02  3.45490230e-02 -4.72846287e-02\n",
      "  -2.61984913e-02 -3.69706049e-02  3.92954171e-03  1.90071139e-02\n",
      "  -5.65266126e-02 -3.65668868e-02 -3.15350379e-02  1.12293962e-02\n",
      "  -4.16128786e-02 -6.81478926e-02 -1.00097886e-02 -3.90706949e-02\n",
      "  -1.26538186e-01 -7.82671527e-03 -1.46013613e-02 -1.79719838e-02\n",
      "   4.67112347e-02  3.47462200e-02  1.42906262e-02  5.24009766e-02\n",
      "  -3.37050794e-02 -4.04654330e-02 -3.54269853e-02  1.15731572e-02\n",
      "  -3.66429696e-03 -1.94074780e-02  7.04889571e-02 -8.29759668e-02\n",
      "  -8.07437606e-02 -5.00486748e-02 -9.62240663e-03  4.06626170e-02\n",
      "   8.70033296e-02 -3.78559103e-02  1.02569818e-01 -7.72686368e-03\n",
      "   5.98425483e-02 -1.50132170e-02 -8.11373528e-03 -5.62298873e-03\n",
      "  -1.55855223e-02  3.71567672e-02 -1.14516378e-02  2.18826322e-02\n",
      "  -3.22660350e-02  4.86954550e-02  3.36313544e-02 -1.08560085e-02\n",
      "  -3.26074822e-02 -4.14333484e-03 -7.30270686e-02 -9.03531414e-02\n",
      "   4.06882125e-03  1.82012385e-03 -1.27859674e-01  6.72905969e-02\n",
      "   4.59862341e-02 -8.94642974e-02  9.19838836e-04  3.68788844e-03\n",
      "   1.33351713e-01 -1.85412784e-02  3.08350678e-04  5.57623701e-02\n",
      "   1.29213113e-01  1.77821127e-02  1.00005467e-01  3.54210646e-02\n",
      "   3.75642956e-02  7.75837123e-02  5.74307693e-02  5.66098398e-02\n",
      "  -1.12705964e-03  4.93355885e-02  3.77252430e-02  2.97383263e-02\n",
      "  -3.97400186e-02 -1.18107692e-01  2.24723681e-02  1.53535633e-03\n",
      "   2.83509684e-03 -5.97661468e-02 -1.68840706e-02 -3.07872948e-03\n",
      "  -3.09905825e-02  2.27523265e-02  3.90043105e-02 -4.89760609e-02\n",
      "   3.39239189e-02 -3.23247734e-02 -5.54360046e-02 -3.45679402e-02\n",
      "   4.92795516e-02 -1.05330841e-02 -9.85935131e-02  1.77444149e-02\n",
      "   9.72329877e-02 -5.82913713e-02  1.89169625e-03 -4.36868436e-02\n",
      "   4.13118051e-02 -1.00982877e-03  1.65636579e-02 -1.83205402e-02\n",
      "   6.90579602e-03 -7.47790278e-02  4.84399194e-02  5.06659752e-02]\n",
      " [-3.73374151e-02  4.52622496e-02  3.01901221e-03 -3.98607799e-02\n",
      "   1.72484584e-03  1.40186032e-01 -1.72230363e-02 -1.13195442e-01\n",
      "  -1.64924609e-02 -2.50504258e-02  5.49270636e-02  1.12119060e-02\n",
      "  -6.20461637e-03 -6.78507812e-02  2.22233790e-02  3.00134704e-02\n",
      "   3.28048406e-02 -2.16300923e-02  1.74988584e-02  9.88198879e-02\n",
      "  -2.19484033e-02 -1.57715915e-02 -5.05793704e-03 -8.96964521e-03\n",
      "   1.34438804e-03 -5.40228065e-02  6.98910665e-02 -1.58362780e-02\n",
      "  -5.96394533e-02 -4.35557271e-02 -2.28050223e-02  4.93098645e-03\n",
      "   8.92254797e-02 -7.23854068e-02 -6.85099556e-02  6.78975024e-03\n",
      "  -3.58559831e-03 -1.41847545e-02 -3.95882490e-02  6.85366543e-02\n",
      "   6.99705481e-02  5.62423879e-02 -1.37422179e-01 -1.32829792e-01\n",
      "  -3.18888032e-03 -9.00373227e-03 -1.07615830e-01  1.84489121e-02\n",
      "  -6.58856761e-02  3.08235054e-02  7.65719949e-02  5.25834417e-02\n",
      "  -7.14270284e-03 -1.17687952e-01 -4.57165047e-02 -3.01979628e-04\n",
      "  -1.05590594e-02  2.40538010e-03 -9.70314687e-02  2.05160871e-02\n",
      "  -7.25426743e-02  1.95461364e-02  2.23424696e-02 -1.26531142e-02\n",
      "  -8.63963773e-03 -1.58081707e-02 -2.64746544e-03  5.78349013e-02\n",
      "  -1.21494855e-02 -3.25616830e-02 -2.81971185e-02 -7.91832749e-02\n",
      "   7.10840052e-03  6.12160350e-03  4.53597946e-02  3.19617329e-02\n",
      "   6.49851809e-02  6.29619817e-02  1.02675416e-02 -1.41982350e-02\n",
      "  -3.49359758e-02  2.55639365e-02  4.44333086e-02  5.36587762e-02\n",
      "   1.92971579e-02 -8.06919185e-02  6.02008132e-02  6.05649932e-02\n",
      "  -4.41860237e-03  3.24339254e-02 -7.96448012e-02 -5.51775165e-02\n",
      "   4.19653707e-02  4.63109783e-03  2.47500770e-02 -2.68772458e-02\n",
      "   8.74206740e-02 -2.46748224e-04  6.73415791e-02 -2.59053066e-02\n",
      "  -6.97409374e-03  3.33608576e-02 -6.96268278e-02  4.36771636e-02\n",
      "   2.30109200e-03 -4.67380602e-02  7.41468912e-02  7.50073994e-02\n",
      "   4.10442748e-02 -2.22210460e-02 -4.98749844e-02  3.20850082e-02\n",
      "  -2.91032448e-02 -1.04332559e-02  8.38941168e-03 -1.29447937e-02\n",
      "   3.40433349e-02 -9.73017306e-03 -1.64742079e-02  1.14144541e-02\n",
      "   7.59230083e-02  1.27294831e-02  9.72255303e-04  3.84354412e-02\n",
      "  -5.84055271e-02  1.06601402e-01  2.10900876e-02  4.03809357e-03\n",
      "  -7.74055603e-02  1.13951417e-02 -9.63261075e-02  2.34582540e-02\n",
      "  -3.50050812e-02  1.02144566e-02 -6.20464861e-02  9.58340297e-03\n",
      "  -3.49642722e-02 -1.40148356e-02 -3.90376827e-02  5.44210957e-03\n",
      "  -1.32530804e-02  3.50136092e-02  7.22171762e-02 -4.15456207e-02\n",
      "  -2.65427586e-02  3.10889248e-03  5.09397152e-02 -7.72170466e-02\n",
      "  -7.66414456e-03 -2.45955133e-02  5.37125341e-02 -1.30075291e-01\n",
      "   4.75263289e-03 -8.22213191e-02 -8.68851702e-02  4.63603089e-02\n",
      "  -1.56229627e-01  5.31592307e-02 -1.00469534e-01  3.78023812e-02\n",
      "   3.16248102e-02 -6.06647656e-02  3.65622763e-02  1.61896346e-02\n",
      "   1.35655368e-02  7.66991647e-03 -3.74868357e-03  5.00896088e-02\n",
      "  -1.11392142e-02  9.99692094e-03  8.86128768e-03  1.00433986e-01\n",
      "  -3.50697969e-02 -2.49272373e-02 -3.64641332e-02  5.48925600e-02\n",
      "  -3.53609069e-02 -2.82061408e-02  5.15484717e-02  5.76827121e-02\n",
      "  -8.93058035e-03 -2.96589373e-02  3.57911230e-02 -1.74965927e-02\n",
      "  -7.83164459e-02  2.59471078e-02  9.31740927e-02  5.75395817e-02\n",
      "   7.15334802e-02 -6.98232247e-03 -2.22631978e-02 -6.67255472e-02\n",
      "  -6.88314034e-02  5.59865911e-02  5.99030412e-03 -2.00693104e-03\n",
      "   2.01375438e-02  6.24731657e-02  2.86141974e-02  1.32415242e-02]]\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# XavierInitializerテスト\n",
    "xavier = XavierInitializer()\n",
    "\n",
    "print(xavier.W(400, 200)[:5])\n",
    "print(xavier.B(200)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeInitializer:\n",
    "    \"\"\"\n",
    "    Heの初期値作成クラス\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        sigma = np.sqrt(2.0 / n_nodes1)\n",
    "        W = sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        \n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = np.random.randn(n_nodes2)\n",
    "        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.44407202e-02 -2.09987811e-01  2.53719886e-03  1.11705389e-01\n",
      "  -8.02657210e-02 -4.85724627e-02  1.00576777e-01 -9.94327980e-02\n",
      "  -7.78442289e-02 -1.46477426e-01  8.33067080e-02  1.21938376e-01\n",
      "   1.07690380e-01 -1.16511810e-02 -4.70955111e-02 -6.49023155e-02\n",
      "   5.43041647e-02  1.27066969e-01  3.47596505e-02 -1.31039239e-01\n",
      "   9.52227265e-03 -8.69881569e-02 -2.18215732e-02 -2.71616313e-02\n",
      "   5.56186873e-02 -1.45049294e-02  1.34027603e-02 -3.66905455e-02\n",
      "  -1.55387974e-02  9.04431789e-02 -7.94809334e-03  1.24354565e-01\n",
      "   1.05997102e-02  1.44329831e-01 -6.01265347e-02 -1.86129463e-02\n",
      "  -2.33782556e-02 -8.56290931e-02 -1.18839549e-01  1.82223813e-02\n",
      "  -4.76353210e-02 -5.54349232e-02  4.11777410e-02 -5.20871321e-02\n",
      "   9.32194637e-03  1.78532669e-01 -3.58325592e-02 -3.18926489e-02\n",
      "   3.00621575e-02  1.06845131e-01  8.51621363e-04 -7.09943178e-03\n",
      "   1.06530372e-01 -2.41360728e-02 -6.93668069e-02 -6.74591128e-03\n",
      "   3.56260554e-02 -5.92913119e-02  7.92721604e-02 -6.33676968e-02\n",
      "  -7.46849418e-02 -8.65110458e-02  6.45561611e-02 -2.03764801e-02\n",
      "   6.20336735e-03  7.49612970e-02  2.97387030e-02  6.95825058e-02\n",
      "  -2.56318472e-02 -2.37630171e-02 -9.35944659e-02 -1.17510694e-01\n",
      "   2.44144067e-02 -3.65613245e-02  4.86537883e-02 -9.89743019e-03\n",
      "   2.58081248e-02  6.53945671e-04 -9.23264567e-02  1.23007369e-01\n",
      "   3.40110390e-02  9.94921677e-02  1.72142527e-02  3.34609734e-02\n",
      "   1.29445016e-01  5.28428165e-02  7.59486004e-02 -6.01593388e-02\n",
      "   8.11346719e-02 -5.64818201e-02 -1.25109301e-01  2.24270330e-02\n",
      "   1.34718225e-02 -1.07377088e-01 -1.02282554e-01 -1.85416292e-01\n",
      "   4.69580257e-02 -2.75329594e-02 -2.94713110e-02 -5.78581255e-02\n",
      "  -3.54431194e-02  5.85492159e-02 -3.39005521e-02 -3.62216822e-03\n",
      "  -2.68078619e-02  9.93057753e-02 -1.14290054e-01 -5.42823131e-02\n",
      "  -1.32045421e-01  1.14514908e-03 -2.02120149e-01 -8.52765480e-02\n",
      "  -2.45363322e-02 -2.29076565e-02 -7.89394663e-03 -5.64457954e-02\n",
      "   6.41065325e-02  3.73608021e-02 -2.78884049e-02  7.62266832e-02\n",
      "   1.13368988e-01 -1.52065518e-01  6.94454843e-03 -6.83077163e-04\n",
      "  -4.71080950e-02  6.03055025e-02 -4.61090865e-02 -6.31337048e-02\n",
      "  -4.53845535e-03 -4.96133009e-02  2.02274991e-02 -9.61770514e-02\n",
      "   6.73160771e-02 -7.22454478e-02 -4.45536487e-02 -8.74865178e-02\n",
      "   6.41479461e-02  6.27507767e-02 -1.79954565e-02  9.58184333e-02\n",
      "  -5.74266895e-02  1.79031349e-02  5.83212230e-02 -1.38698418e-02\n",
      "   9.62627091e-03  1.17476187e-01  5.13457951e-02  3.51144220e-02\n",
      "   3.97894783e-03 -3.86331908e-02  2.90131308e-02  2.03136426e-01\n",
      "  -1.85603324e-02  1.35659937e-01  7.89194989e-02 -4.01482181e-02\n",
      "   3.10555682e-02  1.78955261e-02 -6.00729622e-03  8.30800633e-02\n",
      "   2.62977565e-02 -7.48352037e-02 -6.57279270e-02  1.13627815e-01\n",
      "   5.11695263e-02  4.19407635e-02 -8.30987528e-03  5.86836591e-02\n",
      "  -9.83926605e-03 -6.07620990e-02 -2.46029391e-02 -1.64614882e-03\n",
      "  -1.87273350e-01  5.02673135e-02 -1.07158771e-01 -1.45752367e-01\n",
      "  -5.04461966e-02 -1.14812084e-01  6.71129063e-02  1.04543515e-01\n",
      "  -7.94507920e-03  7.28111742e-02  1.77132431e-01  1.71441022e-02\n",
      "   3.18028704e-03  8.54704441e-02  7.55211038e-02  1.52371804e-01\n",
      "   4.45033484e-02 -5.01039786e-02  2.51386275e-02 -5.73059247e-02\n",
      "   3.47861603e-02 -4.56201888e-02 -2.82754795e-02  6.08242612e-03\n",
      "   8.10088923e-02 -2.01870478e-02 -9.63166591e-02 -7.70148335e-02]\n",
      " [ 1.70859792e-02  6.70499324e-02 -3.31544574e-02 -2.36555477e-02\n",
      "   1.26977435e-01  9.13611597e-02  7.42743472e-02  1.44179004e-01\n",
      "  -7.27898453e-02  1.75429862e-02 -6.95830438e-02 -2.97079987e-02\n",
      "   1.05645762e-01 -8.18768088e-02  4.03739798e-02 -1.23821909e-02\n",
      "   9.57588407e-02 -5.26336489e-03 -1.05755656e-02  3.22209660e-02\n",
      "  -2.75917389e-02  6.33989064e-02  1.08616377e-01  4.58986470e-02\n",
      "  -1.12703968e-02  2.43907836e-02 -1.20351513e-02 -6.70541508e-02\n",
      "  -2.42414937e-02 -9.11799166e-04 -6.56539351e-03  9.60352638e-02\n",
      "  -5.64230154e-02 -2.57091198e-02 -7.17529014e-02 -2.71746728e-02\n",
      "   2.58808443e-02  3.88546713e-02  1.09285743e-01  2.55326717e-02\n",
      "  -6.81854183e-03  2.65448778e-02 -1.17873697e-04 -3.39625742e-02\n",
      "   2.74839021e-02  3.87519655e-02 -4.41718503e-02 -7.79376379e-03\n",
      "  -3.84323029e-02 -7.06175323e-02  9.56073918e-02 -6.93639032e-02\n",
      "   1.04159793e-01 -4.61826379e-03  7.43096468e-02  9.66327024e-02\n",
      "  -8.75549583e-02  1.12458233e-01 -1.50110557e-02  7.39436843e-02\n",
      "  -6.79356704e-02  1.45945928e-01  5.00055985e-02 -5.95693401e-02\n",
      "   6.39779776e-02  2.46549944e-02  1.35167721e-02  3.03672653e-02\n",
      "   1.00545692e-01 -8.68016214e-02 -3.42944124e-02  5.52672071e-02\n",
      "  -3.06199092e-02  1.47383108e-02  8.25737891e-02  4.15900401e-03\n",
      "   1.52538808e-04  2.15406211e-02  1.85648773e-01 -5.37136461e-02\n",
      "   4.52484216e-02  6.62549187e-02 -1.14239799e-01 -1.54429079e-02\n",
      "   4.63404102e-02 -5.03312155e-02 -7.55400571e-02  3.10048268e-02\n",
      "  -1.23451430e-01 -1.54996053e-02 -7.31603452e-02  8.76046078e-02\n",
      "  -1.19090472e-02  4.39425668e-02 -2.80427219e-02  9.84747967e-02\n",
      "   3.73018946e-02 -1.43612798e-01  4.98629468e-02  9.67502941e-03\n",
      "   4.90071076e-02 -3.45125421e-02 -4.59876960e-02 -4.72539593e-03\n",
      "  -6.11629414e-02  3.92464828e-02 -2.53462408e-02 -2.71063827e-02\n",
      "  -1.09478794e-02 -4.06097027e-02  1.14961236e-01 -9.95609645e-02\n",
      "  -7.86764124e-02 -7.80747232e-02 -1.58750652e-02 -1.36958930e-01\n",
      "   1.43143246e-01  6.78856210e-02 -8.53431181e-04  4.39790673e-02\n",
      "  -3.58243516e-02 -1.38969964e-01 -1.39341282e-01  8.52474317e-02\n",
      "  -4.71140643e-02  7.70590963e-02  4.54116236e-03 -9.83756631e-02\n",
      "   4.96973486e-02 -2.03018260e-02 -1.43927956e-01  3.28763109e-02\n",
      "  -8.04580819e-02 -1.69593603e-02  9.57067249e-02  1.65115439e-01\n",
      "   9.76121599e-03  9.60443649e-02  1.20363309e-01 -8.13356652e-02\n",
      "  -2.79198997e-02  3.00677646e-02 -1.32303938e-01  1.03560768e-02\n",
      "  -1.14173955e-02  1.18968489e-01  1.82187474e-02  4.62183597e-02\n",
      "  -3.42806276e-03  5.82340248e-03 -1.37602208e-01 -5.63690650e-03\n",
      "   4.95319024e-02  4.42636364e-02 -3.17624299e-02  1.08791899e-02\n",
      "   4.98500581e-02 -9.84518080e-02 -1.04215634e-01  5.84558060e-02\n",
      "  -4.14459257e-02  6.89721693e-02  4.69971113e-02 -4.04892964e-02\n",
      "   4.41726144e-02  1.27316604e-01  1.28122070e-02  4.55551546e-02\n",
      "  -1.45023731e-01  4.60030777e-02 -4.40692471e-02 -1.31830936e-02\n",
      "  -2.11683392e-02 -8.15268076e-02  2.20778055e-02  5.40757833e-02\n",
      "  -5.30881454e-02  1.00791497e-01  1.00550492e-01 -1.30636860e-02\n",
      "   4.65620128e-02  2.46781150e-02  5.34985543e-02 -1.78940612e-02\n",
      "   8.48295184e-02  8.72364749e-02 -5.99246915e-02  1.20218614e-02\n",
      "  -3.73300461e-02 -4.58231954e-02  4.74152258e-02 -1.08064986e-01\n",
      "   1.68169404e-02 -2.37792910e-02 -1.10903333e-01 -4.57201862e-02\n",
      "   9.57274973e-02 -5.25975950e-02 -3.80050531e-03 -5.17054431e-02]\n",
      " [ 6.12195429e-02  1.02306018e-01  8.24022709e-02  1.05613775e-01\n",
      "   6.83052142e-02  7.06597425e-02  8.11673148e-03  4.90576122e-02\n",
      "   1.07424330e-01  2.87430925e-02  4.73313487e-02  1.27691656e-01\n",
      "   4.13135796e-02 -9.46565169e-02 -2.78736453e-03  1.68861504e-02\n",
      "   1.22330563e-02  1.08241447e-01 -5.93554219e-02 -6.75992473e-03\n",
      "   1.47032570e-01  3.54179730e-02  4.42441269e-02  8.77593633e-02\n",
      "   1.73953269e-01  5.98226149e-02 -3.81575127e-02 -1.26887170e-02\n",
      "   3.68151495e-02  4.69784352e-02 -4.60042672e-02 -3.23332219e-02\n",
      "   2.94739527e-02 -5.74260817e-02 -1.92222409e-03 -1.36660216e-01\n",
      "  -1.35333363e-02  4.34517998e-02  6.60917949e-02  9.84907730e-02\n",
      "  -1.53583516e-02  7.56023337e-02 -9.23875118e-02 -3.66307152e-02\n",
      "  -1.09901774e-01 -7.92475210e-02 -1.84045729e-03 -1.07653680e-01\n",
      "  -1.67820331e-01 -9.43952178e-02  9.67454823e-02  1.71525811e-03\n",
      "  -7.15107759e-02  1.81011197e-02  1.06787349e-01 -5.67215151e-04\n",
      "  -7.39858218e-03 -7.70438652e-02 -6.00443714e-02  2.37464452e-02\n",
      "  -3.16275057e-02 -1.03168836e-01 -2.59791143e-02  1.17619453e-01\n",
      "  -3.53419466e-03  7.25515504e-02  2.66667229e-02 -7.12521680e-04\n",
      "  -7.98802636e-02  5.22601695e-04  5.59883155e-02 -8.59082748e-03\n",
      "  -8.03781631e-02  1.32828334e-01 -8.21009304e-02 -2.17947103e-02\n",
      "   5.32754452e-02  4.81530696e-02 -1.67283416e-01 -8.37858496e-02\n",
      "   6.73162151e-02  1.28504558e-01 -7.47725666e-02 -3.44236887e-02\n",
      "   5.94613414e-02 -1.33529993e-02 -1.42103069e-01 -3.02674774e-02\n",
      "   8.18348020e-02 -3.51425494e-02  1.25632109e-01  1.48259132e-02\n",
      "  -2.02075733e-02  4.73747736e-02 -9.40573319e-02 -1.24988698e-01\n",
      "   2.89163199e-02 -8.78322609e-02 -1.60793873e-02  4.33158691e-03\n",
      "   5.31495098e-02  6.66181021e-02 -7.05466905e-02  5.75894820e-02\n",
      "  -7.90085769e-03  8.98260411e-02  7.66270878e-03  1.03581672e-01\n",
      "  -1.55756718e-01  6.31979287e-02 -2.83600836e-02 -1.00901084e-01\n",
      "  -6.83485241e-02 -8.46434007e-02  4.23948374e-02  9.56823129e-04\n",
      "  -1.10569931e-01 -2.07283522e-02  5.81781319e-02 -3.33160505e-02\n",
      "   9.54963213e-02 -7.40212060e-02  1.47651146e-01  9.22112302e-02\n",
      "   1.21255992e-01  1.42711187e-02 -7.20695567e-02  1.11061864e-01\n",
      "  -3.02812454e-02  7.48125458e-02  7.70578050e-02 -6.14348706e-02\n",
      "  -5.31078568e-02 -3.15214157e-02  3.61424488e-02 -4.03006969e-02\n",
      "   1.73741680e-01 -5.41751821e-02  1.47777770e-02  1.40074595e-01\n",
      "  -8.18196084e-02  1.15331991e-01 -7.14786885e-02 -1.54838244e-03\n",
      "   1.51360360e-02  3.96682089e-02 -1.60463656e-02  6.43335090e-02\n",
      "   1.06422797e-01  1.18650442e-01 -1.00143826e-01 -1.75756585e-02\n",
      "  -1.91174182e-02  1.73768098e-02  1.18635296e-01  3.70830192e-03\n",
      "   4.35983583e-02 -6.66211256e-02  1.72574304e-02 -1.01976771e-02\n",
      "  -7.59067169e-02 -3.38316149e-02  1.24757171e-01 -5.64092222e-02\n",
      "   5.98744438e-02  3.05756056e-02  7.45859687e-02  3.68984319e-02\n",
      "  -3.11808869e-02 -5.25875732e-02  1.05784147e-01  1.55468282e-02\n",
      "  -5.22698378e-02 -4.33788090e-02 -7.32451188e-02 -7.34340122e-02\n",
      "  -1.85835635e-01  6.59627075e-03 -4.44377596e-02  5.37247068e-02\n",
      "   6.00052933e-02  9.91874692e-03  3.19104147e-02 -1.16852195e-01\n",
      "   1.23014242e-01  2.39476973e-02 -4.16149713e-02  5.69545430e-02\n",
      "  -1.86150666e-03  7.02289598e-02 -7.07768769e-02  1.49222078e-01\n",
      "   8.25659146e-02  7.62681615e-02  3.60923744e-02 -5.71332121e-02\n",
      "  -2.24257989e-03  8.55195962e-04  3.57482848e-02 -2.17612702e-02]\n",
      " [ 5.61415623e-02  1.58999208e-01 -3.61902423e-02  1.91266067e-02\n",
      "   2.19660999e-02 -1.08500418e-01 -9.22833237e-02  5.38126176e-02\n",
      "  -4.68801487e-04 -5.41531928e-03 -3.11946729e-02 -2.32048771e-02\n",
      "   1.07023229e-01  1.59295871e-02  5.53472919e-02  4.87259362e-02\n",
      "  -5.90212634e-05  3.63121623e-02 -9.20288971e-02 -6.01855750e-02\n",
      "   4.49544780e-02 -1.31108991e-02  1.12699769e-02  6.27927576e-03\n",
      "   9.63295568e-02  1.88011144e-02 -7.95632898e-02  9.81964776e-02\n",
      "   5.00664301e-02  1.14195123e-02 -3.27284525e-03  2.96183873e-02\n",
      "  -5.89489336e-02 -1.13240983e-01 -4.36233515e-02 -6.81282863e-02\n",
      "  -6.94386022e-02 -5.03743857e-02  3.55227657e-02  1.59053564e-01\n",
      "  -2.51217131e-03  2.24021712e-02  3.40085914e-03  4.38243097e-04\n",
      "  -3.09373966e-02 -1.12763235e-01 -3.57907058e-02  1.15495473e-02\n",
      "  -1.13140134e-01 -6.96497741e-02  5.96192927e-02 -3.22259023e-03\n",
      "  -1.27026583e-01 -2.67191393e-02 -3.62119034e-02 -1.53998014e-01\n",
      "  -6.33120512e-02 -1.21861714e-01 -2.82968553e-02 -1.59608406e-01\n",
      "   2.97343719e-02  7.92826562e-02 -1.80831509e-02  2.10052259e-02\n",
      "  -4.11345561e-03  1.07033775e-01 -6.54342344e-02  9.40189598e-02\n",
      "   8.89342091e-02 -7.25753753e-02  1.20471780e-02 -5.48608508e-02\n",
      "   5.52164758e-02  4.35814419e-02  7.42593546e-03 -6.01938248e-02\n",
      "   8.96014406e-02 -2.69909113e-02  2.99006627e-02  5.88705006e-03\n",
      "   1.11337861e-01  7.55816480e-02 -5.61054208e-02 -4.51771017e-02\n",
      "   2.40836663e-02  1.10660179e-01 -1.00908151e-02 -1.03546947e-01\n",
      "  -4.30920988e-02  1.00322766e-02  1.00570113e-02 -6.22649241e-03\n",
      "   6.63597173e-02 -2.81164689e-02 -2.00300899e-02  1.04373513e-01\n",
      "  -1.77355482e-02  6.90585900e-02  4.95139382e-02 -1.15848076e-02\n",
      "   1.01730916e-01 -3.36521363e-02 -1.33209838e-01  3.95235115e-02\n",
      "  -5.10666512e-02  3.85282664e-02  1.29061955e-01 -9.42213336e-02\n",
      "  -2.68137895e-02 -1.54964899e-01  1.14718391e-01 -1.57694834e-03\n",
      "  -1.72451050e-02  5.55187691e-02 -5.68899825e-02 -6.65254063e-03\n",
      "   1.40906177e-01 -2.44476541e-03  9.86392107e-02 -1.45475122e-01\n",
      "   3.04016923e-02  4.05498451e-02  5.24375569e-02  7.37819293e-03\n",
      "  -4.53749519e-03 -1.36921985e-01  6.39975544e-02 -1.34638944e-02\n",
      "  -9.71737827e-02  4.24877428e-02 -7.69223359e-02 -1.64246327e-02\n",
      "  -1.34643347e-01 -6.10393562e-02 -1.16068801e-01  3.76489821e-02\n",
      "   1.35400491e-02 -5.87675553e-02 -1.55236644e-01  8.21894260e-02\n",
      "  -3.13322941e-02 -7.63301854e-02 -1.26768112e-01 -9.41799759e-03\n",
      "  -1.48692040e-02  7.32538263e-02 -4.30688797e-02  1.26565012e-01\n",
      "   1.02130979e-01  5.68329656e-02  2.60837338e-02  2.48958099e-02\n",
      "  -1.68954338e-01  1.05162018e-01  2.09448988e-02 -8.45767898e-03\n",
      "  -2.77981228e-03 -9.91463377e-02 -9.00892725e-02  6.85017123e-02\n",
      "  -5.45505844e-02  3.31446792e-02  1.65092975e-01  5.26987034e-02\n",
      "   2.46670588e-02  1.13145635e-02  3.97829929e-02 -1.46173769e-01\n",
      "  -4.66151924e-02 -1.04447130e-03 -2.27167931e-02  9.93161908e-02\n",
      "   1.26212639e-02 -2.34853263e-02 -4.25368332e-02  1.62349405e-02\n",
      "  -8.01537441e-02 -5.88734680e-02  2.90860580e-02 -2.83851146e-03\n",
      "  -1.67278126e-02  4.83212259e-02  1.40457954e-02 -1.09154285e-01\n",
      "  -9.60802331e-02  3.43461224e-03 -4.10640643e-02 -3.93545246e-02\n",
      "   2.29299662e-02  1.37859610e-01 -7.74070191e-02 -9.73026564e-02\n",
      "  -1.83341247e-01 -8.96165203e-02 -6.87302632e-02 -2.96730500e-02\n",
      "  -1.65373294e-02  1.08431162e-01  9.95584785e-03  1.30731314e-02]\n",
      " [-4.65701575e-02  7.57484864e-02 -9.42740057e-02  1.79400000e-02\n",
      "  -6.22602832e-02  5.65180394e-02 -1.60183786e-02 -8.02119571e-02\n",
      "   1.15098756e-01  3.85506754e-02  3.77186378e-02  4.98871971e-02\n",
      "   1.01912828e-01 -1.10849216e-01 -9.99773597e-02 -1.16059227e-01\n",
      "  -4.46351171e-02  1.95063387e-02  7.54928935e-02 -6.51784438e-03\n",
      "   6.71731652e-02 -1.16105023e-01 -2.02182075e-03 -7.77500041e-03\n",
      "  -2.03049845e-03 -9.14564940e-03  3.65550183e-02  9.48683289e-03\n",
      "  -2.53847406e-02 -1.88189034e-02 -3.35023598e-03 -3.11524110e-02\n",
      "  -2.08399809e-02 -2.21877850e-02  2.25718008e-02  7.36221608e-03\n",
      "  -2.15216206e-02 -5.29434749e-02  6.44807275e-02 -8.92762556e-03\n",
      "  -1.27491008e-01  2.84758728e-03  1.43454431e-02  6.92039804e-02\n",
      "  -2.53625261e-02 -1.24541151e-01  1.10182958e-01 -6.89343023e-02\n",
      "  -3.04612210e-03 -7.61298918e-02 -1.83626873e-02 -1.03201359e-01\n",
      "   1.84242468e-01  1.62095857e-01  1.57569254e-02  3.60957905e-02\n",
      "  -1.37732228e-02 -2.07118947e-02 -1.02007518e-01 -4.67293872e-02\n",
      "  -8.01415580e-02 -1.21489897e-01 -3.91440615e-02  7.31626308e-02\n",
      "   5.50311256e-02 -2.85376989e-02  4.87693508e-02  3.56159196e-02\n",
      "  -5.36478588e-02 -2.57133065e-02  6.72392895e-02  6.82647507e-02\n",
      "  -1.42146854e-02  1.69849689e-02  9.25191890e-02  1.15515504e-01\n",
      "   7.33468689e-02 -3.95188928e-02 -1.96738973e-02  3.38783728e-02\n",
      "   6.54962942e-02 -6.29286749e-03 -1.11588121e-01  8.19930014e-04\n",
      "  -1.51585526e-01 -5.09841809e-02 -1.03731212e-02 -1.50276247e-01\n",
      "  -2.25310701e-02  2.73175545e-02 -6.51690161e-02 -8.50293685e-02\n",
      "  -7.93362968e-02 -7.20577998e-02 -1.38211478e-01  9.86820188e-02\n",
      "  -3.28863271e-02  1.03378208e-02  2.84360907e-02 -1.28151286e-01\n",
      "  -4.50486864e-02 -6.44570078e-02  5.12350877e-02  1.26724139e-01\n",
      "  -1.95875490e-02 -9.03390511e-02 -8.25803857e-03 -7.90762806e-02\n",
      "  -1.00493454e-01 -3.82920099e-02  7.60797113e-02  1.80550029e-01\n",
      "   8.14282890e-02  2.94672932e-02 -1.19833704e-02 -1.82594402e-01\n",
      "   5.50161714e-02 -9.42147983e-02  6.50469671e-02 -2.72308961e-02\n",
      "   9.80427989e-02 -3.86736104e-02 -4.37290350e-02  7.88546244e-02\n",
      "  -3.04573778e-02  6.90251365e-02 -5.95136966e-03 -5.05560948e-02\n",
      "  -9.61193904e-03  6.73905698e-02 -1.13415370e-04  5.24980628e-02\n",
      "   5.36185821e-02  1.51983893e-02  7.40969046e-02  4.62764743e-02\n",
      "   1.18385847e-02  8.45417846e-03 -3.60497248e-02  5.15528971e-02\n",
      "   9.37906893e-02  2.27313398e-02  8.01663772e-02 -8.78952970e-02\n",
      "  -8.15598582e-02  9.59657532e-02  3.01378392e-02  9.85090125e-02\n",
      "  -5.09956156e-02  8.37443499e-02  5.87360468e-02 -1.32795833e-02\n",
      "   4.92679750e-02 -1.30748668e-01 -5.54185850e-02  1.77625798e-02\n",
      "  -3.56687870e-02  7.38828149e-02  8.14013451e-02 -3.15081772e-02\n",
      "  -8.20908044e-02 -7.53673420e-02  2.25136269e-02 -5.89207907e-03\n",
      "  -2.17681427e-02  2.68447147e-02  6.86883679e-02 -5.06882294e-02\n",
      "   2.69132056e-02 -9.64894217e-02  2.23577944e-02 -1.54255978e-02\n",
      "   8.60204678e-02 -3.70770821e-02  1.53893255e-02  3.69880468e-02\n",
      "  -1.88180669e-01  2.37635097e-02  8.50926706e-02  6.69151936e-02\n",
      "   1.17604994e-01  5.77410868e-02  8.00081614e-02 -1.56435086e-02\n",
      "  -3.92057535e-02 -3.13999387e-02 -3.29991561e-02 -5.67524613e-02\n",
      "  -8.13516186e-02  1.23646503e-02 -2.99693621e-02  2.43629013e-02\n",
      "  -4.23888899e-02  1.44246901e-01 -9.60155796e-03  7.80773558e-02\n",
      "   2.85273035e-02 -2.42249747e-02 -3.35829856e-03  7.57446505e-02]]\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# HeInitializerテスト\n",
    "he = HeInitializer()\n",
    "\n",
    "print(he.W(400, 200)[:5])\n",
    "print(he.B(200)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題7】最適化手法\n",
    "学習率は学習過程で変化させていく方法が一般的です。基本的な手法である AdaGrad のクラスを作成してください。\n",
    "\n",
    "\n",
    "まず、これまで使ってきたSGDを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adagrad:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        self.HW = 0\n",
    "        self.HB = 0\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        self.HW += np.square(layer.dW), axis=0\n",
    "        layer.W -= self.lr * layer.dW / (np.sqrt(self.HW) + 1e-7)\n",
    "        \n",
    "        self.HB += np.square(layer.dB)\n",
    "        layer.B -= self.lr * layer.dB / (np.sqrt(self.HB) + 1e-7)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題8】クラスの完成\n",
    "任意の構成で学習と推定が行えるScratchDeepNeuralNetrowkClassifierクラスを完成させてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# データセットの読み込みから前処理まで\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(X_train[0].dtype) # uint8\n",
    "print(X_train[0])\n",
    "\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD, SimpleInitializer, Tanh \n",
    "class ScratchDeepNeuralNetrowkClassifier:\n",
    "    def __init__(self, lr, n_nodes1, n_nodes2, n_output, sigma=0.01):\n",
    "        self.lr = lr\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.n_output = n_output\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None, epoch=20):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, self.n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, self.n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        self.n_features = X.shape[1]\n",
    "        self.loss = np.zeros(epoch)\n",
    "        \n",
    "        # 各インスタンス初期化\n",
    "        optimizer = SGD(self.lr)\n",
    "        self.FC1 = FC(self.n_features, self.n_nodes1, SimpleInitializer(self.sigma), optimizer)\n",
    "        self.activation1 = Tanh()\n",
    "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, SimpleInitializer(self.sigma), optimizer)\n",
    "        self.activation2 = Tanh()\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, SimpleInitializer(self.sigma), optimizer)\n",
    "        self.activation3 = Softmax()\n",
    "              \n",
    "        # ラベル化\n",
    "        enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        y_train_one_hot = enc.fit_transform(y[:, np.newaxis])\n",
    "        \n",
    "        for i in range(epoch):\n",
    "            get_mini_batch = GetMiniBatch(X, y_train_one_hot, batch_size=20)\n",
    "            \n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                # フォワードプロバゲーション\n",
    "                A1 = self.FC1.forward(mini_X_train)     #shape(n_batch, n_nodes1)\n",
    "                Z1 = self.activation1.forward(A1)     #shape(n_batch, n_nodes1)\n",
    "                A2 = self.FC2.forward(Z1)        #shape(n_batch, n_nodes2\n",
    "                Z2 = self.activation2.forward(A2)       #shape(n_batch, n_nodes2)\n",
    "                A3 = self.FC3.forward(Z2)       #shape(n_batch, n_output)\n",
    "                Z3 = self.activation3.forward(A3)     #shape(n_batch , n_output)\n",
    "                \n",
    "                # バックプロバゲーション\n",
    "                dA3, self.loss[i] = self.activation3.backward(Z3, mini_y_train) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "                dZ2 = self.FC3.backward(dA3)     \n",
    "                dA2 = self.activation2.backward(dZ2)\n",
    "                dZ1 = self.FC2.backward(dA2)\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "                dZ0 = self.FC1.backward(dA1) # dZ0は使用しない        \n",
    "        \n",
    "        \n",
    "    def predict(self,X):\n",
    "        A1 = self.FC1.forward(X)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "        y = self.activation3.forward(A3)\n",
    "        \n",
    "        pred = np.argmax(y, axis=1)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD、Tanhで実行\n",
    "scr_DNN = ScratchDeepNeuralNetrowkClassifier(lr=0.01, n_nodes1=400, n_nodes2=200, n_output=10)\n",
    "\n",
    "scr_DNN.fit(X_train, y_train, epoch=20)\n",
    "pred = scr_DNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9732"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adagrad、SimpleInitializer, Tanhで実行\n",
    "\n",
    "class ScratchDeepNeuralNetrowkClassifier2:\n",
    "    def __init__(self, lr, n_nodes1, n_nodes2, n_output, sigma=0.01):\n",
    "        self.lr = lr\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.n_output = n_output\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None, epoch=20):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, self.n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, self.n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        self.n_features = X.shape[1]\n",
    "        self.loss = np.zeros(epoch)\n",
    "        \n",
    "        # 各インスタンス初期化\n",
    "        optimizer = Adagrad(self.lr)\n",
    "        self.FC1 = FC(self.n_features, self.n_nodes1, SimpleInitializer(sigma=0.01), copy.deepcopy(optimizer))\n",
    "        self.activation1 = Tanh()\n",
    "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, SimpleInitializer(sigma=0.01), copy.deepcopy(optimizer))\n",
    "        self.activation2 = Tanh()\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, SimpleInitializer(sigma=0.01), copy.deepcopy(optimizer))\n",
    "        self.activation3 = Softmax()\n",
    "              \n",
    "        # ラベル化\n",
    "        enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        y_train_one_hot = enc.fit_transform(y[:, np.newaxis])\n",
    "        \n",
    "        for i in range(epoch):\n",
    "            get_mini_batch = GetMiniBatch(X, y_train_one_hot, batch_size=20)\n",
    "            \n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                # フォワードプロバゲーション\n",
    "                A1 = self.FC1.forward(mini_X_train)     #shape(n_batch, n_nodes1)\n",
    "                Z1 = self.activation1.forward(A1)     #shape(n_batch, n_nodes1)\n",
    "                A2 = self.FC2.forward(Z1)        #shape(n_batch, n_nodes2\n",
    "                Z2 = self.activation2.forward(A2)       #shape(n_batch, n_nodes2)\n",
    "                A3 = self.FC3.forward(Z2)       #shape(n_batch, n_output)\n",
    "                Z3 = self.activation3.forward(A3)     #shape(n_batch , n_output)\n",
    "                \n",
    "                # バックプロバゲーション\n",
    "                dA3, self.loss[i] = self.activation3.backward(Z3, mini_y_train) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "                dZ2 = self.FC3.backward(dA3)     \n",
    "                dA2 = self.activation2.backward(dZ2)\n",
    "                dZ1 = self.FC2.backward(dA2)\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "                dZ0 = self.FC1.backward(dA1) # dZ0は使用しない        \n",
    "        \n",
    "        \n",
    "    def predict(self,X):\n",
    "        A1 = self.FC1.forward(X)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "        y = self.activation3.forward(A3)\n",
    "        \n",
    "        pred = np.argmax(y, axis=1)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9768\n"
     ]
    }
   ],
   "source": [
    "scr_DNN2 = ScratchDeepNeuralNetrowkClassifier2(lr=0.01, n_nodes1=400, n_nodes2=200, n_output=10)\n",
    "\n",
    "scr_DNN2.fit(X_train, y_train, epoch=20)\n",
    "\n",
    "pred2 = scr_DNN2.predict(X_test)\n",
    "print(\"Accuracy:{}\".format(accuracy_score(y_test, pred2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD、XavierInitializer, sigmoidで実行\n",
    "\n",
    "class ScratchDeepNeuralNetrowkClassifier3:\n",
    "    def __init__(self, lr, n_nodes1, n_nodes2, n_output, sigma=0.01):\n",
    "        self.lr = lr\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.n_output = n_output\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None, epoch=20):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, self.n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, self.n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        self.n_features = X.shape[1]\n",
    "        self.loss = np.zeros(epoch)\n",
    "        \n",
    "        # 各インスタンス初期化\n",
    "        optimizer = SGD(self.lr)\n",
    "        self.FC1 = FC(self.n_features, self.n_nodes1, XavierInitializer(), copy.deepcopy(optimizer))\n",
    "        self.activation1 = Sigmoid()\n",
    "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, XavierInitializer(), copy.deepcopy(optimizer))\n",
    "        self.activation2 = Sigmoid()\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, XavierInitializer(), copy.deepcopy(optimizer))\n",
    "        self.activation3 = Softmax()\n",
    "              \n",
    "        # ラベル化\n",
    "        enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        y_train_one_hot = enc.fit_transform(y[:, np.newaxis])\n",
    "        \n",
    "        for i in range(epoch):\n",
    "            get_mini_batch = GetMiniBatch(X, y_train_one_hot, batch_size=20)\n",
    "            \n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                # フォワードプロバゲーション\n",
    "                A1 = self.FC1.forward(mini_X_train)     #shape(n_batch, n_nodes1)\n",
    "                Z1 = self.activation1.forward(A1)     #shape(n_batch, n_nodes1)\n",
    "                A2 = self.FC2.forward(Z1)        #shape(n_batch, n_nodes2\n",
    "                Z2 = self.activation2.forward(A2)       #shape(n_batch, n_nodes2)\n",
    "                A3 = self.FC3.forward(Z2)       #shape(n_batch, n_output)\n",
    "                Z3 = self.activation3.forward(A3)     #shape(n_batch , n_output)\n",
    "                \n",
    "                # バックプロバゲーション\n",
    "                dA3, self.loss[i] = self.activation3.backward(Z3, mini_y_train) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "                dZ2 = self.FC3.backward(dA3)     \n",
    "                dA2 = self.activation2.backward(dZ2)\n",
    "                dZ1 = self.FC2.backward(dA2)\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "                dZ0 = self.FC1.backward(dA1) # dZ0は使用しない        \n",
    "        \n",
    "        \n",
    "    def predict(self,X):\n",
    "        A1 = self.FC1.forward(X)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "        y = self.activation3.forward(A3)\n",
    "        \n",
    "        pred = np.argmax(y, axis=1)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9774\n"
     ]
    }
   ],
   "source": [
    "scr_DNN3 = ScratchDeepNeuralNetrowkClassifier3(lr=0.01, n_nodes1=400, n_nodes2=200, n_output=10)\n",
    "\n",
    "scr_DNN3.fit(X_train, y_train, epoch=20)\n",
    "\n",
    "pred3 = scr_DNN3.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:{}\".format(accuracy_score(y_test, pred3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD、Heinitializer, Reluで実行\n",
    "\n",
    "class ScratchDeepNeuralNetrowkClassifier4:\n",
    "    def __init__(self, lr, n_nodes1, n_nodes2, n_output, sigma=0.01):\n",
    "        self.lr = lr\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.n_output = n_output\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None, epoch=20):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, self.n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, self.n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        self.n_features = X.shape[1]\n",
    "        self.loss = np.zeros(epoch)\n",
    "        \n",
    "        # 各インスタンス初期化\n",
    "        optimizer = SGD(self.lr)\n",
    "        self.FC1 = FC(self.n_features, self.n_nodes1, HeInitializer(), copy.deepcopy(optimizer))\n",
    "        self.activation1 = Relu()\n",
    "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, HeInitializer(), copy.deepcopy(optimizer))\n",
    "        self.activation2 = Relu()\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, HeInitializer(), copy.deepcopy(optimizer))\n",
    "        self.activation3 = Softmax()\n",
    "              \n",
    "        # ラベル化\n",
    "        enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        y_train_one_hot = enc.fit_transform(y[:, np.newaxis])\n",
    "        \n",
    "        for i in range(epoch):\n",
    "            get_mini_batch = GetMiniBatch(X, y_train_one_hot, batch_size=20)\n",
    "            \n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                # フォワードプロバゲーション\n",
    "                A1 = self.FC1.forward(mini_X_train)     #shape(n_batch, n_nodes1)\n",
    "                Z1 = self.activation1.forward(A1)     #shape(n_batch, n_nodes1)\n",
    "                A2 = self.FC2.forward(Z1)        #shape(n_batch, n_nodes2\n",
    "                Z2 = self.activation2.forward(A2)       #shape(n_batch, n_nodes2)\n",
    "                A3 = self.FC3.forward(Z2)       #shape(n_batch, n_output)\n",
    "                Z3 = self.activation3.forward(A3)     #shape(n_batch , n_output)\n",
    "                \n",
    "                # バックプロバゲーション\n",
    "                dA3, self.loss[i] = self.activation3.backward(Z3, mini_y_train) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "                dZ2 = self.FC3.backward(dA3)     \n",
    "                dA2 = self.activation2.backward(dZ2)\n",
    "                dZ1 = self.FC2.backward(dA2)\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "                dZ0 = self.FC1.backward(dA1) # dZ0は使用しない        \n",
    "        \n",
    "        \n",
    "    def predict(self,X):\n",
    "        A1 = self.FC1.forward(X)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "        y = self.activation3.forward(A3)\n",
    "        \n",
    "        pred = np.argmax(y, axis=1)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9807\n"
     ]
    }
   ],
   "source": [
    "scr_DNN4 = ScratchDeepNeuralNetrowkClassifier4(lr=0.01, n_nodes1=400, n_nodes2=200, n_output=10)\n",
    "\n",
    "scr_DNN4.fit(X_train, y_train, epoch=20)\n",
    "\n",
    "pred4 = scr_DNN4.predict(X_test)\n",
    "print(\"Accuracy:{}\".format(accuracy_score(y_test, pred4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Loss Comparison\")\n",
    "plt.plot(scr_DNN.loss, label=\"DNN[SGD, SimpleIni, Tanh]\", marker=\".\")\n",
    "plt.plot(scr_DNN2.loss, label=\"DNN[Adag, SimpleIni, Tanh]\", marker=\".\")\n",
    "plt.plot(scr_DNN3.loss, label=\"DNN[SGD, Xavier, Sigmoid]\", marker=\".\")\n",
    "plt.plot(scr_DNN4.loss, label=\"DNN[SGD, Heini, Relu]\", marker=\".\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比較・考察\n",
    "- Relu関数が面白い波形になった。バックプロバゲーションの際に、0or1にするという極端な変化を加えるためと考えられる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自習\n",
    "- sklearnモデル[sklearn.neural_network.MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)を利用してみる\n",
    "- パラメータが非常に多い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9737\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=1, max_iter=300, early_stopping=True)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred5 = clf.predict(X_test)\n",
    "print(\"Accuracy:{}\".format(accuracy_score(y_test, pred5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### スクラッチモデルをsklearnと同じようにインスタンス時のパラメータでinitilizerやoptimizerを選べるようにしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD、Heinitializer, Reluで実行\n",
    "\n",
    "class ScratchDeepNeuralNetrowkClassifier5:\n",
    "    def __init__(self, lr, n_nodes1, n_nodes2, n_output, sigma=0.01, Initializer=\"Simple\", optimizer=\"SGD\", activation=\"relu\"):\n",
    "        self.lr = lr\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.n_output = n_output\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        self.Initializer = {\"Simple\":SimpleInitializer(sigma=0.01), \"Xavier\": XavierInitializer(), \"He\": HeInitializer()}\n",
    "        self.optimizer = {\"SGD\": SGD, \"Adagrad\": Adagrad}\n",
    "        self.activation = {\"sigmoid\": Sigmoid, \"tanh\": Tanh, \"relu\": Relu}\n",
    "        \n",
    "    def fit(self, X, y, X_val=None, y_val=None, epoch=20):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, self.n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, self.n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        self.n_features = X.shape[1]\n",
    "        self.loss = np.zeros(epoch)\n",
    "        \n",
    "        # 各インスタンス初期化\n",
    "        optimizer = self.optimizer.values(self.lr)\n",
    "        self.FC1 = FC(self.n_features, self.n_nodes1, copy.deepcopy(self.Initializer), copy.deepcopy(optimizer))\n",
    "        self.activation1 = copy.deepcopy(self.activation())\n",
    "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, copy.deepcopy(self.Initializer), copy.deepcopy(optimizer))\n",
    "        self.activation2 = copy.deepcopy(self.activation())\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, copy.deepcopy(self.Initializer), copy.deepcopy(optimizer))\n",
    "        self.activation3 = Softmax()\n",
    "              \n",
    "        # ラベル化\n",
    "        enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        y_train_one_hot = enc.fit_transform(y[:, np.newaxis])\n",
    "        \n",
    "        for i in range(epoch):\n",
    "            get_mini_batch = GetMiniBatch(X, y_train_one_hot, batch_size=20)\n",
    "            \n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                # フォワードプロバゲーション\n",
    "                A1 = self.FC1.forward(mini_X_train)     #shape(n_batch, n_nodes1)\n",
    "                Z1 = self.activation1.forward(A1)     #shape(n_batch, n_nodes1)\n",
    "                A2 = self.FC2.forward(Z1)        #shape(n_batch, n_nodes2\n",
    "                Z2 = self.activation2.forward(A2)       #shape(n_batch, n_nodes2)\n",
    "                A3 = self.FC3.forward(Z2)       #shape(n_batch, n_output)\n",
    "                Z3 = self.activation3.forward(A3)     #shape(n_batch , n_output)\n",
    "                \n",
    "                # バックプロバゲーション\n",
    "                dA3, self.loss[i] = self.activation3.backward(Z3, mini_y_train) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "                dZ2 = self.FC3.backward(dA3)     \n",
    "                dA2 = self.activation2.backward(dZ2)\n",
    "                dZ1 = self.FC2.backward(dA2)\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "                dZ0 = self.FC1.backward(dA1) # dZ0は使用しない        \n",
    "        \n",
    "        \n",
    "    def predict(self,X):\n",
    "        A1 = self.FC1.forward(X)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "        y = self.activation3.forward(A3)\n",
    "        \n",
    "        pred = np.argmax(y, axis=1)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上記は個人的宿題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "426.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "747.205px",
    "left": "1763.33px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
