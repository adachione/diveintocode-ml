{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 機械学習スクラッチ 線形回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(0)\n",
    "\n",
    "X_array = np.array([[1, 1], [1, 2], [1, 3]])\n",
    "y_array = np.ones(3)\n",
    "X_val = np.array([[1, 2], [1, 4], [1, 6]])\n",
    "y_val = np.array([1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scr_lr = ScratchLinearRegression(num_iter=10, \n",
    "                                 lr=1, \n",
    "                                 no_bias=1, \n",
    "                                 verbose=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preX [[1 1]\n",
      " [1 2]\n",
      " [1 3]]\n",
      "self.X [[1. 1. 1.]\n",
      " [1. 1. 2.]\n",
      " [1. 1. 3.]]\n",
      "pred [2.13090181 2.64741308 3.16392436]\n",
      "loss [4.56875725 4.02050638 3.53804561 3.11348014 2.73986252 2.41107902\n",
      " 2.12174954 1.86713959 1.64308284 1.4459129 ]\n",
      "val_loss [3.40913573 5.38996394 2.53757868 4.33860279 1.87945162 3.50918695\n",
      " 1.38458795 2.85347458 1.01438064 2.33388769]\n"
     ]
    }
   ],
   "source": [
    "scr_lr.fit(X_array, y_array, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】仮定関数\n",
    "以下の数式で表される線形回帰の仮定関数を実装してください。メソッドの雛形を用意してあります。\n",
    "\n",
    "\n",
    "h\n",
    "θ\n",
    "(\n",
    "x\n",
    ")\n",
    "=\n",
    "θ\n",
    "0\n",
    "x\n",
    "0\n",
    "+\n",
    "θ\n",
    "1\n",
    "x\n",
    "1\n",
    "+\n",
    ".\n",
    ".\n",
    ".\n",
    "+\n",
    "θ\n",
    "j\n",
    "x\n",
    "j\n",
    "+\n",
    ".\n",
    ".\n",
    ".\n",
    "+\n",
    "θ\n",
    "n\n",
    "x\n",
    "n\n",
    ".\n",
    "(\n",
    "x\n",
    "0\n",
    "=\n",
    "1\n",
    ")\n",
    "\n",
    "$x$ : 特徴量ベクトル\n",
    "\n",
    "\n",
    "$\\theta$ : パラメータベクトル\n",
    "\n",
    "\n",
    "$n$ : 特徴量の数\n",
    "\n",
    "\n",
    "$x_j$ : j番目の特徴量\n",
    "\n",
    "\n",
    "$\\theta_j$ : j番目のパラメータ（重み）\n",
    "\n",
    "\n",
    "特徴量の数$n$は任意の値に対応できる実装にしてください。\n",
    "\n",
    "\n",
    "なお、ベクトル形式で表すと以下のようになります。\n",
    "\n",
    "\n",
    "h\n",
    "θ\n",
    "(\n",
    "x\n",
    ")\n",
    "=\n",
    "θ\n",
    "T\n",
    "⋅\n",
    "x\n",
    ".\n",
    "\n",
    "雛形\n",
    "\n",
    "\n",
    "クラスの外から呼び出すことがないメソッドのため、Pythonの慣例としてアンダースコアを先頭にひとつつけています。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題1  単独で作成した関数\n",
    "\n",
    "def _linear_hypothesis(X):\n",
    "    \"\"\"\n",
    "    線形の仮定関数を計算する\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "      次の形のndarray, shape (n_samples, 1)\n",
    "      線形の仮定関数による推定結果\n",
    "\n",
    "    \"\"\"\n",
    "    line_hypo = np.dot(X, theta.T)\n",
    "    \n",
    "    return line_hypo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】最急降下法\n",
    "最急降下法により学習させる実装を行なってください。以下の式で表されるパラメータの更新式のメソッド_gradient_descentを追加し、fit\n",
    "メソッドから呼び出すようにしてください。\n",
    "\n",
    "\n",
    "θ\n",
    "j\n",
    ":=\n",
    "θ\n",
    "j\n",
    "−\n",
    "α\n",
    "1\n",
    "m\n",
    "m\n",
    "∑\n",
    "i\n",
    "=\n",
    "1\n",
    " \n",
    "[\n",
    "(\n",
    "h\n",
    "θ\n",
    "(\n",
    "x\n",
    "(\n",
    "i\n",
    ")\n",
    ")\n",
    "−\n",
    "y\n",
    "(\n",
    "i\n",
    ")\n",
    ")\n",
    "x\n",
    "(\n",
    "i\n",
    ")\n",
    "j\n",
    "]\n",
    "\n",
    "$\\alpha$ : 学習率\n",
    "\n",
    "\n",
    "$i$ : サンプルのインデックス\n",
    "\n",
    "\n",
    "$j$ : 特徴量のインデックス\n",
    "\n",
    "\n",
    "雛形\n",
    "\n",
    "\n",
    "ScratchLinearRegressionクラスへ以下のメソッドを追加してください。コメントアウト部分の説明も記述してください。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題２　単独で作成した関数\n",
    "\n",
    "def _gradient_descent_1(X, y, alpha=0.1, error=0):\n",
    "    \"\"\"\n",
    "    最急降下法\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    \n",
    "    alpha：学習率\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    \"\"\"\n",
    "    # データフレーム型だった場合にnd_array型に変換\n",
    "    if type(X) is pd.core.frame.DataFrame:\n",
    "        X = X.values\n",
    "        \n",
    "    np.random.seed(0)\n",
    "    theta = np.random.random(size=X.shape[1])\n",
    "\n",
    "    y = np.ones(5)\n",
    "    \n",
    "    # gradientを求める\n",
    "    gradient = 0\n",
    "    for x in range(X.shape[1]):\n",
    "        gradient += alpha * (_linear_hypothesis(X)[x] - y[x]) * X[x, :]\n",
    "    \n",
    "    gradient = gradient / X.shape[1]\n",
    "    \n",
    "    # thetaの更新\n",
    "    error = theta - gradient\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】推定\n",
    "推定する仕組みを実装してください。ScratchLinearRegressionクラスの雛形に含まれるpredictメソッドに書き加えてください。\n",
    "\n",
    "\n",
    "仮定関数 $h_\\theta(x)$ の出力が推定結果です。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題3 単独で作成した関数\n",
    "def predict(X):\n",
    "    \"\"\"\n",
    "    線形回帰を使い推定する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "        サンプル\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        次の形のndarray, shape (n_samples, 1)\n",
    "        線形回帰による推定結果\n",
    "    \"\"\"\n",
    "\n",
    "    theta = np.random.random(size=X.shape[1])\n",
    "    theta = np.dot(X, _gradient_descent(X).T)    \n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】平均二乗誤差\n",
    "線形回帰の指標値として用いられる平均二乗誤差（mean square error, MSE）の関数を作成してください。\n",
    "\n",
    "\n",
    "平均二乗誤差関数は回帰問題全般で使える関数のため、ScratchLinearRegressionクラスのメソッドではなく、別の関数として作成してください。雛形を用意してあります。\n",
    "\n",
    "\n",
    "平均二乗誤差は以下の数式で表されます。\n",
    "\n",
    "\n",
    "L\n",
    "(\n",
    "θ\n",
    ")\n",
    "=\n",
    "1\n",
    "m\n",
    "m\n",
    "∑\n",
    "i\n",
    "=\n",
    "1\n",
    " \n",
    "(\n",
    "h\n",
    "θ\n",
    "(\n",
    "x\n",
    "(\n",
    "i\n",
    ")\n",
    ")\n",
    "−\n",
    "y\n",
    "(\n",
    "i\n",
    ")\n",
    ")\n",
    "2\n",
    ".\n",
    "\n",
    "$m$ : 入力されるデータの数\n",
    "\n",
    "\n",
    "$h_\\theta()$ : 仮定関数\n",
    "\n",
    "\n",
    "$x^{(i)}$ : i番目のサンプルの特徴量ベクトル\n",
    "\n",
    "\n",
    "$y^{(i)}$ : i番目のサンプルの正解値\n",
    "\n",
    "\n",
    "なお、最急降下法のための目的関数（損失関数）としては、これを2で割ったものを使用します。（問題5, 9）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題4\n",
    "\n",
    "def MSE(y_pred, y):\n",
    "    \"\"\"\n",
    "    平均二乗誤差の計算\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : 次の形のndarray, shape (n_samples,)\n",
    "      推定した値\n",
    "    y : 次の形のndarray, shape (n_samples,)\n",
    "      正解値\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mse : numpy.float\n",
    "      平均二乗誤差\n",
    "    \"\"\"\n",
    "    mse = np.average((y_pred - y) ** 2)\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】目的関数\n",
    "以下の数式で表される線形回帰の 目的関数（損失関数） を実装してください。そして、これをself.loss, self.val_lossに記録するようにしてください。\n",
    "\n",
    "\n",
    "目的関数（損失関数） \n",
    "J\n",
    "(\n",
    "θ\n",
    ")\n",
    " は次の式です。\n",
    "\n",
    "\n",
    "J\n",
    "(\n",
    "θ\n",
    ")\n",
    "=\n",
    "1\n",
    "2\n",
    "m\n",
    "m\n",
    "∑\n",
    "i\n",
    "=\n",
    "1\n",
    " \n",
    "(\n",
    "h\n",
    "θ\n",
    "(\n",
    "x\n",
    "(\n",
    "i\n",
    ")\n",
    ")\n",
    "−\n",
    "y\n",
    "(\n",
    "i\n",
    ")\n",
    ")\n",
    "2\n",
    ".\n",
    "\n",
    "m\n",
    " : 入力されるデータの数\n",
    "\n",
    "\n",
    "h\n",
    "θ\n",
    "(\n",
    ")\n",
    " : 仮定関数\n",
    "\n",
    "\n",
    "x\n",
    "(\n",
    "i\n",
    ")\n",
    " : i番目のサンプルの特徴量ベクトル\n",
    "\n",
    "\n",
    "y\n",
    "(\n",
    "i\n",
    ")\n",
    " : i番目のサンプルの正解値"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】学習と推定\n",
    "機械学習スクラッチ入門のSprintで用意したHouse Pricesコンペティションのデータに対してスクラッチ実装の学習と推定を行なってください。\n",
    "\n",
    "\n",
    "scikit-learnによる実装と比べ、正しく動いているかを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "Id                                                                    \n",
       "1           60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "2           20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "3           60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "4           70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "5           60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "   LandContour Utilities LotConfig    ...     PoolArea PoolQC Fence  \\\n",
       "Id                                    ...                             \n",
       "1          Lvl    AllPub    Inside    ...            0    NaN   NaN   \n",
       "2          Lvl    AllPub       FR2    ...            0    NaN   NaN   \n",
       "3          Lvl    AllPub    Inside    ...            0    NaN   NaN   \n",
       "4          Lvl    AllPub    Corner    ...            0    NaN   NaN   \n",
       "5          Lvl    AllPub       FR2    ...            0    NaN   NaN   \n",
       "\n",
       "   MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "Id                                                                         \n",
       "1          NaN       0      2    2008        WD         Normal     208500  \n",
       "2          NaN       0      5    2007        WD         Normal     181500  \n",
       "3          NaN       0      9    2008        WD         Normal     223500  \n",
       "4          NaN       0      2    2006        WD        Abnorml     140000  \n",
       "5          NaN       0     12    2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Week4/train.csv\")\n",
    "df = df.set_index(\"Id\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1095, 2)\n",
      "(365, 2)\n",
      "(1095, 1)\n",
      "(365, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X変数には2つ、y変数にはSalePriceを抽出\n",
    "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n",
    "y = df.loc[:, [\"SalePrice\"]]\n",
    "\n",
    "# スクラッチ関数で分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  98.588892  , 1041.18622755]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([-2021422.10210011])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 係数\n",
    "display(lr.coef_)\n",
    "# 切片\n",
    "display(lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題7】学習曲線のプロット\n",
    "学習曲線を表示する関数を作成し、実行してください。グラフを見て損失が適切に下がっているかどうか確認してください。\n",
    "\n",
    "\n",
    "線形回帰クラスの雛形ではself.loss, self.val_lossに損失を記録しておくようになっているため、入力にはこれを利用してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1 = np.ones(X_zero.shape[0]).reshape(-1, 1)\n",
    "X_1\n",
    "\n",
    "#X_array2 = np.hstack((X_1,X_zero))\n",
    "#X_array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      訓練データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証データに対する損失の記録\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_iter, lr, no_bias, verbose):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.no_bias = no_bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "        #np.random.seed(0)\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        \n",
    "        #if type(X) is pd.core.frame.DataFrame:\n",
    "            #X = X.values\n",
    "        \n",
    "        #if type(y) is  pd.core.frame.DataFrame:\n",
    "            #y = y.values\n",
    "        \n",
    "        np.random.seed(0)\n",
    "        self.theta = np.random.randn(X.shape[1] + 1)\n",
    "        \n",
    "        # 訓練データ・学習データのインスタンス変数化\n",
    "        self.X, self.y, self.X_val, self.y_val = self._setting(X, y, X_val, y_val)\n",
    "            \n",
    "\n",
    "        for i in range(self.iter):\n",
    "            self.linear_hypo = self._linear_hypothesis(self.X)\n",
    "            #print(\"linear_hypothetis\", self.linear_hypo)\n",
    "            #print(\"linear_hypothetis.shape\", self.linear_hypo.shape)\n",
    "            \n",
    "            self.grad = self._gradient_descent(self.X, self.y)\n",
    "            #print(\"[theta]\", self.grad)\n",
    "            #print(\"[theta].shape\", self.grad.shape)\n",
    "            \n",
    "            self.pred = self.predict(self.X)\n",
    "            #print(\"[pred]\", self.pred)\n",
    "            \n",
    "            self.loss[i] = self.loss_func(self.y)\n",
    "            \n",
    "            if self.verbose:\n",
    "                # verboseをTrueにした際は学習過程を出力\n",
    "                print(\"iter{}:[loss]:{}\".format(i, self.loss[i]))\n",
    "\n",
    "            if X_val is not None and y_val is not None:\n",
    "                self.val_loss[i] = self.loss_func(self.y_val)\n",
    "                print(\"iter{}:[val_loss]:{}\".format(i, self.val_loss[i]))\n",
    "                \n",
    "\n",
    "    def _setting(self, X, y, X_val, y_val):\n",
    "        X_copy = np.copy(X)\n",
    "        y_copy = np.copy(y)\n",
    "        X_val_copy = np.copy(X_val)\n",
    "        y_val_copy = np.copy(y_val)\n",
    "        \n",
    "        if X_val is None and y_val is None:\n",
    "            return X_copy, y_copy, X_val, y_val\n",
    "\n",
    "        else:\n",
    "            if self.no_bias == False:\n",
    "                X_ones = np.ones(X.shape[0]).reshape(-1, 1)\n",
    "                X_val_ones = np.ones(X_val.shape[0]).reshape(-1, 1)                \n",
    "                X_copy = np.hstack((X_ones, X_copy))\n",
    "                X_val_copy = np.hstack((X_val_ones, X_val_copy))\n",
    "                \n",
    "                return X_copy, y_copy, X_val_copy, y_val_copy\n",
    "            \n",
    "            else:\n",
    "                return X_copy, y_copy, X_val_copy, y_val_copy\n",
    "    \n",
    "    def _linear_hypothesis(self, X):\n",
    "        \"\"\"\n",
    "        線形の仮定関数を計算する\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "          訓練データ\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "          次の形のndarray, shape (n_samples, 1)\n",
    "          線形の仮定関数による推定結果\n",
    "\n",
    "        \"\"\"\n",
    "        self.hypo = np.dot(self.X, self.theta.T)\n",
    "\n",
    "        return self.hypo\n",
    "\n",
    "    def _gradient_descent(self, X, y, alpha=0.1, error=0):\n",
    "        \"\"\"\n",
    "        最急降下法\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "          訓練データ\n",
    "\n",
    "        alpha：学習率\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        m = len(self.y)\n",
    "        #print(m, \"testestestestestestestes\")\n",
    "        #print(self.theta)\n",
    "        #print(self.theta.shape)\n",
    "        \n",
    "        grad = np.dot(self.X.T,(self.linear_hypo-self.y))\n",
    "        #print(grad, \"testestestestestestestes\")\n",
    "        #print(grad.shape)\n",
    "\n",
    "        grad_average = np.average(grad, axis=1)\n",
    "        #print(\"grad_average!!!!!!\", grad_average, \"testestestestestestestes\")\n",
    "        #print(grad_average.shape)\n",
    "        \n",
    "        self.theta = self.theta - alpha*grad_average\n",
    "        \n",
    "        # theta = np.random.random(2)\n",
    "        \n",
    "        #for x in range(X.shape[0]):\n",
    "        # self.temp0 = theta[0] - alpha*(1/(m))*np.sum(theta[0]+theta[1]*X-y)\n",
    "        # self.temp1 = theta[1] - alpha*(1/(m))*np.sum((theta[0]+theta[1]*X-y)*X)\n",
    "        \n",
    "        # self.gradient += alpha * (self._linear_hypothesis(X)[x] - y[x]) * X[x, :]\n",
    "\n",
    "        # self.gradient = self.gradient / X.shape[0]\n",
    "\n",
    "        # thetaの更新\n",
    "        # theta = np.array([self.temp0, self.temp1])\n",
    "        \n",
    "        return self.theta\n",
    "\n",
    "    def predict(self, X):#self.linear_hypo\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            線形回帰による推定結果\n",
    "        \"\"\"\n",
    "        # print(self.X)\n",
    "\n",
    "        pred = np.dot(self.X, self._gradient_descent(self.X, self.y).T)\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def loss_func(self, y):\n",
    "        \"\"\"\n",
    "        損失関数の計算\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : 次の形のndarray, shape (n_samples,)\n",
    "        訓練データまたはテストデータ\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        \"\"\"\n",
    "        loss = np.average((self.pred - y) ** 2) / 2\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter0:[loss]:3.241206495189395e+28\n",
      "iter0:[val_loss]:3.2412064951704223e+28\n",
      "iter1:[loss]:5.960999651279994e+46\n",
      "iter1:[val_loss]:5.960999651279995e+46\n",
      "iter2:[loss]:1.0985667743739024e+65\n",
      "iter2:[val_loss]:1.0985667743739027e+65\n",
      "iter3:[loss]:2.024574783351277e+83\n",
      "iter3:[val_loss]:2.024574783351277e+83\n",
      "iter4:[loss]:3.731136922212059e+101\n",
      "iter4:[val_loss]:3.7311369222120575e+101\n",
      "iter5:[loss]:6.87620079375384e+119\n",
      "iter5:[val_loss]:6.87620079375384e+119\n",
      "iter6:[loss]:1.2672313651783405e+138\n",
      "iter6:[val_loss]:1.2672313651783408e+138\n",
      "iter7:[loss]:2.3354107610564466e+156\n",
      "iter7:[val_loss]:2.3354107610564474e+156\n",
      "iter8:[loss]:4.303983923323016e+174\n",
      "iter8:[val_loss]:4.303983923323016e+174\n",
      "iter9:[loss]:7.931914128820454e+192\n",
      "iter9:[val_loss]:7.93191412882046e+192\n"
     ]
    }
   ],
   "source": [
    "scr_lr = ScratchLinearRegression(num_iter=10, \n",
    "                                 lr=0.01, \n",
    "                                 no_bias = False,\n",
    "                                 verbose=True)\n",
    "\n",
    "scr_lr.fit(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4236548 , 0.64589411])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = np.random.random(X_train.shape[1])\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo = X_train * error.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.32095208e+11, -3.31169729e+11],\n",
       "       [-3.90041825e+11, -3.88685887e+11]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.66047604e+09, -1.65584864e+09],\n",
       "       [-1.95020913e+09, -1.94342944e+09]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "467px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
