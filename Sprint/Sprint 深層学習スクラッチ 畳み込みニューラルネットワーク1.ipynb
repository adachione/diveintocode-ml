{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 深層学習スクラッチ 畳み込みニューラルネットワーク1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import copy\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.optimizer = optimizer\n",
    "        self.shape = n_nodes1, n_nodes2\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(self.shape)\n",
    "        self.B = initializer.B(self.shape)\n",
    "        self.dW = 0\n",
    "        self.dB = 0\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        A = np.dot(X, self.W) + self.B   # (batch_size, n_nodes2)\n",
    "\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        n_batch = dA.shape[0]\n",
    "        \n",
    "        # TODO　dw とdbをバッチサイズで割る　FCで実行\n",
    "        self.dB = np.sum(dA, axis=0)/n_batch\n",
    "        self.dW = np.dot(self.X.T, dA)/n_batch\n",
    "        dZ = np.dot(dA, self.W.T)    # (batch_size, n_nodes1)\n",
    "        \n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return dZ\n",
    "\n",
    "# Initializer群\n",
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma, debug=False):\n",
    "        self.sigma = sigma\n",
    "        self.debug = debug\n",
    "        # self.shape\n",
    "        \n",
    "    def W(self, shape):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_N : int\n",
    "          前の層のノード数\n",
    "        shape : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        if self.debug == \"問題3\":\n",
    "            # 問題3テスト用\n",
    "            W = np.array([3, 5, 7])\n",
    "\n",
    "        elif self.debug == \"問題4\":\n",
    "            # 問題4テスト用\n",
    "            W = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "\n",
    "        else:\n",
    "            W = self.sigma * np.random.standard_normal(shape)\n",
    "            \n",
    "        return W\n",
    "\n",
    "\n",
    "\n",
    "    def B(self, shape):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        shape : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        if self.debug == \"問題3\":\n",
    "            # 問題3テスト用\n",
    "            B = np.array([1])\n",
    "        \n",
    "        elif self.debug == \"問題4\":\n",
    "            # 問題4テスト用\n",
    "            B = np.array([1, 2, 3]).astype(\"float\") # （出力チャンネル数）\n",
    "\n",
    "        else:\n",
    "            B = np.random.standard_normal(shape[1]).astype(\"float\")\n",
    "            \n",
    "        return B\n",
    "\n",
    "# Initializer群\n",
    "class SimpleInitializer_Conv():\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma, debug=False):\n",
    "        self.sigma = sigma\n",
    "        self.debug = debug\n",
    "        # self.shape\n",
    "        \n",
    "    def W(self, shape):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_N : int\n",
    "          前の層のノード数\n",
    "        shape : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        if self.debug == \"問題3\":\n",
    "            # 問題3テスト用\n",
    "            W = np.array([3, 5, 7])\n",
    "\n",
    "        elif self.debug == \"問題4\":\n",
    "            # 問題4テスト用\n",
    "            W = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "\n",
    "        else:\n",
    "            W = self.sigma * np.random.standard_normal(shape)\n",
    "            \n",
    "        return W\n",
    "\n",
    "\n",
    "\n",
    "    def B(self, shape):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        shape : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        if self.debug == \"問題3\":\n",
    "            # 問題3テスト用\n",
    "            B = np.array([1])\n",
    "        \n",
    "        elif self.debug == \"問題4\":\n",
    "            # 問題4テスト用\n",
    "            B = np.array([1, 2, 3]).astype(\"float\") # （出力チャンネル数）\n",
    "\n",
    "        else:\n",
    "            B = np.random.standard_normal(shape[0]).astype(\"float\")\n",
    "            \n",
    "        return B\n",
    "\n",
    "class XavierInitializer:\n",
    "    \"\"\"\n",
    "    Xavierの初期値作成クラス\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def W(self, shape):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_N : int\n",
    "          前の層のノード数\n",
    "        shape : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        sigma = 1.0 / np.sqrt(shape[1])\n",
    "        W = sigma * np.random_standard_normal(shape)\n",
    "        \n",
    "        return W\n",
    "    \n",
    "    def B(self, shape):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        shape : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = np.random.standard_normal(shape[0])\n",
    "        \n",
    "        return B\n",
    "\n",
    "class HeInitializer:\n",
    "    \"\"\"\n",
    "    Heの初期値作成クラス\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def W(self, shape):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_N : int\n",
    "          前の層のノード数\n",
    "        shape : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        sigma = np.sqrt(2.0 / shape[1])\n",
    "        W = sigma * np.random_standard_normal(shape)\n",
    "        \n",
    "        return W\n",
    "    \n",
    "    def B(self, shape):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        shape : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = np.random.standard_normal(shape[0])\n",
    "        \n",
    "        return B\n",
    "\n",
    "# optimizer群\n",
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"   \n",
    "        layer.W -= self.lr * layer.dW        \n",
    "        layer.B -= self.lr * layer.dB\n",
    "        \n",
    "class Adagrad:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        self.HW = 0\n",
    "        self.HB = 0\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        self.HW += np.square(layer.dW)\n",
    "        layer.W -= self.lr * layer.dW / (np.sqrt(self.HW) + 1e-7)\n",
    "        self.HB += np.square(layer.dB)        \n",
    "        layer.B -= self.lr * layer.dB / (np.sqrt(self.HB) + 1e-7)\n",
    "\n",
    "# Activation群\n",
    "class Tanh():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return np.tanh(A)\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        dZ : n層目のバックプロバゲーション\n",
    "        A :　n層目のフォワードプロバゲーションのA\n",
    "        \n",
    "        \"\"\"\n",
    "        y = dZ*((1-self.forward(self.A)**2))\n",
    "        return y\n",
    "\n",
    "class Sigmoid():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return 1 / (1 + np.exp(-A))\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        dZ : n層目のバックプロバゲーション\n",
    "        A :　n層目のフォワードプロバゲーションのA\n",
    "         \n",
    "        \"\"\"\n",
    "        y = dZ*(1-self.forward(self.A))*(self.forward(self.A))\n",
    "        return y    \n",
    "\n",
    "class Softmax():\n",
    "    \"\"\"\n",
    "    ソフトマックス関数クラス\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self, A):\n",
    "        # ソフトマックス計算 Zが出力値\n",
    "        self.A = A\n",
    "        c = np.max(A)\n",
    "        self.Z = np.exp(A-c) / np.sum(np.exp(A-c), axis=1, keepdims=True)\n",
    "        \n",
    "        return self.Z\n",
    "    \n",
    "    def backward(self, Z, y):\n",
    "        \"\"\"\n",
    "        dZ　: 最終層のZ\n",
    "        Y　:　（バッチ）サンプルラベル\n",
    "        \"\"\"\n",
    "        dZ = self.Z - y\n",
    "        \n",
    "        # クロスエントロピー誤差計算\n",
    "        batch_size = y.shape[0]\n",
    "        error = -np.sum(y*np.log(self.Z + 1e-7)) / batch_size\n",
    "        \n",
    "        return dZ , error\n",
    "\n",
    "# ゼロつくに乗っていたコード\n",
    "class Relu():\n",
    "    \"\"\"\n",
    "    Relu関数クラス\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, A):\n",
    "        self.mask = (A <= 0)\n",
    "        out = A.copy()\n",
    "        out[self.mask] = 0\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dz):\n",
    "        \"\"\"\n",
    "        Z:\n",
    "        y:\n",
    "        \n",
    "        \"\"\"\n",
    "        dz[self.mask] = 0\n",
    "        y = dz\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】チャンネル数を1に限定した1次元畳み込み層クラスの作成\n",
    "チャンネル数を1に限定した1次元畳み込み層のクラスSimpleConv1dを作成してください。基本構造は前のSprintで作成した全結合層のFCクラスと同じになります。なお、重みの初期化に関するクラスは必要に応じて作り変えてください。Xavierの初期値などを使う点は全結合層と同様です。\n",
    "\n",
    "\n",
    "ここでは パディング は考えず、ストライド も1に固定します。また、複数のデータを同時に処理することも考えなくて良く、バッチサイズは1のみに対応してください。この部分の拡張はアドバンス課題とします。\n",
    "\n",
    "\n",
    "フォワードプロパゲーションの数式は以下のようになります。\n",
    "\n",
    "\n",
    "a\n",
    "i\n",
    "=\n",
    "F\n",
    "−\n",
    "1\n",
    "∑\n",
    "s\n",
    "=\n",
    "0\n",
    " \n",
    "x\n",
    "(\n",
    "i\n",
    "+\n",
    "s\n",
    ")\n",
    "w\n",
    "s\n",
    "+\n",
    "b\n",
    "\n",
    "$a_i$ : 出力される配列のi番目の値\n",
    "\n",
    "\n",
    "$F$ : フィルタのサイズ\n",
    "\n",
    "\n",
    "$x_{(i+s)}$ : 入力の配列の(i+s)番目の値\n",
    "\n",
    "\n",
    "$w_s$ : 重みの配列のs番目の値\n",
    "\n",
    "\n",
    "$b$ : バイアス項\n",
    "\n",
    "\n",
    "全てスカラーです。\n",
    "\n",
    "\n",
    "次に更新式です。ここがAdaGradなどに置き換えられる点は全結合層と同様です。\n",
    "\n",
    "\n",
    "w\n",
    "′\n",
    "s\n",
    "=\n",
    "w\n",
    "s\n",
    "−\n",
    "α\n",
    "∂\n",
    "L\n",
    "∂\n",
    "w\n",
    "s\n",
    "b\n",
    "′\n",
    "=\n",
    "b\n",
    "−\n",
    "α\n",
    "∂\n",
    "L\n",
    "∂\n",
    "b\n",
    "\n",
    "$\\alpha$ : 学習率\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial w_s}$ : $w_s$ に関する損失 $L$ の勾配\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial b}$ : $b$ に関する損失 $L$ の勾配\n",
    "\n",
    "\n",
    "勾配 $\\frac{\\partial L}{\\partial w_s}$ や $\\frac{\\partial L}{\\partial b}$ を求めるためのバックプロパゲーションの数式が以下です。\n",
    "\n",
    "\n",
    "∂\n",
    "L\n",
    "∂\n",
    "w\n",
    "s\n",
    "=\n",
    "N\n",
    "o\n",
    "u\n",
    "t\n",
    "−\n",
    "1\n",
    "∑\n",
    "i\n",
    "=\n",
    "0\n",
    " \n",
    "∂\n",
    "L\n",
    "∂\n",
    "a\n",
    "i\n",
    "x\n",
    "(\n",
    "i\n",
    "+\n",
    "s\n",
    ")\n",
    "∂\n",
    "L\n",
    "∂\n",
    "b\n",
    "=\n",
    "N\n",
    "o\n",
    "u\n",
    "t\n",
    "−\n",
    "1\n",
    "∑\n",
    "i\n",
    "=\n",
    "0\n",
    " \n",
    "∂\n",
    "L\n",
    "∂\n",
    "a\n",
    "i\n",
    "\n",
    "$\\frac{\\partial L}{\\partial a_i}$ : 勾配の配列のi番目の値\n",
    "\n",
    "\n",
    "$N_{out}$ : 出力のサイズ\n",
    "\n",
    "\n",
    "前の層に流す誤差の数式は以下です。\n",
    "\n",
    "\n",
    "∂\n",
    "L\n",
    "∂\n",
    "x\n",
    "j\n",
    "=\n",
    "F\n",
    "−\n",
    "1\n",
    "∑\n",
    "s\n",
    "=\n",
    "0\n",
    " \n",
    "∂\n",
    "L\n",
    "∂\n",
    "a\n",
    "(\n",
    "j\n",
    "−\n",
    "s\n",
    ")\n",
    "w\n",
    "s\n",
    "\n",
    "$\\frac{\\partial L}{\\partial x_j}$ : 前の層に流す誤差の配列のj番目の値\n",
    "\n",
    "\n",
    "ただし、 $j-s<0$ または $j-s>N_{out}-1$ のとき $\\frac{\\partial L}{\\partial a_{(j-s)}} =0$ です。\n",
    "\n",
    "\n",
    "全結合層との大きな違いは、重みが複数の特徴量に対して共有されていることです。この場合は共有されている分の誤差を全て足すことで勾配を求めます。計算グラフ上での分岐はバックプロパゲーションの際に誤差の足し算をすれば良いことになります。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_length = 100\n",
    "n_sample = 100000\n",
    "anomaly_noise = np.random.randn(data_length)    #異常値は分散が大きい\n",
    "nomaly_noise  = np.random.randn(data_length)/2  #正常値は分散が小さい\n",
    "\n",
    "#時系列とラベルを生成\n",
    "t = np.linspace(0,10,data_length)\n",
    "x_anomaly = np.array([np.sin(t) + anomaly_noise for i in range(n_sample//2)])\n",
    "x_nomaly  = np.array([np.sin(t) + nomaly_noise  for i in range(n_sample//2)])\n",
    "X = np.concatenate([x_anomaly,x_nomaly])\n",
    "y = np.concatenate([np.ones(n_sample//2),np.zeros(n_sample//2)])\n",
    "\n",
    "#シャッフル\n",
    "rand_idx = np.arange(n_sample)\n",
    "np.random.shuffle(rand_idx)\n",
    "X = X[rand_idx,:]\n",
    "y = y[rand_idx]\n",
    "\n",
    "#描画\n",
    "plt.plot(t,x_anomaly[0,:])\n",
    "plt.plot(t,x_nomaly[0,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題1,3\n",
    "class SimpleConv1d:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.initializer = initializer\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        self.W = self.initializer.W(shape=(3))\n",
    "        self.B = self.initializer.B(shape=(3))\n",
    "        self.dW = 0\n",
    "        self.dB = 0\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        \n",
    "        # TODO 汎用性ある形にする********************\n",
    "        a = np.zeros((2, 3))\n",
    "        self.indexes0 = np.arange(X.shape[0]-1).astype(np.int)\n",
    "        self.indexes1 = np.arange(1, X.shape[0]).astype(np.int)\n",
    "        a[0] = X[self.indexes0]*self.W # x[indexes0]は([1, 2, 3])である\n",
    "        a[1] = X[self.indexes1]*self.W # x[indexes1]は([2, 3, 4])である\n",
    "        a = a.sum(axis=1) + self.B\n",
    "\n",
    "        return a\n",
    "        \n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        # TODO 汎用性ある形にする********************\n",
    "        self.dB = np.sum(dA)\n",
    "        self.dW = dA[0] * self.X[self.indexes0] + dA[1] * self.X[self.indexes1]\n",
    "        dx1 = np.hstack((dA[0] * self.W, 0))\n",
    "        dx2 = np.insert(dA[1] * self.W, 0, 0)\n",
    "        \n",
    "        dx = dx1 + dx2\n",
    "        \n",
    "        # 更新\n",
    "#         self = self.optimizer.update(self)\n",
    "        \n",
    "        return self.dB, self.dW, dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35. 50.]\n",
      "(30, array([ 50,  80, 110]), array([ 30, 110, 170, 140]))\n"
     ]
    }
   ],
   "source": [
    "# 問題3\n",
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])\n",
    "\n",
    "delta_a = np.array([10, 20])\n",
    "\n",
    "test = SimpleConv1d(n_nodes1=0, n_nodes2=0, initializer=SimpleInitializer(sigma=0.01, debug=\"問題3\"), optimizer=SGD())\n",
    "\n",
    "print(test.forward(x))\n",
    "print(test.backward(delta_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ↑shapeは(出力, 入力, フィルターサイズ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 検算やnumpyテストなど\n",
    "a = np.array([10, 20, 30])\n",
    "\n",
    "b = np.array([3, 5, 7])\n",
    "\n",
    "b+a\n",
    "\n",
    "np.insert(a, 0, 0)\n",
    "\n",
    "np.hstack((b, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実装に向けて必要そうなクラスや関数リストをまとめておく\n",
    "\n",
    "**最低限必要なLayer Class**\n",
    "- 畳み込み層(Conv1d)\n",
    "- 平滑化層(Flatten)\n",
    "- 全結合出力層(Affin)\n",
    " - 回帰\n",
    " - 二値分類\n",
    " - 多値分類\n",
    "- Pooling層\n",
    "\n",
    "あればうれしい\n",
    "- Global Average Pooling層\n",
    "- Atrous層(Dilated層)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizerのクラス群\n",
    "- SGD\n",
    "- Adagrad\n",
    "\n",
    "発展的なOptimizer\n",
    "- Adam\n",
    "- Eve\n",
    "- 最近提案されたやつ(Adaboundsとか？)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】1次元畳み込み後の出力サイズの計算\n",
    "畳み込みを行うと特徴量の数が変化します。どのように変化するかは以下の数式から求められます。パディングやストライドも含めています。この計算を行う関数を作成してください。\n",
    "\n",
    "$$\n",
    "N_{out}=\\frac{N_{in}+2P−F}{S}+1\n",
    "$$\n",
    "\n",
    "$N_{out}$ : 出力のサイズ（特徴量の数）\n",
    "\n",
    "\n",
    "$N_{in}$ : 入力のサイズ（特徴量の数）\n",
    "\n",
    "\n",
    "$P$ : ある方向へのパディングの数\n",
    "\n",
    "\n",
    "$F$ : フィルタのサイズ\n",
    "\n",
    "\n",
    "$S$ : ストライドのサイズ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題2\n",
    "def calc_out_shape(X, w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "    X : 入力array\n",
    "    w : フィルター\n",
    "    stride=1\n",
    "    pad=0\n",
    "    \n",
    "    return\n",
    "    out_N : 出力のサイズ\n",
    "    \"\"\"\n",
    "    input_size = X.shape[1]\n",
    "    filter_size = w.shape[-1]\n",
    "    \n",
    "    out_N = 1 + (input_size + 2*pad - filter_size) / stride\n",
    "    \n",
    "    return int(out_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】小さな配列での1次元畳み込み層の実験\n",
    "次に示す小さな配列でフォワードプロパゲーションとバックプロパゲーションが正しく行えているか確認してください。\n",
    "\n",
    "\n",
    "入力x、重みw、バイアスbを次のようにします。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問題1のクラス下に回答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成\n",
    "チャンネル数を1に限定しない1次元畳み込み層のクラスConv1dを作成してください。\n",
    "\n",
    "\n",
    "例えば以下のようなx, w, bがあった場合は、\n",
    "入力が2チャンネル、出力が3チャンネルの例です。計算グラフを書いた上で、バックプロパゲーションも手計算で考えてみましょう。計算グラフの中には和と積しか登場しないので、微分を新たに考える必要はありません。\n",
    "\n",
    "\n",
    "《補足》\n",
    "\n",
    "\n",
    "チャンネル数を加える場合、配列をどういう順番にするかという問題があります。(バッチサイズ、チャンネル数、特徴量数)または(バッチサイズ、特徴量数、チャンネル数)が一般的で、ライブラリによって順番は異なっています。（切り替えて使用できるものもあります）\n",
    "\n",
    "\n",
    "今回のスクラッチでは自身の実装上どちらが効率的かを考えて選んでください。上記の例ではバッチサイズは考えておらず、(チャンネル数、特徴量数)です。\n",
    "\n",
    "\"\"\"python\n",
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d:\n",
    "    \"\"\"\n",
    "    チャネル数次元が増えた場合のクラス\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, out_channel, in_channel, filter_size, initializer, optimizer):\n",
    "        self.optimizer = optimizer \n",
    "        self.shape = out_channel, in_channel, filter_size\n",
    "        # 初期化\n",
    "        self.W = initializer.W(self.shape) #(出力チャンネル数、入力チャンネル数、フィルタサイズ)\n",
    "        self.B = initializer.B(self.shape)\n",
    "        self.dW = 0\n",
    "        self.dB = 0\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_input)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_output)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.n_channel = self.W.shape[0]  # W.shape=(出力チャンネル数、入力チャンネル数、フィルタサイズ)\n",
    "        self.n_features = self.X.shape[1]\n",
    "        \n",
    "        # 畳み込み後の出力サイズを計算し、その分のIndexを作成\n",
    "        n_out = self._calc_out_shape(self.X,self.W)\n",
    "        id_Z = np.arange(n_out)[:,None]  #出力層分のindexを生成\n",
    "        id_w = np.arange(w.shape[0])  #フィルタ数分のindexを生成\n",
    "        \n",
    "        self.indexes = id_Z + id_w  #ブロードキャストで計算用index arrayを生成; shape (n_out, w.shape)\n",
    "        \n",
    "        x_reshape = X[:, self.indexes]　　　# X[[[1, 2, 3],[2, 3, 4]], [3, 4, 5], [4, 5, 6]]]のような3次元のshapeを作成\n",
    "        \n",
    "        # aを計算\n",
    "        a = np.tensordot(x_reshape, self.W, axes=([1, 2], [1, 2])) + self.B\n",
    "\n",
    "        return a\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.dB = np.sum(dA, axis=1).astype(\"float\")\n",
    "        self.dW = np.tensordot(dA, self.X[:, self.indexes], axes=([1], [0]))   #(3, 2, 3)にしなければいけない\n",
    "        \n",
    "        # dxの空箱を作成\n",
    "        dx = np.zeros(self.X.shape)\n",
    "        \n",
    "        # （出力チャンネル数, 特徴量数, フィルターサイズ）のテンソルを作成\n",
    "        dx0 = np.tensordot(self.W,dA, axes=([0], [0]))\n",
    "        \n",
    "        # 元のXshapeに変換計算\n",
    "        dx_trans = dx0.transpose(1, 2, 0)\n",
    "        for i in range(dx_trans.shape[0]):\n",
    "            dx[:, i:i+dx_trans.shape[2]] += dx_trans[i]\n",
    "                \n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "\n",
    "        return dx\n",
    "    \n",
    "    # 問題2\n",
    "    def _calc_out_shape(self, X, w, stride=1, pad=0):\n",
    "        \"\"\"\n",
    "        X : 入力array\n",
    "        w : フィルター\n",
    "        stride=1\n",
    "        pad=0\n",
    "\n",
    "        return\n",
    "        out_N : 出力のサイズ\n",
    "        \"\"\"\n",
    "        input_size = X.shape[1]\n",
    "        filter_size = w.shape[-1]\n",
    "\n",
    "        out_N = 1 + (input_size + 2*pad - filter_size) / stride\n",
    "\n",
    "        return int(out_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題1~6は上記クラスに実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】（アドバンス課題）パディングの実装\n",
    "畳み込み層にパディングの機能を加えてください。1次元配列の場合、前後にn個特徴量を増やせるようにしてください。\n",
    "\n",
    "\n",
    "最も単純なパディングは全て0で埋める ゼロパディング であり、CNNでは一般的です。他に端の値を繰り返す方法などもあります。\n",
    "\n",
    "\n",
    "フレームワークによっては、元の入力のサイズを保つようにという指定をすることができます。この機能も持たせておくと便利です。なお、NumPyにはパディングの関数が存在します。\n",
    "\n",
    "\n",
    "numpy.pad — NumPy v1.17 Manual\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(X, n):\n",
    "    \"\"\"\n",
    "    X : 配列\n",
    "    n : パディング指定数\n",
    "    \"\"\"\n",
    "    if X.ndim == 1:\n",
    "        padding = np.pad(X, (n, n), 'constant')\n",
    "    elif X.ndim == 2:\n",
    "        padding = np.pad(X, ((0, 0), (n, n)), 'constant')\n",
    "        \n",
    "    # 3次元以上はいったん放置\n",
    "    \n",
    "    return padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "１次元 [ 0 10 20  0]\n",
      "2次元 [[ 0  0 10 15  0  0]\n",
      " [ 0  0 15 20  0  0]\n",
      " [ 0  0 20 25  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# 関数テスト\n",
    "print(\"１次元\", padding(delta_a, 1))\n",
    "print(\"2次元\", padding(delta_aa, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】（アドバンス課題）ミニバッチへの対応\n",
    "ここまでの課題はバッチサイズ1で良いとしてきました。しかし、実際は全結合層同様にミニバッチ学習が行われます。Conv1dクラスを複数のデータが同時に計算できるように変更してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, y, batch_size=20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0] / self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        p0 = item * self.batch_size\n",
    "        p1 = item * self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter * self.batch_size\n",
    "        p1 = self._counter * self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題7】（アドバンス課題）任意のストライド数\n",
    "ストライドは1限定の実装をしてきましたが、任意のストライド数に対応できるようにしてください。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題8】学習と推定\n",
    "これまで使ってきたニューラルネットワークの全結合層の一部をConv1dに置き換えてMNISTを学習・推定し、Accuracyを計算してください。\n",
    "\n",
    "\n",
    "出力層だけは全結合層をそのまま使ってください。ただし、チャンネルが複数ある状態では全結合層への入力は行えません。その段階でのチャンネルは1になるようにするか、 平滑化 を行なってください。\n",
    "\n",
    "\n",
    "画像に対しての1次元畳み込みは実用上は行わないことのため、精度は問いません。\n",
    "\n",
    "- (後藤メンターコメント)これまでと同じように、活性化関数やOptimizerのクラス（関数）を組み合わせて学習・推定させましょう。 チャンネル数が１よりも大きいときはうまく実行できません。なので、平滑化を行えるクラス（関数）を作りましょう。 発展的にGlobal Average Pollingを実装しても問題ありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "# データセットの読み込みから前処理まで\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scratch1dCNNClassifier:\n",
    "    def __init__(self, lr=0.01, n_pad=0, stride=1, fillter_size=3, n_fillter1=20, n_nodes=20, verbose = False):\n",
    "        \n",
    "        self.lr = lr #学習率\n",
    "        self.n_pad = n_pad #パディング数\n",
    "        self.stride = stride #ストライド数\n",
    "        self.fillter_size = fillter_size #フィルターサイズ\n",
    "        self.n_fillter1 = n_fillter1 #1層目フィルター数\n",
    "        self.n_nodes = n_nodes\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None, batch_size=20, epoch=20):\n",
    "        # ラベル化\n",
    "        enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        y_train_one_hot = enc.fit_transform(y[:, np.newaxis]) \n",
    "        if X_val is not None and y_val is not None:\n",
    "            y_val_one_hot = enc.fit_transform(y_val[:, np.newaxis])\n",
    "        \n",
    "        self.n_output = y_train_one_hot.shape[1]\n",
    "        \n",
    "        self.n_features = X.shape[1]  #784\n",
    "        self.n_ch = X.shape[1]  #1        \n",
    "        # lossリスト\n",
    "        self.loss = np.zeros(epoch)\n",
    "        self.val_loss = np.zeros(epoch)\n",
    "        \n",
    "        optimizer = SGD(self.lr)\n",
    "        initializer1 = SimpleInitializer_Conv(sigma=0.01, debug=False)\n",
    "        initializer2 = SimpleInitializer(sigma=0.01, debug=False)\n",
    "        self.Conv1d1 = Conv1d(self.n_fillter1, self.n_ch-2,  self.fillter_size, initializer1, optimizer)\n",
    "        self.activation1 = Tanh()\n",
    "        self.FC2 = FC(self.n_fillter1, self.n_nodes, copy.deepcopy(initializer2), optimizer)\n",
    "        self.activation2 = Tanh()\n",
    "        self.FC3 = FC(self.n_nodes, self.n_output, copy.deepcopy(initializer2), optimizer)\n",
    "        self.activation3 = Softmax()\n",
    "        \n",
    "        #学習処理\n",
    "        for i in range(epoch):\n",
    "            get_mini_batch = GetMiniBatch(X, y_train_one_hot, batch_size)\n",
    "            loss_list = []\n",
    "            \n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                # フォワードプロバゲーション                \n",
    "                A1 = self.Conv1d1.forward(mini_X_train)\n",
    "                Z1 = self.activation1.forward(A1)\n",
    "                A2 = self.FC2.forward(Z1)\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                A3 = self.FC3.forward(Z2)\n",
    "                Z3 = self.activation3.forward(A3)\n",
    "\n",
    "                # バックプロバゲーション\n",
    "                dA3, error = self.activation3.backward(Z3, mini_y_train) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "                loss_list.append(error)\n",
    "                dZ2 = self.FC3.backward(dA3)\n",
    "                dA2 = self.activation2.backward(dZ2)\n",
    "                dZ1 = self.FC2.backward(dA2)\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "                dZ0 = self.Conv1d1.backward(dA1) # dZ0は使用しない\n",
    "                \n",
    "            self.loss[i] =np.sum(loss_list)/len(loss_list)\n",
    "\n",
    "            # val_lossの計算\n",
    "            if X_val is not None and y_val is not None:\n",
    "                # フォワードプロバゲーション**************************\n",
    "                A1 = self.Conv1d1.forward(X_val)     \n",
    "                Z1 = self.activation1.forward(A1)\n",
    "                A2 = self.FC2.forward(Z1)        \n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                A3 = self.FC3.forward(Z2)       \n",
    "                Z3 = self.activation3.forward(A3)\n",
    "\n",
    "                # クロスエントロピー誤差**************************            \n",
    "                _, val_error = self.activation3.backward(Z3, y_val_one_hot) \n",
    "                self.val_loss[i]= val_error                        \n",
    "\n",
    "    def predict(self,X):\n",
    "        A1 = self.Conv1d1.forward(X)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "        y = self.activation3.forward(A3)\n",
    "        \n",
    "        pred = np.argmax(y, axis=1)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.568\n"
     ]
    }
   ],
   "source": [
    "scr_cnn = Scratch1dCNNClassifier(n_fillter1=20)\n",
    "\n",
    "scr_cnn.fit(X_train, y_train, X_val, y_val, epoch=20)\n",
    "\n",
    "pred = scr_cnn.predict(X_test)\n",
    "print(\"Accuracy:{}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss可視化\n",
    "plt.plot(scr_cnn.loss, marker=\".\", label=\"train_loss\")\n",
    "plt.plot(scr_cnn.val_loss, marker=\".\", label=\"val_loss\")\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for文をなるべく少なく、tensordotというメソッドがあることを知り、そこから色々と改変しました。initializerなどもfitを回すために改変したため、振り返って戻すこともできないレベルですが、lossは減少しており、accも程々になりましたので、提出させていただきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問題5のパディングはクラスとして作成したものの、最後の推定問題のクラスには導入しませんでした。問題6のミニバッチ対応は、意識はしておりませんでしたが、最後の推定で無事回ったので問題ないものと思います。問題7のアドバンスは改変に改変を繰り返した結果、複雑になりすぎた為できておりません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "792.205px",
    "left": "1763.33px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
